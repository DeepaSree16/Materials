{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M2_SNB_MiniProject_04_Fare_Amount_Prediction_Using_Dask.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hawaiian-astronomy"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "## A program by IISc and TalentSprint\n",
        "### Mini-Project: Implementation of Linear Regression on a Large Dataset Using Dask Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-kxaHhwXEp9"
      },
      "source": [
        "**DISCLAIMER:** THIS NOTEBOOK IS PROVIDED ONLY AS A REFERENCE SOLUTION NOTEBOOK FOR THE MINI-PROJECT. THERE MAY BE OTHER POSSIBLE APPROACHES/METHODS TO ACHIEVE THE SAME RESULTS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "latin-seventh"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "civil-joyce"
      },
      "source": [
        "At the end of the mini-project, you will be able to :\n",
        "\n",
        "- understand how dask handles large dataset over pandas dataframe \n",
        "- perform exploratory data analysis on a large dataset (2 Million rows) using dask\n",
        "- implement linear regression model using dask library and make predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm1iYi7ZD7Yq"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlU7vlOfD7uk"
      },
      "source": [
        " Predict the taxi fare amount in New York city using Dask-ML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGHv4isOD72Y"
      },
      "source": [
        "## Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bprA1vC_Fgjc"
      },
      "source": [
        "### Dask \n",
        "[Dask](https://dask.pydata.org/en/latest/) is an open source project that gives abstractions over NumPy Arrays, Pandas Dataframes and regular lists, allowing you to run operations on them in parallel, using multicore processing.\n",
        "\n",
        "We can summarize the basics of Dask as follows:\n",
        "\n",
        "* processes data that doesn’t fit into memory by breaking it into blocks and specifying task chains\n",
        "\n",
        "* parallelizes execution of tasks across cores and even nodes of a cluster\n",
        "\n",
        "* moves computation to the data rather than the other way around, to minimize communication overhead"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0joKJDwcO4P6"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "The dataset is based on the 2016 NYC Yellow Cab trip record data made available in Big Query on Google Cloud Platform. Its variables are as follows:\n",
        "![Dataset](https://cdn.iisc.talentsprint.com/CDS/Images/NYC_Taxi_data_description.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQNKsjS7c04"
      },
      "source": [
        "## Grading = 10 Points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "SbsLsOTejPIW"
      },
      "source": [
        "#@title Install Dask dependencies and restart runtime\n",
        "!pip -qq install dask-ml==1.8.0\n",
        "!pip -qq install dask==2.9.1\n",
        "!pip -qq install dask[delayed]\n",
        "!pip -qq install dask[dataframe] --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKxO3msLjVB-"
      },
      "source": [
        "#### Importing Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tZDtdlmShI5"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import dask\n",
        "import dask.dataframe as dd\n",
        "import dask.array as da\n",
        "from dask_ml.linear_model import LinearRegression\n",
        "from dask_ml.model_selection import train_test_split\n",
        "from dask_ml.metrics import mean_squared_error, r2_score\n",
        "from dask.distributed import Client\n",
        "import time as time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns, matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "from dask.distributed import Client, progress\n",
        "# client = Client()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anjQfD2Imqpg",
        "cellView": "form"
      },
      "source": [
        "#@title Download the data\n",
        "!wget -qq https://cdn.iisc.talentsprint.com/CDS/MiniProjects/Dask_MP_dataset.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtkQh3Wtje4C"
      },
      "source": [
        "#### Exercise 1: Read the dataset using dask library and compare the time of execution with pandas library.\n",
        "\n",
        "**Hint:** pass `dtype` for passenger_count as `int64`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFyPyYzkyS0I"
      },
      "source": [
        "%%time\n",
        "ddf = dd.read_csv('/content/Dask_MP_dataset.csv', dtype={'passenger_count': 'int64'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho9I-czijje-"
      },
      "source": [
        "#### Use pandas to read the dataset and compare the time taken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GtHtAhLvJZB"
      },
      "source": [
        "%%time\n",
        "df_pd = pd.read_csv('/content/Dask_MP_dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaXBh2aTZYM4"
      },
      "source": [
        "%%time\n",
        "ddf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFhWA9t11JhC"
      },
      "source": [
        "### Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZX1ryIsjqMu"
      },
      "source": [
        "#### Exercise 2: Drop the unnecessary columns. Also drop the duplicate rows and the rows having null values.\n",
        "\n",
        "**Hint:** Drop those columns which are not useful in EDA as well as model implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY4VbXnyy7E0"
      },
      "source": [
        "ddf = ddf.drop([\"key\", \"Unnamed: 0\"],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C8YkabI1N4l"
      },
      "source": [
        "# Drop duplicate rows\n",
        "%%time\n",
        "ddf = ddf.drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uYv6q0FZtYO"
      },
      "source": [
        "# ddf['pickup_datetime'] = dask.dataframe.to_datetime(ddf['pickup_datetime'])\n",
        "# ddf['year'] = ddf['pickup_datetime'].dt.year\n",
        "# ddf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZTAo8LafjU7"
      },
      "source": [
        "%%time\n",
        "ddf = ddf.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trDd9NJTF61J"
      },
      "source": [
        "# Drop duplicate rows in pandas dataframe\n",
        "%%time\n",
        "df_pd = df_pd.drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlAw0IP3F6oc"
      },
      "source": [
        "%%time\n",
        "df_pd = df_pd.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLOBvChhMOzy"
      },
      "source": [
        "%%time\n",
        "ddf.groupby(\"passenger_count\").fare_amount.mean().compute()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bY6cmDEMO-X"
      },
      "source": [
        "%%time\n",
        "df_pd.groupby(\"passenger_count\").fare_amount.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hui7_jEXNixT"
      },
      "source": [
        "%%time \n",
        "ddf[[\"fare_amount\"]].mean().compute()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GZOsyzWNsCy"
      },
      "source": [
        "%%time \n",
        "df_pd[[\"fare_amount\"]].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4KUGEAlju_J"
      },
      "source": [
        "#### Exercise 3: Visualize the target variable, i.e., `fare_amount` to study the fare distribution, using a histogram density plot. Analyze the fare_amount distribution, try to visualize it for a range of [0, 60].\n",
        "\n",
        "**Hint:** [sns.hisplot()](https://stackoverflow.com/questions/51027636/seaborn-histogram-with-bigdata/51027895) and use `.between` to plot the graph for given range \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpvOEUW01WI_"
      },
      "source": [
        "#exploring data\n",
        "\n",
        "def plot_dist(series=ddf[\"fare_amount\"], title = \"Fare Distribution\"):\n",
        "  sns.histplot(series, kde=True, stat='density',discrete=True)\n",
        "  sns.despine()\n",
        "  plt.title(title)\n",
        "  sns.histplot(series, kde=True, stat='density',discrete=True)\n",
        "  sns.despine()\n",
        "  plt.title(title);\n",
        "  plt.show();\n",
        "  plt.show()\n",
        "plot_dist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEtm-YkTM7iK"
      },
      "source": [
        "#dropping absurd values and plotting fare amount in the range [0, 60]\n",
        "ddf = ddf[ddf.fare_amount.between(0,60)]\n",
        "plot_dist(ddf.fare_amount)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvPfB3yKiVQG"
      },
      "source": [
        "#### Observe the number of workers and cores running in your machine\n",
        "\n",
        "Initialize a client and observe how many workers are working and the number of cores utilizing for the given data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O85yDn3kRErR"
      },
      "source": [
        "# Initializing a client\n",
        "# client = Client(processes=False)\n",
        "# client"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6bDBe3KsrEy"
      },
      "source": [
        "From, above you can observe how many workers are working and the number of cores utilizing for the given data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFmt8ZxPj9Oh"
      },
      "source": [
        "### EDA based on Time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8cNhcLukCwi"
      },
      "source": [
        "#### Exercise 4: Extract day of the week (dow), hour, month and year from `pickup_datetime`.\n",
        "\n",
        "**Hint:** use `pd.to_datetime()` function as dask does not have this functionality in it.\n",
        "\n",
        "Remember to use `.compute()` while passing the dask dataframe in defined function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZUu0gSEgKWm"
      },
      "source": [
        "# pickup_datetime feature\n",
        "\n",
        "def extract_time_features(ddf):\n",
        "    timezone_name = 'America/New_York'\n",
        "    time_column = \"pickup_datetime\"\n",
        "    ddf.index = pd.to_datetime(ddf[time_column])\n",
        "    #ddf.index = ddf.index.tz_convert(timezone_name)\n",
        "    ddf[\"dow\"] = ddf.index.weekday\n",
        "    ddf[\"hour\"] = ddf.index.hour\n",
        "    ddf[\"month\"] = ddf.index.month\n",
        "    ddf[\"year\"] = ddf.index.year\n",
        "    return ddf.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4qP_G40gaX6"
      },
      "source": [
        "ddf = extract_time_features(ddf.compute())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAxBjYaCziQc"
      },
      "source": [
        "ddf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQlZJuvfkHmx"
      },
      "source": [
        "#### Exercise 5: a.) Plot the taxi trip by hour of the day\n",
        "\n",
        "* Partition the data into segments using `dask.from_pandas()`\n",
        "\n",
        "* Plot the taxi trip for hour of the day. **Hint:** [sns.catplot](https://seaborn.pydata.org/generated/seaborn.catplot.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcDhog9ntzYn"
      },
      "source": [
        "ddf = dd.from_pandas(ddf, npartitions=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r06GIu7AuZ8N"
      },
      "source": [
        "type(ddf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3GzEYwzgiwq"
      },
      "source": [
        "# taxi trip repartition by hour of the day\n",
        "\n",
        "sns.catplot(x=\"hour\", kind=\"count\", palette=\"icefire\", data=ddf.compute(), height=5, aspect=3);\n",
        "sns.despine()\n",
        "plt.title('Hour of Day');\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjSKhr4HkNL3"
      },
      "source": [
        "#### Exercise 5: b.) Plot the taxi trip repartition by day of the week (dow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf3fe9hnRFnL"
      },
      "source": [
        "# taxi trip repartition by day of the week\n",
        "\n",
        "sns.catplot(x=\"dow\", kind=\"count\", palette=\"icefire\", data=ddf.compute(), height=5, aspect=3);\n",
        "sns.despine()\n",
        "plt.title('Day of Week');\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez8XDkvXkSr7"
      },
      "source": [
        "#### Exercise 6: a.) Draw a plot between the target variable and passenger count and analyze it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATLNkBHqYrG_"
      },
      "source": [
        "#passenger count feature\n",
        "\n",
        "sns.catplot(x=\"passenger_count\", y=\"fare_amount\", palette=\"icefire\", data=ddf.compute(), kind=\"bar\", aspect=3)\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pGGhg1rkXl3"
      },
      "source": [
        "#### Exercise 6: b.) Draw a plot between the target variable and hour and analyze it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DVhX3JZYytp"
      },
      "source": [
        "#fare amount by hour\n",
        "\n",
        "sns.catplot(x=\"hour\", y=\"fare_amount\", palette=\"icefire\", data=ddf.compute(), kind=\"bar\", aspect=3)\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnhM0X0MkgOx"
      },
      "source": [
        "#### Exercise 7: Compute the Haversine distance between samples\n",
        "\n",
        "* Convert the latitude and longitude co-rodinates to radians\n",
        "\n",
        "* Calculate the Haversine distance\n",
        "\n",
        "  **Hint:** [haversine_distances](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.haversine_distances.html)\n",
        "\n",
        "* Add the \"distance\" feature to the dataset and plot its distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4oLk2DtR-kP"
      },
      "source": [
        "# Distance feature (given formula)\n",
        "\n",
        "def haversine_distance(ddf,\n",
        "                       start_lat=\"start_lat\",\n",
        "                       start_lon=\"start_lon\",\n",
        "                       end_lat=\"end_lat\",\n",
        "                       end_lon=\"end_lon\"):\n",
        "    \n",
        "    # Calculate the great circle distance between two points \n",
        "    #on the earth (specified in decimal degrees).\n",
        "       \n",
        "    # Vectorized version of the haversine distance for pandas df\n",
        "    #Computes distance in kms\n",
        "    \n",
        "    lat_1_rad, lon_1_rad = np.radians(ddf[start_lat].astype(float)), np.radians(ddf[start_lon].astype(float))\n",
        "    lat_2_rad, lon_2_rad = np.radians(ddf[end_lat].astype(float)), np.radians(ddf[end_lon].astype(float))\n",
        "    dlon = lon_2_rad - lon_1_rad\n",
        "    dlat = lat_2_rad - lat_1_rad\n",
        "\n",
        "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat_1_rad) * np.cos(lat_2_rad) * np.sin(dlon / 2.0) ** 2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    haversine_distance = 6371 * c\n",
        "    return haversine_distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WGnk96MsrFI"
      },
      "source": [
        "%%time\n",
        "ddf[\"distance\"] = haversine_distance(ddf, \n",
        "                                     start_lat=\"pickup_latitude\", start_lon=\"pickup_longitude\",\n",
        "                                     end_lat=\"dropoff_latitude\", end_lon=\"dropoff_longitude\"\n",
        "                                     )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaKyX4pQYeNF"
      },
      "source": [
        "ddf.distance.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RHj-NePYi3y"
      },
      "source": [
        "%matplotlib inline\n",
        "plot_dist(series=ddf[ddf.distance<50].distance, title = \"Distance distribution\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEm1VCEhkmxy"
      },
      "source": [
        "### Correlation between distance and fare amount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8C5jkzcZOxO"
      },
      "source": [
        "# Correlation between fare_amount and distance\n",
        "\n",
        "sns.scatterplot(x=\"distance\", y=\"fare_amount\", palette=\"icefire\",data=ddf[ddf.distance < 80].compute().sample(10000))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI_BrhbAksa4"
      },
      "source": [
        "### Preparing dataset for model implementation\n",
        "\n",
        "**Note:** For the above modified dataset, perform the initial preprocessing steps before applying the modelling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBdsM-ue0PAU"
      },
      "source": [
        "# Read the dataset to prepare for training\n",
        "\n",
        "data_train = ddf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxy-7gBSRWGP"
      },
      "source": [
        "### Removing outliers from training set Based on Coordinates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rJQ5ecOk_Q8"
      },
      "source": [
        "#### Exercise 8: Remove the outliers using the given latitude and longitude features from the dataset. We need to analyze the data of taxi within New York City.\n",
        "\n",
        "**Hint:** Given the co-ordinates of New York city are Latitude: 40.7128° and Longitude: -74.0060°. You can include the pickup and drop off points such that there left and right value mean will be the given co-ordinate value. \n",
        "\n",
        "Also, choose nearest extreme values.\n",
        "\n",
        "Use `.between()` and pass left and right value attributes accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsqHSsooRi4V"
      },
      "source": [
        "%%time\n",
        "data_train = data_train[data_train[\"pickup_latitude\"].between(left = 40, right = 42 )]\n",
        "data_train = data_train[data_train[\"pickup_longitude\"].between(left = -74.3, right = -72.9 )]\n",
        "data_train = data_train[data_train[\"dropoff_latitude\"].between(left = 40, right = 42 )]\n",
        "data_train = data_train[data_train[\"dropoff_longitude\"].between(left = -74, right = -72.9 )]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhjCIcP4z6HM"
      },
      "source": [
        "%%time\n",
        "data_train[\"distance\"] = haversine_distance(data_train, \n",
        "                                      start_lat=\"pickup_latitude\", start_lon=\"pickup_longitude\",\n",
        "                                      end_lat=\"dropoff_latitude\", end_lon=\"dropoff_longitude\"\n",
        "                                     )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVKVLO_wz_yO"
      },
      "source": [
        "data_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0wKLJpOlGX2"
      },
      "source": [
        "#### Exercise 9: Divide the data into train and test splits with X as feature variables and y as target variable\n",
        "\n",
        "* Divide data into train test split with 70-30 ratio, Hint: `train_test_split()`\n",
        "\n",
        "* As dask functions operate lazily so, before calling `.fit()` function, call the dask dataframe with `.compute()`.\n",
        "* Convert X_train and y_train into array using `.values` as [dask's](https://ml.dask.org/modules/api.html) `.fit()` function takes array as attribute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3asw71jH1C7V"
      },
      "source": [
        "X = data_train.drop([\"fare_amount\", \"pickup_datetime\"], axis=1)\n",
        "y = data_train[[\"fare_amount\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhvvQ7jdg-4I"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAorNHLaNauK"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rvbe9ZtUoMp"
      },
      "source": [
        "type(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5_q4A_oOPBD"
      },
      "source": [
        "X_train = X_train.compute()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be5xWyYcOS36"
      },
      "source": [
        "y_train = y_train.compute()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb4qVD4GgqhJ"
      },
      "source": [
        "#fit the model\n",
        "lr = LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AQ8kJ-K0HCM"
      },
      "source": [
        "%%time\n",
        "lr.fit(X_train.values, y_train.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZr9OMdElQcb"
      },
      "source": [
        "#### Exercise 10: Predict the test data and calculate the mean squared error and r2 score.\n",
        "\n",
        "**Hint:** Remember to call `.compute()` function as dask functions operate lazily and convert the dask dataframe to `.values` (Array type) as suggested in above exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqGNMROAWZgm"
      },
      "source": [
        "%%time\n",
        "X_test = X_test.compute()\n",
        "y_pred = lr.predict(X_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdRoc9cv2E2-"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHDebnxC1LCG"
      },
      "source": [
        "y_test = y_test.to_dask_array(lengths=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-iLrP4h2uDC"
      },
      "source": [
        "y_test = y_test.reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4ImLCty2-xP"
      },
      "source": [
        "y_test.compute()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_FetEGcW8_M"
      },
      "source": [
        "# Mean squared error\n",
        "%%time\n",
        "mean_squared_error(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDEKGa5Q3Xla"
      },
      "source": [
        "# R2_Score\n",
        "%%time\n",
        "r2_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgxf18oYRAMV"
      },
      "source": [
        "### Report Analysis\n",
        "* Discuss the pros and cons of using dask\n",
        "* Discuss the EDA insights\n",
        "\n"
      ]
    }
  ]
}