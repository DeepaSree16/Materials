# CFU

## Question 1

The -------------- is the metrics used for finding the correctness and accuracy of the model used for Classification problem where the output can be of two or more types of classes.

1. Precision
2. Confusion matrix
3. Recall

> Second option is correct

## Question 2

Which of the following is correct about False Positives?

1. The total number of inaccurate predictions that were “positive”
2. The total number of accurate predictions that were “positive”
3. The total number of inaccurate predictions that were “Negative”

> First option is correct

## Question 3

ROC curve is very near to x=y line. The diagonal line. What does that indicate?

1. Model is not good. Needs improvement. Should not be used for predictions
2. Model is good. Needs no improvement. Should go ahead with predictions
3. There is no significance of shape of ROC curve. It is the ROC tangent slope that gives us the idea on model

> First option is correct

## Question 4

--------------- in classification problems is the number of correct predictions made by the model over all kinds predictions made.

1. Recall
2. Precision
3. Accuracy

> Third option is correct

## Question 5

We have a classification problem where we are predicting whether a person is having cancer (0) or not (1).

--------------- is a measure that tells us what proportion of patients that we diagnosed as having cancer, actually had cancer

1. Accuracy
2. Recall
3. Precision

> Third option is correct

## Question 6

We have a classification problem where we are predicting whether a person is having cancer (0) or not (1).

---------------- is a measure that tells us what proportion of patients that did NOT have cancer, were predicted by the model as non-cancerous.

1. Precision
2. Specificity
3. Recall

> Second option is correct

## Question 7

There models with AUC=0.9; AUC=0.75; AUC=0.5 ; How to infer these three results

1. 0.9 is a Bad fit; 0.75 is a moderate fit ; 0.5 is a Good fit
2. AUC has no impact on model fitness
3. 0.9 is a Good fit; 0.75 is a moderate fit ; 0.5 is a Bad fit

> Third option is correct

## Question 8

Each eigenvector has a corresponding eigenvalue

1. TRUE
2. FALSE

> First option is correct

## Question 9

----------------- should never be used as a measure when the target variable classes in the data are a majority of one class.

1. Accuracy
2. F1-Score
3. None of the above

> First option is correct

## Question 10

Choose the most descriptive statement from the following.

1. Precision depends on number of classes in the sample
2. Precision decreases with increasing number of classes
3. Precision increases initially with k but will depend on class-size if k becomes very large.

> Third option is correct

## Question 11

Which of the following is correct about True Positives?

1. The total number of accurate predictions that were “positive"
2. The total number of inaccurate predictions that were “positive"
3. The total number of accurate predictions that were “Negative"

> First option is correct

## Question 12

------------- is a good measure when the target variable classes in the data are nearly balanced.

1. Accuracy
2. Precision
3. Recall

> First option is correct

## Question 13

We have a classification problem where we are predicting whether a person is having cancer (0) or not (1).

--------------- is a measure that tells us what proportion of patients that actually had cancer was diagnosed by the algorithm as having cancer.

1. Accuracy
2. Recall 
3. Specificity

> Second option is correct

## Question 14

Recall gives us information about a classifier’s performance with respect to false negatives (how many did we miss), while precision gives us information about its performance with respect to false positives (how many did we caught)

1. TRUE
2. FALSE 

>  First option is correct

## Question 15

When do we consider sensitivity and specificity instead of overall accuracy?

1. When accuracy is impossible to compute
2. When the output is binary class
3. When individual class accuracy is important than overall accuracy

> Third option is correct

## Question 16

------------------ works by penalising the false classifications

1. Logarithmic Loss
2. F1-Score
3. None of the above

> First option is correct

## Question 17

Higher the Precision & Recall higher the ------------------

1. ROC-AUC
2. F1 score
3. None of the above

> Second option is correct

## Question 18

How is ROC curve created ?

1. False positive rate on X-axis and True positive rate on Y- axis for all possible threshold values
2. False positive rate on X-axis and True positive rate on Y- axis for a threshold value of 0.5
3. False positive rate on X-axis R-Squared on Y-axis

> First option is correct

## Question 19

Which of the following are the limitations of Eigen Faces?

1. Proper centered face is required for training/testing.
2. The algorithm is sensitive to lightining, shadows and also scale of face in the image 
3. Both A and B

> Third option is correct

## Question 20

---------------- gives us a matrix as output and describes the complete performance of the model

1. Accuracy
2. Confusion Matrix
3. F1-Score

> Second option is correct

## Question 21

High entropy means that the partitions in classification are

1. pure
2. not pure
3. none of the above

> Second option is correct

## Question 22

What are the axes of an ROC curve?

1. Vertical axis: % of true negatives; Horizontal axis: % of false negatives
2. Vertical axis: % of false negatives; Horizontal axis: % of false positives
3. Vertical axis: % of true positives; Horizontal axis: % of false positives

> Third option is correct

## Question 23

--------- is defined as the percentage of correct predictions for the test data


1. Accuracy
2. Precision
3. Recall

> First option is correct

## Question 24

--------------- is the proportion of actual positive cases which are correctly identified.


1. Precision
2. Accuracy
3. Sensitivity or Recall 

> Third option is correct

## Question 25

------------ is the most popular evaluation metric used in regression problems.


1. Precision
2. RMSE
3. F1-score 

> Second option is correct

## Question 26

An -------- is a two-dimensional depiction of classifier performance


1. ROC curve
2. RMSE
3. F1-score 

> First option is correct

## Question 27

An -------- is a two-dimensional depiction of classifier performance


1. ROC curve
2. RMSE
3. F1-score 

> First option is correct

## Question 28

---------- is scale-invariant which measures how well predictions are ranked, rather than their absolute values.



1. ROC curve
2. RMSE
3. AUC

> Third option is correct

## Question 29

 ---------- and ---------- are two popular metrics mostly used in medical and biology related fields,



1. Sensitivity and specificity
2. F1-score and Accuracy
3. None of the above

> First option is correct

## Question 30

 ------------ finds the average squared error between the predicted and actual values.



1. Root mean square error
2. Mean square error
3. Absolute error

> Second option is correct


