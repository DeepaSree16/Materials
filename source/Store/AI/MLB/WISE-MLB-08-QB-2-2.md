# CFU

## Question 1

Which of the  following is not an Ensemble method?

1. Decision Tree
2. Random Forest
3. Bagging and Boosting

> First option is correct

## Question 2

Which of the following statement is incorrect about Bagging ensemble method?

1. Bagging can reduce errors by reducing the variance term
2. Bagging is a method in ensemble for improving unstable estimation or classification schemes
3. Bagging method is used sequentially to reduce the bias of the combined model

> Third option is correct

## Question 3

Does Random forests partly operates as an Ensemble Method?

1. True
2. False

> First option is correct

## Question 4

What kind of analysis are not done in NLP?

1. Topic modelling 
2. Reinforcement learning
3. Sentiment analysis

> Second option is correct

## Question 5

Tokenisation and tokens 

1. Tokens are words with sentiment scores
2. Tokens are used in visualizations only, for analysis, we always use sentences
3. Tokens are basic atoms of analysis. They can be lemmas, stems, words

> Third option is correct

## Question 6

Which of these are enghlish stopwords?

1. stop, go, sad, happy
2. i, me, myself, about, into
3. beauty, words, amazing

> Second option is correct

## Question 7

Which of the following statement is correct about Bag of words?

1. keeps word order, disregards word multiplicity
2. disregards word order, keeps word multiplicity
3. disregards word order, disregards word multiplicity

> Second option is correct

## Question 8

What is the approach of basic algorithm for decision tree induction?

1. Greedy
2. Top Down
3. Step by step

> First option is correct

## Question 9

 Tree/Rule based classification algorithms generate __ rule to perform the classification.

1. if..then
2. while
3. do..while

> First option is correct

## Question 10

Which of the following is a correct way of importing nltk?

1. import nltk
2. from nltk
3. from import nltk

> First option is correct

## Question 11

Which of the following function in nltk package is used to tokenize the sentence?

1. sent_tokenize
2. tokenize
3. word_tokenize

> First option is correct

## Question 12

Which of the following techniques can be used for keyword normalization in NLP, the process of converting a keyword into its base form?

1. Lemmatization
2. Euclidean distance
3. N-grams

> First option is correct

## Question 13

Dissimilarity between words expressed using cosine similarity will have values significantly higher than 0.5

1. True
2. False

> First option is correct

## Question 14

Which of the below are NLP use cases?

1. Text summarization
2. Image recognization
3. Reinforcement learning

> First option is correct

## Question 15

In NLP, The process of converting a sentence or paragraph into tokens is referred to as Stemming

1. True
2. False

> Second option is correct

## Question 16

Which of the following statement is incorrect about random forest?

1. random forest builds multiple decision trees and merges them together to get a more accurate and stable prediction 
2. random forest is a supervised learning algorithm. The "forest" it builds, is an ensemble of decision trees, usually trained with the “bagging” method.
3. random forest have different hyper-parameters as decision tree or bagging classifier

> Third option is correct

## Question 17

Which of the following statement is incorrect about random forest?

1. Overfits the data
2. Effective method for estimating missing data and maintains accuracy when a large proportion of the data are missing.
3. Runs efficiently on large data bases

> First option is correct

## Question 18

Why would we use a random forest instead of a decision tree?

1. for lower training error
2. to better approximate posterior probabilities
3. to increase variance of a model

> Second option is correct

## Question 19

When the number of classes is large Gini index is not a good choice.

1. True 
2. False

> First option is correct

## Question 20

Which of the following statement is incorrect about ensemble methods?

1. Bagging, a Parallel ensemble method (stands for Bootstrap Aggregating), is a way to decrease the variance of the prediction model by generating additional data in the training stage.
2. Boosting is a sequential ensemble method that in general decreases the bias error and builds strong predictive models.
3. Ensemble methods divides into three groups

> Third option is correct

## Question 21

Which of the following statement is incorrect about random forest?

1. Random forest is an extension over boosting
2. Random forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble.
3. The difference between Random Forest algorithm and the decision tree algorithm is that in Random Forest, the process es of finding the root node and splitting the feature nodes will run randomly.

> First option is correct

## Question 22

Which of the following statement is incorrect about ensemble methods?

1. Ensemble methods, which combines several decision trees to produce better predictive performance than utilizing a single decision tree. 
2. The main principle behind the ensemble model is that a group of weak learners come together to form a strong learner.
3. Ensemble methods are used to increase the variance

> Third option is correct

## Question 23

Random forest is an extension over __

1. Bagging
2. Boosting

> First option is correct

## Question 24

NLP is concerned with the interactions between computers and human (natural) languages.

1. True
2. False

> First option is correct

## Question 25

Which of the following classifications would best suit the student
performance classification systems?

1. if..then analysis
2. clustering analysis
3. regression analysis

> First option is correct

## Question 26

Which of these problems does not fall into 3 main types of ML tasks: classification, regression, and clustering?

1. Identifying a topic of a live-chat with a customer 
2. Grouping news into topics
3. Predicting LTV (Life-Time Value) - the amount of money spent by a customer in a certain large period of time
4. Listing top products that a user is prone to buy (based on his/her click history)

> First option is correct

## Question 27

Maximal possible entropy is achieved when all states are equally probable (prove it yourself for a system with 2 states with probabilities  𝑝  and  1−𝑝 ). What's the maximal possible entropy of a system with N states? (here all logs are with base 2)

1. log N
2. -N log N
3. N log N

> First option is correct

## Question 28

Decision tree is computationally cheap for predictions but training the tree can be computationally expensive.

1. True
2. False

> First option is correct

## Question 29

Ensemble methods are meta-algorithms that combine several machine learning techniques into one predictive model

1. True
2. False

> First option is correct

## Question 30

In random forests, each tree in the ensemble is built from a different sample drawn with replacement (i.e. a bootstrap sample) from the training set

1. True
2. False

> First option is correct
