# CFP

## Question 1

How is a completely successful clustering defined?

1. The centroids constantly undergo a high degree of movement
2. The centroids are completely stabilized
3. The degree of centroid movement is slightly reduced

> Second option is correct

## Question 2

What does the “K” in K-Means Clustering signify?

1. The number of data points in each cluster
2. The number of nearest neighbours to the centroids
3. The number of arbitrary centroids used in the process

> Third option is correct

## Question 3

Which of the following statements is True regarding Unsupervised algorithms?

1. Inferences made by unsupervised algorithms are partially  based on known or labelled outcomes
2. Unsupervised algorithms infer based on known or labelled outcomes
3. Unsupervised algorithms infer without referring to known or labelled outcomes

> Third option is correct

## Question 4

K-means clustering aims to partition n observations into K clusters in which each observation belongs to the cluster with the closest _________

1. Mean
2. Median
3. Mode

> First option is correct

## Question 5

Assume, you want to cluster 7 observations into 3 clusters using a K-Means clustering algorithm. After the first iteration clusters, C1, C2, C3 have the following observations:
C1: {(2,2), (4,4), (6,6)}
C2: {(0,4), (4,0)}
C3: {(5,5), (9,9)}
What will be the cluster centroids if you want to proceed for a second iteration?

1. C1: (4,4), C2: (2,2), C3: (7,7)
2. C1: (6,6), C2: (4,4), C3: (9,9)
3. C1: (2,2), C2: (0,0), C3: (5,5)

> First option  is correct

## Question 6

Categorization of fruits, as red, yellow and green, based on weight is most likely which of the following?

1. Binary Classification
2. Multivariate Classification
3. Regression

> Second option is correct

## Question 7

When classifying using kNN, the majority label can be said to be the _______ of the k neighbouring labels.

1. Mean 
2. Median
3. Mode

> Third option is correct

## Question 8

Hierarchical clustering can be:

1. Done in top down way but not in a bottom up way
2. Can be done in either top down or bottom up way
3. The terms top down and bottom up are not relevant for clustering

> Second option is correct

## Question 9

Perfectly separated data will incur which of the following Gini scores?

1. 1
2. 0
3. 0.5

> Second option is correct

## Question 10

Which of the following measure is not effected by few outliers in the data?

1. Mean
2. Median
3. Standard deviation

> Second option is correct

## Question 11

K-Means algorithm is a ………… method

1. Supervised
2. Semi-supervised
3. Unsupervised

>Third option is correct

## Question 12

Which of the following statements is True regarding ‘Clusters’?

1. It is a collection of data points aggregated together because of certain similarities
2. Only the close-together data points undergo clustering
3. Data points that are far-off from each other are more likely to belong to the same cluster

>First option is correct

## Question 13

Is it possible to apply a logistic regression algorithm on a 3-class Classification problem?

1. Yes
2. No

> First option is correct

## Question 14

Is it possible that the assignment of samples to clusters does not change between successive iterations in K-Means clustering?

1. Yes
2. No

> First option is correct

## Question 15

Arrange the following statements about K-means Clustering algorithm in their correct order:

A. Divide the training samples into K non-empty clusters
B. Generate a centriod for new cluster formed
C. Identify the cluster centroids (mean points) 
D. Compute the distances for each sample and allot samples to the cluster where the distance from the centroid is minimum
E. Assign each sample to a specific cluster
F. Repeat the process until the centroid position remains constant

1. A, E, B, C, D, F
2. A, B, C, D, E, F
3. A, C, E, D, B, F

>Third option is correct

## Question 16

Which of the following statements about K-Means clustering is FALSE?

1. It is an extensively used technique for data cluster analysis
2. Slight variations in the data can lead to high variance
3. It accounts for the possibility of irregular cluster shapes

> Third option is correct

## Question 17

How many clusters can a single data point belong to?

1. 1
2. 2
3. 3

> First option is correct

## Question 18

Which of the following is NOT a clustering Algorithm?

1. DBScan
2. Random Forests
3. Hierarchical Clustering 

> Second option is correct

## Question 19

Which of the following methods doesn’t necessarily improve the performance of the K-Means algorithm?

1. Improved feature selection
2. Normalization through feature transformation
3. Increasing the number of centroids

> Third option is correct

## Question 20

What is the goal of the k-Means Clustering algorithm?

1. To find the data, with the number of groups represented by the variable K.
2. To find groups in the data, with the number of groups represented by the variable K.
3. None of the above

> Second option is correct

## Question 21

Hierarchical clustering is a method which seeks to build a hierarchy of clusters.

1. True
2. False

> First option is correct

## Question 22

Which of the following best describes the k-Means clustering algorithm:

1. Assumes a set of centroids and Iteratively computes clusters using these centroids; then using these clusters, recomputes centroids till convergence
2. Assumes a set of clusters, and then computes their centroids; repeats the computation of clusters using these new centroids and so on till convergence.
3. Is a corollary to the k-NN algorithm

> First option is correct

## Question 23

K-Means clustering will:

1. always cluster the samples properly if given the right number of clusters as input
2. Will not at all work if the number of clusters given as input is wrong
3. mostly cluster properly but can end up with a poor result even when given right number of clusters

> Third option is correct

## Question 24

What is the major difference between k-means cluster analysis and decision trees

1. Decision trees are a special case of cluster analysis
2. Decision tree consider target variable separately, cluster analysis treats all the variables equally
3. None of the above

> Second option is correct

## Question 25

In order to decide which clusters should be combined (for agglomerative), or where a cluster should be split (for divisive), a measure of dissimilarity between sets of observations is re-
quired.

1. True
2. False

> First option is correct

## Question 26

--------------- is the collection of data objects which are similar to one another within the same group (class or category) and are different from the objects in the other clusters.

1. Cluster
2. Data
3. Dendogram

> First option is correct

## Question 27

Clustering allows us to find hidden relationship between the data points in the dataset.

1. TRUE
2. FALSE

> First option is correct

## Question 28

Hierarchical clustering cannot be visualized using dendrogram

1. TRUE
2. FALSE

> Second option is correct

## Question 29

How to measure closeness of points in Hierarchical Clustering?

1. Euclidean distance
2. Manhattan distance
3. Both A and B

> Third option is correct

## Question 30

---------------- makes the separation between two clusters and main goal is to maximize the distance between 2 clusters.

1. Inter-cluster Maximization
2. Inter-cluster Minimization
3. Intra-cluster Maximization

> First option is correct

