\documentclass{beamer}
\usetheme{Madrid}
\usepackage{amsmath}
\usepackage{ragged2e}


\title{Introduction to Central Limit Theorem}
\author{by Talentsprint Pvt.Ltd.}
\centering
\date{July 2020}

\begin{document}
\maketitle
\begin{frame}{Content}
	\begin{itemize}
		\item Standard Deviation
		\item Central Limit Theorem
		\item Law of Large Numbers
		\item Dice Example
		\item Impact on Machine Learning
		\item Significance Tests
		\item Confidence Intervals
	\end{itemize}
\end{frame}

\begin{frame}{Standard Deviation}
\begin{flushleft}
\textbf{What is Standard Deviation?} \\
\vspace{10pt}
	Standard deviation is the measure of dispersion, or how spread out values are, in a dataset. It’s represented by the sigma ($\sigma$) symbol and found by taking the square root of the variance. The variance is just the average of the squared differences from the mean. Unlike variance, standard deviation is measured using the same units as the data.
\vspace{10pt} \\
\textbf{How is Standard Deviation Used in Machine Learning?}\\
\vspace{10pt}
	Using this metric to calculate the variability of a population or sample is a crucial test of a machine learning model’s accuracy against real world data. In addition, standard deviation can be used to measure confidence in a model’s statistical conclusions.
\end{flushleft}
\end{frame}

\begin{frame}{Central Limit Theorem}
	\begin{itemize}
		\item The theorem states that as the size of the sample increases, the distribution of the mean across multiple samples will approximate a Gaussian distribution.
		\item We can imagine performing a trial and getting a result or an observation. We can repeat the trial again and get a new independent observation. Collected together, multiple observations represents a sample of observations.
		\begin{itemize}
			\item \textbf{Observation:} Result from one trial of an experiment.
			\item \textbf{Sample:} Group of results gathered from separate independent trials.
			\item \textbf{Population:} Space of all possible observations that could be seen from a trial.
		\end{itemize}
		\item If we calculate the mean of a sample, it will be an estimate of the mean of the population distribution. But, like any estimate, it will be wrong and will contain some error. If we draw multiple independent samples, and calculate their means, the distribution of those means will form a Gaussian distribution.
	\end{itemize}
\end{frame}

\begin{frame}{Contd..}
	\begin{itemize}
		\item It is important that each trial that results in an observation be independent and performed in the same way. This is to ensure that the sample is drawing from the same underlying population distribution. More formally, this expectation is referred to as independent and identically distributed, or iid.
		\item Firstly, the central limit theorem is impressive, especially as this will occur no matter the shape of the population distribution from which we are drawing samples. It demonstrates that the distribution of errors from estimating the population mean fit a distribution that the field of statistics knows a lot about.
		\item Secondly, this estimate of the Gaussian distribution will be more accurate as the size of the samples drawn from the population is increased. This means that if we use our knowledge of the Gaussian distribution in general to start making inferences about the means of samples drawn from a population, that these inferences will become more useful as we increase our sample size.
	\end{itemize}
\end{frame}

\begin{frame}{Law of Large Numbers}
	\begin{itemize}
		\item The central limit theorem is often confused with the law of large numbers. 
		\item The law of large numbers is another different theorem from statistics. It is simpler in that it states that as the size of a sample is increased, the more accurate of an estimate the sample mean will be of the population mean.
		\item The central limit theorem does not state anything about a single sample mean; instead, it is broader and states something about the shape or the distribution of sample means.
		\item The law of large numbers is intuitive. It is why we think that collecting more data will lead to a more representative sample of observations from the domain. The theorem supports this intuition.
		\item The central limit theorem is not intuitive. Instead, it is a finding that we can exploit in order to make claims about sample means.
	\end{itemize}
\end{frame}

\begin{frame}{Dice Example}
	\begin{itemize}
		\item We can make the central limit theorem concrete with a worked example involving the rolling of die.
		\item Remember that a die is a cube with a different number on each side from 1-to-6. Each number has a 1-in-6 likelihood to turn up from a roll. The distribution of the numbers that turn up from a dice roll is uniform given the equal likelihood.
	\end{itemize}
\end{frame}

\begin{frame}{Impact on Machine Learning}
	\begin{flushleft}
			The central limit theorem has important implications in applied machine learning.
\vspace{10pt}

The theorem does inform the solution to linear algorithms such as linear regression, but not exotic methods like artificial neural networks that are solved using numerical optimization methods. Instead, we must use experiments to observe and record the behavior of the algorithms and use statistical methods to interpret their results.
\vspace{10pt}

Let’s look at two important examples.
		\begin{itemize}
			\item Significance Tests
			\item Confidence Intervals
		\end{itemize}
	\end{flushleft}
\end{frame}

\begin{frame}{Significance Tests}
	\begin{itemize}
		\item In order to make inferences about the skill of a model compared to the skill of another model, we must use tools such as statistical significance tests.
		\item These tools estimate the likelihood that the two samples of model skill scores were drawn from the same or a different unknown underlying distribution of model skill scores. If it looks like the samples were drawn from the same population, then no difference between the models skill is assumed, and any actual differences are due to statistical noise.
		\item The ability to make inference claims like this is due to the central limit theorem and our knowledge of the Gaussian distribution and how likely the two sample means are to be a part of the same Gaussian distribution of sample means.
	\end{itemize}
\end{frame}
\begin{frame}{Confidence Intervals}
	\begin{itemize}
		\item Once we have trained a final model, we may wish to make an inference about how skillful the model is expected to be in practice.
		\item The presentation of this uncertainty is called a confidence interval.
		\item We can develop multiple independent (or close to independent) evaluations of a model accuracy to result in a population of candidate skill estimates. The mean of these skill estimates will be an estimate (with error) of the true underlying estimate of the model skill on the problem.
		\item With knowledge that the sample mean will be a part of a Gaussian distribution from the central limit theorem, we can use knowledge of the Gaussian distribution to estimate the likelihood of the sample mean based on the sample size and calculate an interval of desired confidence around the skill of the model.
	\end{itemize}
\end{frame}

\begin{frame}
\huge{\centerline{The End}}
\end{frame}
\end{document}