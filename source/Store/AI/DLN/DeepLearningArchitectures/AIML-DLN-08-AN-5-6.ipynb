{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-DLN-08-AN-5-6.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"IahDH5fXZnZu"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"y2QTUhNJcbr2"},"source":["###Not for Grading"]},{"cell_type":"markdown","metadata":{"id":"f3xfgSow_UcS"},"source":["## What layers do?"]},{"cell_type":"code","metadata":{"id":"5cr6zpXF_UsL","cellView":"form"},"source":["#@title Case Study Walkthrough\n","#@markdown What layers do?\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"320\" height=\"240\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_b7_hyd/preview_videos/what_layers_do.mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OB79RK6kZprN"},"source":["## Implementing an MLP to understand the Effect of Layers"]},{"cell_type":"markdown","metadata":{"id":"aVR7NaXjZ0bI"},"source":["The objective of the experient to understand how the changes in layers of MLP affect the output."]},{"cell_type":"markdown","metadata":{"id":"MUOzHIu4RmPF"},"source":["## Importing required packages "]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-11-25T11:43:14.125783Z","start_time":"2018-11-25T11:43:14.121198Z"},"id":"zF4UyDEtVwa5"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.datasets import make_circles \n","from sklearn.neural_network import MLPClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EFxigadoz8o8"},"source":["## Generate make_circles data"]},{"cell_type":"code","metadata":{"id":"ZNVxAfRdz75l"},"source":["datasets = [make_circles(noise=0.3, random_state=0,factor=0.3)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hUsbPfNCVwbB"},"source":["## Define MLP with different number of hidden layers"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-11-25T11:47:08.809548Z","start_time":"2018-11-25T11:47:08.801416Z"},"id":"115KAF1AVwbE"},"source":["names = [\"MLP31\",\"MLP331\", \"MLP3331\"]\n","classifiers = [ MLPClassifier(solver='lbfgs', activation='logistic', hidden_layer_sizes=(1), random_state=1)\n","               ,MLPClassifier(solver='lbfgs', activation='logistic', hidden_layer_sizes=(3,1), random_state=1)\n","               ,MLPClassifier(solver='lbfgs', activation='logistic', hidden_layer_sizes=(3, 3,1), random_state=42)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fJw0PyK1RsoQ"},"source":["## Visualizing the MLP with different number of hidden layers"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-11-25T11:50:18.056230Z","start_time":"2018-11-25T11:50:16.663194Z"},"id":"MavkpFnrVwbJ"},"source":["figure = plt.figure(figsize=(50, 10))\n","i = 1\n","h = .02  # step size in the mesh\n","# iterate over datasets\n","for ds_cnt, ds in enumerate(datasets):\n","    # preprocess dataset, split into training and test part\n","    X, y = ds\n","    X = StandardScaler().fit_transform(X)\n","    X_train, X_test, y_train, y_test = \\\n","        train_test_split(X, y, test_size=.4, random_state=42)\n","\n","    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n","    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n","                         np.arange(y_min, y_max, h))\n","\n","    # just plot the dataset first\n","    cm = plt.cm.RdBu\n","    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n","    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n","    if ds_cnt == 0:\n","        ax.set_title(\"Input data\")\n","    # Plot the training points\n","    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n","               edgecolors='k',s=200)\n","    # Plot the testing points\n","    ax.set_xlim(xx.min(), xx.max())\n","    ax.set_ylim(yy.min(), yy.max())\n","    ax.set_xticks(())\n","    ax.set_yticks(())\n","    i += 1\n","\n","    # iterate over classifiers\n","    for name, clf in zip(names, classifiers):\n","        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n","        clf.fit(X_train, y_train)\n","        score = clf.score(X_test, y_test)\n","\n","        # Plot the decision boundary. For that, we will assign a color to each\n","        # point in the mesh [x_min, x_max]x[y_min, y_max].\n","        if hasattr(clf, \"decision_function\"):\n","            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n","        else:\n","            Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]) #[:, 1]\n","        # Put the result into a color plot\n","        Z = Z.reshape(xx.shape)\n","        ax.contourf(xx, yy, Z, cmap=plt.cm.Blues_r)\n","\n","        # Plot the training points\n","        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n","                   edgecolors='k', s=200)\n","        # Plot the testing points\n","        ax.set_xlim(xx.min(), xx.max())\n","        ax.set_ylim(yy.min(), yy.max())\n","        ax.set_xticks(())\n","        ax.set_yticks(())\n","        if ds_cnt == 0:\n","            ax.set_title(name)\n","        i += 1\n","plt.savefig('Different_arch_mlp_moons.png')\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t9JkFJ7_ZkTY"},"source":["We can visualize that different hidden layers giving different decision boundaries from the above image. "]}]}