{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-DLN-16-AN-1-1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"1grJJ2H_1igl"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"FNvZkWe1fCyC"},"source":["### Not for grading"]},{"cell_type":"markdown","metadata":{"id":"PWYOSAbmfNnl"},"source":["## Sentence Level Author identification using RNN"]},{"cell_type":"code","metadata":{"id":"_p6Kp79tfFzp","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":261},"executionInfo":{"status":"ok","timestamp":1631080828110,"user_tz":-330,"elapsed":18,"user":{"displayName":"AIML Support","photoUrl":"","userId":"10944637975474083227"}},"outputId":"42483a8d-f024-42aa-9f46-6297a6c6f5da"},"source":["#@title Case Study Walkthrough\n","#@markdown  Sentence Level Author identification using RNN\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"320\" height=\"240\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_b7_hyd/preview_videos/sentence_level_author_identification_using_rnn.mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<video width=\"320\" height=\"240\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_b7_hyd/preview_videos/sentence_level_author_identification_using_rnn.mp4\">\n","</video>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["! wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week12/Exp2/test.csv\n","! wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week12/Exp2/train.csv\n","! wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week12/Exp2/val.csv\n","! wget https://cdn.talentsprint.com/aiml/CaseStudies/Sentence_level_rnn_trained_0.66.pt\n","    "],"metadata":{"id":"Qt0oJvvVo9R5"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E8NHuTToEBMQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631080846964,"user_tz":-330,"elapsed":23,"user":{"displayName":"AIML Support","photoUrl":"","userId":"10944637975474083227"}},"outputId":"f1eff2f2-75f2-417a-b23e-6df336673f51"},"source":["ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34msample_data\u001b[0m/                        train.csv\n","Sentence_level_rnn_trained_0.66.pt  U4W19_CS_Author_identification_RNN.ipynb\n","test.csv                            val.csv\n"]}]},{"cell_type":"markdown","metadata":{"id":"r1M4fVUJ42QM"},"source":["###Importing required packages"]},{"cell_type":"code","metadata":{"id":"etmSif-S1X17"},"source":["import pandas as pd\n","import numpy as np\n","import gensim\n","import re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u_bmukEj1X2B"},"source":["from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","from nltk.tokenize import word_tokenize"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eYZFTgbaEICU"},"source":["### Assign numbers to the labels using dictionary data structure\n"]},{"cell_type":"code","metadata":{"id":"X5NGCnLF1X2I"},"source":["label = {'EAP':0, 'HPL':1, 'MWS':2}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WGhNQ7GtEMb_"},"source":["### Load the train data"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"OCf-sHhW1X2N"},"source":["train_data = pd.read_csv('train.csv', encoding='latin1')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CXdRakQVEQSW","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1631080848773,"user_tz":-330,"elapsed":93,"user":{"displayName":"AIML Support","photoUrl":"","userId":"10944637975474083227"}},"outputId":"46a06fc6-2c48-4e51-cfac-894a7ef1a29f"},"source":["train_data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>author</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id26305</td>\n","      <td>This process, however, afforded me no means of...</td>\n","      <td>EAP</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id17569</td>\n","      <td>It never once occurred to me that the fumbling...</td>\n","      <td>HPL</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id11008</td>\n","      <td>In his left hand was a gold snuff box, from wh...</td>\n","      <td>EAP</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id27763</td>\n","      <td>How lovely is spring As we looked from Windsor...</td>\n","      <td>MWS</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id12958</td>\n","      <td>Finding nothing else, not even gold, the Super...</td>\n","      <td>HPL</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id                                               text author\n","0  id26305  This process, however, afforded me no means of...    EAP\n","1  id17569  It never once occurred to me that the fumbling...    HPL\n","2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n","3  id27763  How lovely is spring As we looked from Windsor...    MWS\n","4  id12958  Finding nothing else, not even gold, the Super...    HPL"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"mqZZcmQnETwT"},"source":["### Collect the sentences from the train data"]},{"cell_type":"code","metadata":{"id":"hf1tFsFh1X2a"},"source":["sentences = train_data[['text','author']].values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fr2PlHEwEbGB"},"source":["### Load the test data"]},{"cell_type":"code","metadata":{"id":"gwMo0MEd1X2e"},"source":["test_data = pd.read_csv('test.csv', encoding='latin1')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"deZYCk6aEd-N"},"source":["### Collect the sentences from the test data"]},{"cell_type":"code","metadata":{"id":"eW-2g2eq1X2i"},"source":["test_sentences = test_data[['text']].values.flatten()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wnk8gb98EqlG"},"source":["### Define the class for stemming / preprocessing sentences"]},{"cell_type":"code","metadata":{"id":"iG7fStmK1X2n"},"source":["#stopWords = pd.read_csv('stopwords.txt').values\n","\n","class MySentences(object):\n","    def __init__(self, fnamelist):\n","        self.fnamelist = fnamelist\n","        # Creating a set of vocabulary\n","        self.vocabulary = set([])\n","        #self.sentences = self.train_data.text.values\n","        #self.labels = [self.train_data.text.values.flatten()\n","\n","    def __iter__(self):\n","        for fname in self.fnamelist:\n","            self.data = pd.read_csv(fname, encoding='latin1')\n","            self.sentences = self.data.text.values\n","            for line in self.sentences:\n","                words = re.findall(r'(\\b[A-Za-z][a-z]{2,15}\\b)', line)\n","                # Stemming a word.\n","                words = [ word.lower() for word in words]\n","                for word in words:\n","                    self.vocabulary.add(word)\n","                yield words"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F28u3Qf-1X2s"},"source":["sentences = MySentences(['train.csv', 'val.csv','test.csv']) # a memory-friendly iterator\n","# for i in sentences:\n","#     print(i)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4db73s1vEx9f"},"source":["### Use gensims.model.Word2Vec to get vectors for the sentences and save the model as a .bin file"]},{"cell_type":"code","metadata":{"id":"HB2Dkfx1EyWU"},"source":["model = gensim.models.Word2Vec(sentences, min_count=1)\n","model.save(\"AuthID2Vec.bin\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qAS2OupcCmfJ"},"source":["### Count the corpus"]},{"cell_type":"code","metadata":{"id":"57bY-4-y1X2z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631080863616,"user_tz":-330,"elapsed":18,"user":{"displayName":"AIML Support","photoUrl":"","userId":"10944637975474083227"}},"outputId":"eee7e495-0d74-4083-d77f-1af36d1d6fc0"},"source":["model.corpus_count"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["27971"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"68GVEOF4DFBH"},"source":["### Import required torch packages"]},{"cell_type":"code","metadata":{"id":"b-2kzWnd1X28"},"source":["import torch \n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import torchvision.transforms as transforms\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vX3rvZsaDNIX"},"source":["### Define custom dataset loader"]},{"cell_type":"code","metadata":{"id":"Pr4pVFLD1X3B"},"source":["class CustomDataset(torch.utils.data.Dataset):    ### custom data loader\n","    \n","    def __init__(self, data_file_path,  train=True):\n","        self.data_file_path = data_file_path\n","        self.train = train\n","        self.data = pd.read_csv(data_file_path, encoding='latin1')\n","        self.ids = self.data.id.values\n","        self.sentences = self.data.text.values\n","        if self.train:\n","            self.label_dict = {'EAP':0, 'HPL':1, 'MWS':2}\n","            self.labels = [self.label_dict[i] for i in self.data.author.values]\n","        \n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        sentence = self.sentences[index]\n","        if self.train:\n","            return self.sentences[index], self.labels[index]\n","        else:\n","            return self.sentences[index], self.ids[index]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ukaUuopoDaoa"},"source":["### Set the batch size\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"DexAnfor1X3G"},"source":["batch_size = 16"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3qJyX1KrDfob"},"source":["### Use the custom dataset loader to load the .csv files for train, val and test data into batches"]},{"cell_type":"code","metadata":{"id":"G9xuancg1X3K"},"source":["# You can then use the prebuilt data loader. \n","train_set = CustomDataset(\"train.csv\", train=True)\n","val_set = CustomDataset(\"val.csv\", train=True)\n","test_set = CustomDataset(\"test.csv\", train=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4BfSI7MM1X3Q"},"source":["trainloader = torch.utils.data.DataLoader(train_set,batch_size=batch_size, shuffle = True)\n","valloader = torch.utils.data.DataLoader(val_set,batch_size=batch_size, shuffle = True)\n","testloader = torch.utils.data.DataLoader(test_set,batch_size=batch_size, shuffle = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"estRiy5F1X3Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631080868212,"user_tz":-330,"elapsed":43,"user":{"displayName":"AIML Support","photoUrl":"","userId":"10944637975474083227"}},"outputId":"4d538341-3f14-4903-afaf-73776143c6d5"},"source":["for X,y in trainloader:\n","    print(X)\n","    print(y.size())\n","    break"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["('Ay, ay,\" continued he, observing my face expressive of suffering, \"M.', 'Such was the maniac language of her enthusiasm.', 'It was small relief to him that our discipline should gain us success in such a conflict; while plague still hovered to equalize the conqueror and the conquered, it was not victory that he desired, but bloodless peace.', 'The inhabitants of the island, and of the fort, thronged out, of course, to see the balloon; but it was with the greatest difficulty that any one could be made to credit the actual voyage the crossing of the Atlantic.', 'It is indeed demonstrable that every such impulse given the air, must, in the end, impress every individual thing that exists within the universe; and the being of infinite understanding the being whom we have imagined might trace the remote undulations of the impulse trace them upward and onward in their influences upon all particles of an matter upward and onward for ever in their modifications of old forms or, in other words, in their creation of new until he found them reflected unimpressive at last back from the throne of the Godhead.', 'I knew my silence disquieted them, and I well remembered the words of my father: \"I know that while you are pleased with yourself you will think of us with affection, and we shall hear regularly from you.', 'After this there was a dead stillness, and I heard nothing more, upon either occasion, until nearly daybreak; unless, perhaps, I may mention a low sobbing, or murmuring sound, so very much suppressed as to be nearly inaudible if, indeed, the whole of this latter noise were not rather produced by my own imagination.', 'We talked often in the night, and in the day, when I chiselled busts of him and carved miniature heads in ivory to immortalise his different expressions.', 'The summer months passed while I was thus engaged, heart and soul, in one pursuit.', 'Just how fully the pursuit was organised and indeed, just what its purpose might be I could form no idea.', 'He says all hope is dead to him, and I know that it is dead to me, so we are both equally fitted for death.', 'Wrap the drawing around it, and try the experiment again.\"', 'she of the diminutive head and the gilded hair?', 'He endeavoured to soothe me as a nurse does a child and reverted to my tale as the effects of delirium.', 'We examined, first, the furniture of each apartment.', 'Who who knoweth the mysteries of the will with its vigor?')\n","torch.Size([16])\n"]}]},{"cell_type":"markdown","metadata":{"id":"Xwo4Ee9TEECj"},"source":["### Load the saved gensim model which contains vectors for the sentences "]},{"cell_type":"code","metadata":{"id":"xjAKgBPf1X3h"},"source":["model_load = gensim.models.Word2Vec.load('AuthID2Vec.bin')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ezo9AATeERuS"},"source":["### Set the deivce to CUDA"]},{"cell_type":"code","metadata":{"id":"qPMZQTH9-qeX"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"djoP9716EasE"},"source":["### Creating the recurrent neural network"]},{"cell_type":"code","metadata":{"id":"AHzTsipX1X3l"},"source":["### Creating recurrent neural network\n","class RNN(nn.Module):\n","    \n","    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n","        super(RNN, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.gru = nn.GRU(input_size, hidden_size, n_layers)\n","        self.decoder = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.Softmax()\n","    \n","    def forward(self, input):\n","        outputs = []\n","        for sentence in input:\n","            hidden= self.init_hidden()\n","            word_embeddings = self.get_embedding(sentence)\n","            for word_embedding in word_embeddings:\n","                output, hidden = self.gru(word_embedding.unsqueeze(0).unsqueeze(0), hidden)\n","            try:\n","                #print(output.size())\n","                outputs.append(output)\n","            except:\n","                outputs.append(torch.rand(1,1,20))\n","                continue\n","        outputs = torch.cat(outputs)\n","        outputs = self.softmax(self.decoder(outputs))\n","        return outputs\n","\n","    def init_hidden(self):\n","        return torch.zeros(self.n_layers, 1, self.hidden_size)\n","    \n","    def get_embedding(self, sentence):\n","        #print(len(sentence))\n","        #sentence_wt = word_tokenize(sentence.lower())\n","        words = re.findall(r'(\\b[A-Za-z][a-z]{2,15}\\b)', sentence)\n","        words = [ word.lower() for word in words]\n","        embedding = []\n","        for word in words:\n","            #print(word)\n","            embedding.append(torch.tensor(model_load[word]))\n","        #print(embedding[0].size())\n","        return embedding"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fQlNF864TASm"},"source":["### Implement the RNN by setting up the required parameters"]},{"cell_type":"code","metadata":{"id":"BT0rfNtB1X3p"},"source":["rnn = RNN(100,20,3,n_layers=1) # Set the denfined RNN model with 100 input layers, 20 hidden layers and 3 output layers\n","lr = 0.001 # learning rate\n","optimizer = torch.optim.Adam(rnn.parameters(), lr=lr) # Set the optimizer \n","## Loss function\n","criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hvOVkn75Fm52"},"source":["### Train and test RNN model"]},{"cell_type":"markdown","metadata":{"id":"3uSh7o3YGyXX"},"source":["### This will take quite a lot of time"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"VR02e_J01X3s","colab":{"base_uri":"https://localhost:8080/"},"outputId":"334bec29-aa7e-4178-b4da-e414742cbd6a"},"source":["losses  = []\n","val_accuracy = 0\n","for j in range(100):\n","    i = 0\n","    correct_train = 0\n","    for X,y in trainloader:\n","        #print(index, end='\\r')\n","        output = rnn(X)\n","        optimizer.zero_grad()\n","        loss = criterion(output.squeeze(1),y)\n","        loss.backward()\n","        optimizer.step()\n","        losses.append(loss.item())\n","        _,predicted = torch.max(output.squeeze(1).data, 1)\n","        #print(predicted)\n","        correct_train += predicted.eq(y.data).cpu().sum().item()\n","        i=i+1\n","    print('Epoch: {}, Train Accuracy: {}, Average Loss: {}'.format(j, correct_train/(i*16), sum(losses)/len(losses)))\n","    correct_val = 0 \n","    for X,y in valloader:\n","        #print(index, end='\\r')\n","        output = rnn(X)\n","        _,predicted = torch.max(output.squeeze(1).data, 1)\n","        correct_val += predicted.eq(y.data).cpu().sum().item()\n","    if val_accuracy<correct_val/6580:\n","        val_accuracy = correct_val/6580\n","        torch.save(rnn.state_dict(), 'Sentence_level_rnn_trained_{:.2f}.pt'.format(val_accuracy))\n","    print('Epoch: {}, Validation Accuracy: {}'.format(j, correct_val/6580))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Train Accuracy: 0.4516451414514145, Average Loss: 1.0788897133694657\n","Epoch: 0, Validation Accuracy: 0.4857142857142857\n","Epoch: 1, Train Accuracy: 0.5349015990159902, Average Loss: 1.0665253377708561\n","Epoch: 1, Validation Accuracy: 0.5452887537993921\n","Epoch: 2, Train Accuracy: 0.5498923739237392, Average Loss: 1.0594833154519985\n","Epoch: 2, Validation Accuracy: 0.5562310030395137\n","Epoch: 3, Train Accuracy: 0.559040590405904, Average Loss: 1.0547626712811975\n","Epoch: 3, Validation Accuracy: 0.5680851063829787\n","Epoch: 4, Train Accuracy: 0.5665744157441575, Average Loss: 1.0515242544340764\n","Epoch: 4, Validation Accuracy: 0.5785714285714286\n","Epoch: 5, Train Accuracy: 0.5782595325953259, Average Loss: 1.0486958682683707\n","Epoch: 5, Validation Accuracy: 0.5844984802431611\n","Epoch: 6, Train Accuracy: 0.573570110701107, Average Loss: 1.0467121162893818\n","Epoch: 6, Validation Accuracy: 0.5764437689969605\n","Epoch: 7, Train Accuracy: 0.5851783517835178, Average Loss: 1.0450556893428606\n","Epoch: 7, Validation Accuracy: 0.5545592705167173\n","Epoch: 8, Train Accuracy: 0.5888683886838868, Average Loss: 1.0432957219624595\n","Epoch: 8, Validation Accuracy: 0.5851063829787234\n","Epoch: 9, Train Accuracy: 0.5954028290282903, Average Loss: 1.041764048940581\n","Epoch: 9, Validation Accuracy: 0.5899696048632219\n","Epoch: 10, Train Accuracy: 0.6040897908979089, Average Loss: 1.040466314158983\n","Epoch: 10, Validation Accuracy: 0.5928571428571429\n","Epoch: 11, Train Accuracy: 0.6064729397293973, Average Loss: 1.039252321224762\n","Epoch: 11, Validation Accuracy: 0.5919452887537994\n","Epoch: 12, Train Accuracy: 0.6140067650676507, Average Loss: 1.0380468281906436\n","Epoch: 12, Validation Accuracy: 0.5989361702127659\n","Epoch: 13, Train Accuracy: 0.6168511685116851, Average Loss: 1.0370274064956033\n","Epoch: 13, Validation Accuracy: 0.6104863221884499\n","Epoch: 14, Train Accuracy: 0.6203874538745388, Average Loss: 1.0360301248946118\n","Epoch: 14, Validation Accuracy: 0.6188449848024317\n","Epoch: 15, Train Accuracy: 0.621540590405904, Average Loss: 1.035101566738638\n","Epoch: 15, Validation Accuracy: 0.6069908814589665\n","Epoch: 16, Train Accuracy: 0.628920664206642, Average Loss: 1.0343086196263425\n","Epoch: 16, Validation Accuracy: 0.6066869300911855\n","Epoch: 17, Train Accuracy: 0.6180043050430505, Average Loss: 1.0335963892369742\n","Epoch: 17, Validation Accuracy: 0.6183890577507599\n","Epoch: 18, Train Accuracy: 0.6171586715867159, Average Loss: 1.0328646252600902\n","Epoch: 18, Validation Accuracy: 0.5870820668693009\n","Epoch: 19, Train Accuracy: 0.6245387453874539, Average Loss: 1.0321595207388257\n","Epoch: 19, Validation Accuracy: 0.6246200607902735\n","Epoch: 20, Train Accuracy: 0.6258456334563346, Average Loss: 1.0315190495991131\n","Epoch: 20, Validation Accuracy: 0.6180851063829788\n","Epoch: 21, Train Accuracy: 0.631150061500615, Average Loss: 1.0309536177533778\n","Epoch: 21, Validation Accuracy: 0.6155015197568389\n","Epoch: 22, Train Accuracy: 0.6293050430504306, Average Loss: 1.0304085799695157\n","Epoch: 22, Validation Accuracy: 0.6262917933130699\n","Epoch: 23, Train Accuracy: 0.6319188191881919, Average Loss: 1.029920050810966\n","Epoch: 23, Validation Accuracy: 0.6293313069908815\n","Epoch: 24, Train Accuracy: 0.6338407134071341, Average Loss: 1.0294135191138527\n","Epoch: 24, Validation Accuracy: 0.6247720364741641\n","Epoch: 25, Train Accuracy: 0.6326107011070111, Average Loss: 1.0289466230073436\n","Epoch: 25, Validation Accuracy: 0.6268996960486323\n","Epoch: 26, Train Accuracy: 0.6406057810578106, Average Loss: 1.0284881532819476\n","Epoch: 26, Validation Accuracy: 0.6015197568389058\n","Epoch: 27, Train Accuracy: 0.6412976629766297, Average Loss: 1.0280690048563523\n","Epoch: 27, Validation Accuracy: 0.6276595744680851\n","Epoch: 28, Train Accuracy: 0.6420664206642066, Average Loss: 1.0276453244467194\n","Epoch: 28, Validation Accuracy: 0.630243161094225\n","Epoch: 29, Train Accuracy: 0.6442189421894219, Average Loss: 1.0272087492846036\n","Epoch: 29, Validation Accuracy: 0.6246200607902735\n","Epoch: 30, Train Accuracy: 0.6404520295202952, Average Loss: 1.0268889633037834\n","Epoch: 30, Validation Accuracy: 0.619756838905775\n","Epoch: 31, Train Accuracy: 0.6455258302583026, Average Loss: 1.0265369950295375\n","Epoch: 31, Validation Accuracy: 0.6310030395136779\n","Epoch: 32, Train Accuracy: 0.6482933579335793, Average Loss: 1.0262041681455958\n","Epoch: 32, Validation Accuracy: 0.6139817629179332\n","Epoch: 33, Train Accuracy: 0.6481396063960639, Average Loss: 1.025898212285439\n","Epoch: 33, Validation Accuracy: 0.6331306990881459\n","Epoch: 34, Train Accuracy: 0.6487546125461254, Average Loss: 1.0255938744381596\n","Epoch: 34, Validation Accuracy: 0.6261398176291794\n","Epoch: 35, Train Accuracy: 0.6401445264452644, Average Loss: 1.0253177302341832\n","Epoch: 35, Validation Accuracy: 0.6186930091185411\n","Epoch: 36, Train Accuracy: 0.6448339483394834, Average Loss: 1.0250505120417155\n","Epoch: 36, Validation Accuracy: 0.6351063829787233\n","Epoch: 37, Train Accuracy: 0.6482164821648216, Average Loss: 1.0247781468979662\n","Epoch: 37, Validation Accuracy: 0.61580547112462\n","Epoch: 38, Train Accuracy: 0.6503690036900369, Average Loss: 1.0245122710393786\n","Epoch: 38, Validation Accuracy: 0.6346504559270517\n","Epoch: 39, Train Accuracy: 0.652060270602706, Average Loss: 1.0242385973368038\n","Epoch: 39, Validation Accuracy: 0.6220364741641338\n","Epoch: 40, Train Accuracy: 0.6453720787207872, Average Loss: 1.0240078139551165\n","Epoch: 40, Validation Accuracy: 0.64209726443769\n","Epoch: 41, Train Accuracy: 0.6509071340713407, Average Loss: 1.023775499723627\n","Epoch: 41, Validation Accuracy: 0.6240121580547112\n","Epoch: 42, Train Accuracy: 0.6477552275522755, Average Loss: 1.0235342364493447\n","Epoch: 42, Validation Accuracy: 0.6358662613981763\n"]}]}]}