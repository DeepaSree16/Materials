{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"AIML-DLN-13-AN-1-4.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"}},"cells":[{"cell_type":"markdown","metadata":{"id":"H7W6IuZjFVoD"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RQL9oiyvFYck"},"source":["### Not for Grading"]},{"cell_type":"markdown","metadata":{"id":"67YV6IpOhBhu"},"source":["# Introduction\n","\n","This notebook aims at discovering Convolutional Neural Network. We will see the theory behind it, and an implementation in Pytorch on FashionMNIST dataset.\n"]},{"cell_type":"code","metadata":{"id":"0XJ35JrOfciN"},"source":["!pip3 install torchviz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wp6PPxbkhBhz"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","import torchvision\n","from torchvision import datasets, transforms, models\n","\n","from torchviz import make_dot\n","\n","import numpy as np\n","\n","import os\n","os.environ[\"PATH\"] += os.pathsep + r\"libraries/graphviz-2.38/release/bin\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z3qF-qJYhBhz"},"source":["Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes\n","\n","![FashionMNIST Dataset](https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/doc/img/fashion-mnist-sprite.png)\n","\n","Pytorch's torchvision module conveniently packages the FashionMNIST dataset into a `torchvision.datasets.FashionMNIST` class for us. We simply need to specify the dataset split (train/test) and the transformations and augmentations we want to apply on each image. We wrap the dataset objects via Pytorch's `torch.utils.data.DataLoader` class to get dataloaders which will return entire batches of samples, and also optionally shuffle the dataset internally."]},{"cell_type":"code","metadata":{"id":"cB4iDtHXhBhz"},"source":["'''\n","Training time transformations and problem specific data augmentations can be applied here.\n","see : https://pytorch.org/docs/stable/torchvision/transforms.html\n","'''\n","transforms_train = transforms.Compose([\n","    transforms.ToTensor(),\n","    # We've computed the mean and variance for this dataset beforehand, so we can plug it in here\n","    transforms.Normalize((0.1307,), (0.3081,)) \n","])\n","'''\n","FashionMNIST is a subclass of torch.utils.data.Dataset, and have __getitem__ and __len__ methods implemented. For creating\n","custom datasets you will have to inherit Dataset class and override __len__() and __getitem__()\n","'''\n","dataset_train = datasets.FashionMNIST(\n","    root='./data', train=True, download=True, transform=transforms_train\n",")\n","'''\n","Pass dataset object to DataLoader, which will later be used for iterating over minibatches\n","'''\n","dataloader_train = DataLoader(\n","    dataset_train, batch_size=128, shuffle=True,\n",")\n","\n","'''\n","Repeat the same thing (defining transforms => dataset instantiation => dataloader creationg) for the test set\n","'''\n","transforms_test =transforms.Compose([\n","    transforms.ToTensor(),\n","    # We've computed the mean and variance for this dataset beforehand, so we can plug it in here\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])\n","\n","dataset_test = datasets.FashionMNIST(\n","    root='./data', train=False, download=False, transform=transforms_test\n",")\n","\n","dataloader_test = DataLoader(\n","    dataset_test, batch_size=128, shuffle=False,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-QQ3el0-hBhz"},"source":["We now create a CNN class, which has to be a subclass of `torch.nn.Module` and have its own `__init__` and `forward` functions. \n","\n","We choose a simple architecture with `3 convolutional blocks` followed by `2 fully connected blocks`.\n","\n","For layers that do not have any parameters, i.e. layers that are simple mathematical operations on the input, such as ReLU, sigmoid, tanh, softmax, dropout, etc., Pytorch provides a `torch.nn.functional` module with such layers.\n","\n","While one can create a ReLU layer by using `nn.ReLU`, it's easier to just call `torch.nn.functional.relu` on a tensor. This helps reduce clutter, since large models can have many such layers.\n","\n","NOTE: We import `torch.nn.functional` as the alias `F`."]},{"cell_type":"code","metadata":{"id":"PIq0tshchBhz"},"source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        # nn.Conv2d API : torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1)  # 32 filters of 5x5 size and depth 1 (since input channel = 1)\n","        self.conv2 = nn.Conv2d(32, 32, kernel_size=5) # 32 filters of 5x5 size and depth 32 (since input channel =  1)\n","        self.conv3 = nn.Conv2d(32, 64, kernel_size=5) # 64 filters of 5x5 size and depth 32 #params = 64x5x5x32 + 64\n","        # nn.Linear API : torch.nn.Linear(in_features, out_features, bias=True)\n","        self.fc1 = nn.Linear(3*3*64, 256)\n","        self.fc2 = nn.Linear(256, 10)\n","\n","    def forward(self, x):\n","        # BLOCK 1: CONV + RELU\n","        x = F.relu(self.conv1(x))\n","        # BLOCK 2: CONV + MAXPOOL + RELU + DROPOUT\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = F.dropout(x, p=0.5, training=self.training) \n","        # BLOCK 3: CONV + MAXPOOL + RELU + DROPOUT\n","        x = F.relu(F.max_pool2d(self.conv3(x),2))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        # FLATTEN\n","        x = x.flatten(start_dim=1)\n","        # BLOCK 4: FC + RELU + DROPOUT\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        # BLOCK 5: FC + LOG SOFTMAX\n","        x = F.log_softmax(self.fc2(x), dim=1)\n","        return x\n","\n","model = CNN()\n","print(model)\n","\n","# get a random training batch\n","iterator = iter(dataloader_train)\n","X_batch, y_batch = next(iterator)\n","print(X_batch.shape, y_batch.shape, model(X_batch).shape)\n","\n","# pass a batch through the model and visualize the architecture\n","# NOTE: we do not have to explicitly call model.forward(inputs), instead we just do model(inputs)\n","# This is because PyTorch internally takes care of, giving us this syntactic sugar\n","make_dot(model(X_batch), params=dict(model.named_parameters()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"thiKjDeKhBh0"},"source":["Now we create some utility functions to help with the training and evaluation process. Most of this is boilerplate code that can be reused with simple changes.\n","\n","For training, we iterate over the datalaoder to get batches, and for each batch we do the following: \n","\n","- move each batch onto the specified device\n","- perform a forward pass through the model to get the outputs\n","- compute the loss based on the outputs and targets\n","- compute the gradients via backpropagation\n","- update the weights via the optimizer\n","\n","Certain layers, e.g. dropout, operate differently in training versus inference modes. To account for the same, we do:\n","\n","- model.train() to set all such layers to training mode\n","- model.eval() to set all such layers to inference mode"]},{"cell_type":"code","metadata":{"id":"rZBhXW-HhBh0"},"source":["def train(model, device, data_loader, optimizer, criterion, epoch):\n","    model.train()\n","    loss_train = 0\n","    num_correct = 0\n","    for batch_idx, (data, target) in enumerate(data_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        loss_train += loss.item()\n","        prediction = output.argmax(dim=1)\n","        num_correct += prediction.eq(target).sum().item()\n","        if batch_idx % 50 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.4f}\\tAccuracy: {:.0f}%'.format(\n","                epoch, batch_idx * len(data), len(data_loader.dataset),\n","                100. * batch_idx / len(data_loader), loss_train / (batch_idx + 1),\n","                100. * num_correct / (len(data) * (batch_idx + 1))))\n","    loss_train /= len(data_loader)\n","    accuracy = num_correct / len(data_loader.dataset)\n","    return loss_train, accuracy\n","    \n","\n","def test(model, device, data_loader, criterion):\n","    model.eval()\n","    loss_test = 0\n","    num_correct = 0\n","    with torch.no_grad():\n","        for data, target in data_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss = criterion(output, target)\n","            loss_test += loss.item()  # sum up batch loss\n","            prediction = output.argmax(dim=1)\n","            num_correct += prediction.eq(target).sum().item()\n","    loss_test /= len(data_loader)\n","    accuracy = num_correct / len(data_loader.dataset)\n","    return loss_test, accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sei6u0vshBh0"},"source":["Now we put it all together:\n","\n","- Create the model\n","- Set up the loss function (cross entropy)\n","- Add an optimizer (in this case, Adam)\n","- [Optional] Have a learning rate scheduler"]},{"cell_type":"code","metadata":{"id":"hGnuaeYrhBh1"},"source":["device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n","model = CNN().to(device)\n","criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","for epoch in range(1, 5):\n","    loss_train, acc_train = train(model, device, dataloader_train, optimizer, criterion, epoch)\n","    print('Epoch {} Train: Loss: {:.4f}, Accuracy: {:.3f}%\\n'.format(\n","        epoch, loss_train, 100. * acc_train))\n","    loss_test, acc_test = test(model, device, dataloader_test, criterion)\n","    print('Epoch {} Test : Loss: {:.4f}, Accuracy: {:.3f}%\\n'.format(\n","        epoch, loss_test, 100. * acc_test))"],"execution_count":null,"outputs":[]}]}