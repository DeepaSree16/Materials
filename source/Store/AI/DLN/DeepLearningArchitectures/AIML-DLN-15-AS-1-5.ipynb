{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"AIML-DLN-15-AS-1-2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2gD6DFr189TS"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"JkxYpEOgC2-q"},"source":["## Learning Objectives\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"byPkySyYcuq9"},"source":["At the end of the experiment you will be able to :\n","\n","* load and extract features of images\n","\n","* implement convolutional neural networks using Keras"]},{"cell_type":"code","metadata":{"cellView":"form","id":"3PGYcsim6A87"},"source":["#@title Experiment Walkthrough Video\n","\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"854\" height=\"480\" controls>\n","  <source src=\"https://cdn.exec.talentsprint.com/non-processed/Keras_Traffic_Sign_Detection.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"50RdSubUPbt2"},"source":["## Introduction\n","\n","Traffic sign recognition is a challenging, real-world problem relevant for AI based transportation systems. Traffic signs show a wide range of variations between classes in terms of color, shape, and the presence of pictograms or text. However, there exist subsets of\n","classes (e.g., speed limit signs) that are very similar to each other Using a comprehensive traffic sign detection dataset, here we will perform CNN to classify each different road sign for us.\n","\n","\n","![alt text](https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Images/img.png)\n","\n"," "]},{"cell_type":"markdown","metadata":{"id":"vcUh05NhX5SC"},"source":["## Dataset\n","The dataset choosen for this experiment is  GTSRB dataset, a dataset with over 1213 images of German Traffic Signs. There are 43 classes (43 different types of signs that we’re going to have to classify). \n","\n","**Labels / Classes**\n","\n","    1:'Speed limit (20km/h)',\n","    2:'Speed limit (30km/h)', \n","    3:'Speed limit (50km/h)', \n","    4:'Speed limit (60km/h)', \n","    5:'Speed limit (70km/h)', \n","    6:'Speed limit (80km/h)', \n","    7:'End of speed limit (80km/h)', \n","    8:'Speed limit (100km/h)', \n","    9:'Speed limit (120km/h)', \n","    10:'No passing', \n","    11:'No passing veh over 3.5 tons', \n","    12:'Right-of-way at intersection', \n","    13:'Priority road', \n","    14:'Yield', \n","    15:'Stop', \n","    16:'No vehicles', \n","    17:'Veh > 3.5 tons prohibited', \n","    18:'No entry', \n","    19:'General caution', \n","    20:'Dangerous curve left', \n","    21:'Dangerous curve right', \n","    22:'Double curve', \n","    23:'Bumpy road', \n","    24:'Slippery road', \n","    25:'Road narrows on the right', \n","    26:'Road work', \n","    27:'Traffic signals', \n","    28:'Pedestrians', \n","    29:'Children crossing', \n","    30:'Bicycles crossing', \n","    31:'Beware of ice/snow',\n","    32:'Wild animals crossing', \n","    33:'End speed + passing limits', \n","    34:'Turn right ahead', \n","    35:'Turn left ahead', \n","    36:'Ahead only', \n","    37:'Go straight or right', \n","    38:'Go straight or left', \n","    39:'Keep right', \n","    40:'Keep left', \n","    41:'Roundabout mandatory', \n","    42:'End of no passing', \n","    43:'End no passing veh > 3.5 tons' \n"]},{"cell_type":"code","source":["! apt-get -qq install -y libfluidsynth1\n","! wget -qq  https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/FullIJCNN2013.zip\n","! unzip -qq FullIJCNN2013.zip"],"metadata":{"id":"Wnc4dM_NlTuS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1TvuqkXfen7x"},"source":["### Import Required packages"]},{"cell_type":"code","metadata":{"id":"tRgJILbWehSl"},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import glob\n","from PIL import Image\n","# Keras\n","import tensorflow as tf \n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten, MaxPool2D,Dropout"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6SmsydI5COq"},"source":["### Load the data\n","\n","#### About glob.iglob:\n","\n","The glob library  provides methods for traversing the file system and returning files that matched a defined set of glob patterns.\n","\n","**Note:** Refer to  [glob.iglob](https://docs.python.org/3/library/glob.html)"]},{"cell_type":"code","metadata":{"id":"wgHjUAfI5hxx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628149394278,"user_tz":-330,"elapsed":14,"user":{"displayName":"tanuja b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9Q6sUC5CBS6NIWyhPbrCA-02jrcvBDs3WpQT_sQ=s64","userId":"04437579799669360422"}},"outputId":"c0122c2e-7d66-4d55-8e9a-a201d6630b33"},"source":["images_data = glob.glob(\"/content/FullIJCNN2013/*/*.ppm\")\n","len(images_data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1213"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"AVKHw-g-6Jub"},"source":["### Extract features and labels from the data"]},{"cell_type":"code","metadata":{"id":"4rbUrXWUfnV2"},"source":["data, labels = [], []\n","for i in images_data:\n","    try:\n","        img = Image.open(i)\n","        img = img.resize((30,30))#.reshape(30*30*3)\n","        labels.append(int(i.split(\"/\")[3]))\n","        data.append(np.array(img))\n","    except:\n","        pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0gYkqKHvZQjC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628149402853,"user_tz":-330,"elapsed":795,"user":{"displayName":"tanuja b","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9Q6sUC5CBS6NIWyhPbrCA-02jrcvBDs3WpQT_sQ=s64","userId":"04437579799669360422"}},"outputId":"1d451211-8607-422b-d040-5ae4cc7f0587"},"source":["#Converting lists into numpy arrays\n","data = np.array(data)\n","print(\"data:\",data.shape)\n","labels = np.array(labels)\n","print(\"labels:\",labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["data: (1213, 30, 30, 3)\n","labels: [ 9  9  9 ... 36 36 36]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_Q9kNOoWfwiw"},"source":["### Split the data into train and test sets\n"]},{"cell_type":"code","metadata":{"id":"Mg7ZD9aHRkaH"},"source":["#Splitting training and testing dataset\n","X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oKWwPHQwiLhJ"},"source":["print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9pgynYeUQ5vO"},"source":["### Data Pre-Processing"]},{"cell_type":"code","metadata":{"id":"pOmotCfQPAMd"},"source":["# Converts a class vector (integers) to binary class matrix\n","y_train = to_categorical(y_train, 43)\n","y_test = to_categorical(y_test, 43)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b949ALb5Eatm"},"source":["### Visualize the sample image of each class"]},{"cell_type":"code","metadata":{"id":"m_n6cNWBEPo5"},"source":["n_classes = len(set(labels))\n","n_classes\n","targets = np.array(labels)\n","plt.figure(figsize=(16, 16))\n","for c in range(n_classes):\n","    i = np.random.choice(np.where(targets == c)[0])\n","    plt.subplot(8, 8, c+1)\n","    plt.axis('off')\n","    plt.title('class: {}'.format(c))\n","    plt.imshow(data[i])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ofaPkKiM-bYt"},"source":["### Preparing the model\n","\n","Initialize our CNN model by creating an instance of Sequential. The Sequential function initializes a linear stack of layers of the network from input to output."]},{"cell_type":"code","metadata":{"id":"UgVKgfEC-aVk"},"source":["model = Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-1YMGi4s-_RK"},"source":["Adding First Convolution Layer to CNN\n","\n","*   First parameter is number of output_channels\n","*   Second parameter is the kernel_size\n","*   Third parameter is activation function. Use rectifier function, shortened as relu.\n","*   Final parameter is input_shape, which is the height and width of the rgb image "]},{"cell_type":"code","metadata":{"id":"JUxZ6AYodV85"},"source":["model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=(30, 30, 3)))\n","model.add(MaxPool2D(pool_size=(2, 2)))\n","model.add(Dropout(rate=0.25))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dkwHm_VSDgwR"},"source":["Adding Second Convolution Layer to CNN\n","\n","*   First parameter is number of output_channels\n","*   Second parameter is the kernel_size\n","*   Third parameter is activation function. Use rectifier function, shortened as relu."]},{"cell_type":"code","metadata":{"id":"9-cHMQ8lcg3K"},"source":["model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPool2D(pool_size=(2, 2))) # Max Pool with kernel size (2, 2)\n","model.add(Dropout(rate=0.25))\n","model.add(Flatten())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d66-LTbfEvTM"},"source":["Adding Fully Connected Layer\n","\n","*   First parameter is number of nodes in each layer.\n","*   Second parameter is activation function. Use rectifier function, shortened as relu.\n"]},{"cell_type":"code","metadata":{"id":"BLy8BYmpO3Co"},"source":["model.add(Dense(256, activation='relu'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w2uBkghEGFiC"},"source":["Adding Output Layer \n","\n","* First parameter of output layer is changed because the expected nodes at the output layer is 43 nodes, here we’re dealing with a classification problem that has 43 categories to classify in the GTSRB dataset.\n","\n","* Change the activation function to Softmax to get the probabilities of those 43 classes. Softmax is a sigmoid function applied to an independent variable with more than two categories"]},{"cell_type":"code","metadata":{"id":"IiDKt4-4GHZi"},"source":["model.add(Dense(43, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Co7kpuUlJObt"},"source":["Compiling the CNN\n"," \n","* The first parameter is to get the optimal set of weights in the neural network. Adam is really efficient  to use for large amount of data.\n","* The second parameter is the loss function. Since our classes are categorical, we use  categorical_crossentopy loss function. \n","* The final argument is the criterion to evaluate the model. In this case we use the accuracy."]},{"cell_type":"code","metadata":{"id":"uWpKBAOVE-ye"},"source":["model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y1ZapugQLD6p"},"source":["To view the model summary"]},{"cell_type":"code","metadata":{"id":"D1GnP7FZ75lL"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vuyvu1nYLYGB"},"source":["### Training the Model\n","\n","* First parameter contains train images\n","* Second parameter contains labels\n","* Epochs represents the number of times we’re going to pass our full dataset through the CNN."]},{"cell_type":"code","metadata":{"id":"sYX1882hPNyh"},"source":["history2 = model.fit(X_train, y_train, epochs=15)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uQ6JqQ2uMmZ-"},"source":["### Evaluate the model\n","\n","* First parameter is predicted labels of the test images\n","* Second parameter is actual labels of the test labels"]},{"cell_type":"code","metadata":{"id":"pJUDJJXbPWHs"},"source":["test_loss, test_acc = model.evaluate(X_test, y_test)"],"execution_count":null,"outputs":[]}]}