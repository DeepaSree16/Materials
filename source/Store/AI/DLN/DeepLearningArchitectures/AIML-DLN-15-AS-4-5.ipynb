{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-DLN-15-AS-4-5.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"l-lz7-0HC24p"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"vmx1zlGdWoUw"},"source":["## Learning Objectives\n","\n"]},{"cell_type":"markdown","metadata":{"id":"enYFutAiiWED"},"source":["At the end of the experiment, you will be able to:\n","\n","* classify the MNIST data using CNN\n","* understand the importance of Gradient descent algorithm"]},{"cell_type":"code","metadata":{"id":"9OerY5NgyXqn","cellView":"form"},"source":["#@title Experiment Explanation Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"850\" height=\"480\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_batch_15/preview_videos/Instrumenting_CNN.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2hCJasxI__be"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"zzWueA91AA7q"},"source":["### Description\n","\n","\n","1. The dataset contains 60,000 Handwritten digits as training samples and 10,000 Test samples, \n","which means each digit occurs 6000 times in the training set and 1000 times in the testing set. \n","2. Each image is Size Normalized and Centered \n","3. Each image is 28 X 28 Pixel with 0-255 Gray Scale Value. \n","4. That means each image is represented as 784 (28 X28) dimension vector where each value is in the range 0- 255."]},{"cell_type":"markdown","metadata":{"id":"k5Eb8UcIE4r2"},"source":["### History\n","\n","Yann LeCun (Director of AI Research, Facebook, Courant Institute, NYU) was given the task of identifying the cheque numbers (in the 90’s) and the amount associated with that cheque without manual intervention. That is when this dataset was created which raised the bars and became a benchmark.\n","\n","Yann LeCun and Corinna Cortes (Google Labs, New York) hold the copyright of MNIST dataset, which is a subset of the original NIST datasets. This dataset is made available under the terms of the Creative Commons Attribution-Share Alike 3.0 license. \n","\n","It is the handwritten digits dataset in which half of them are written by the Census Bureau employees and remaining by the high school students. The digits collected among the Census Bureau employees are easier and cleaner to recognize than the digits collected among the students.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AqAHNnh3E7C0"},"source":["### Challenges\n","\n","Now, if you notice the images below, you will find that between 2 characters there are always certain similarities and differences. To teach a machine to recognize these patterns and identify the correct output.\n","\n","![altxt](https://www.researchgate.net/profile/Radu_Tudor_Ionescu/publication/282924675/figure/fig3/AS:319968869666820@1453297931093/A-random-sample-of-6-handwritten-digits-from-the-MNIST-data-set-before-and-after.png)\n","\n","Hence, all these challenges make this a good problem to solve in Machine Learning."]},{"cell_type":"markdown","metadata":{"id":"A9O2_IcPiNYV"},"source":["## Domain Information"]},{"cell_type":"markdown","metadata":{"id":"_X-e2l14iXvo"},"source":["\n","\n","\n","Handwriting changes person to person. Some of us have neat handwriting and some have illegible handwriting such as doctors. However, if you think about it even a child who recognizes alphabets and numerics can identify the characters of a text even written by a stranger. But even a technically knowledgeable adult cannot describe the process by which he or she recognizes the text/letters. As you know this is an excellent challenge for Machine Learning.\n","\n","![altxt](https://i.pinimg.com/originals/f2/7a/ac/f27aac4542c0090872110836d65f4c99.jpg)\n"]},{"cell_type":"markdown","metadata":{"id":"Bwhk9hAX_Weh"},"source":["## AI/ML Technique"]},{"cell_type":"markdown","metadata":{"id":"7xMc9ipI_ZZ-"},"source":["A neural network is a system of interconnected artificial “neurons” that\n","exchange messages between each other. The connections have numeric weights\n","that are tuned during the training process, so that a properly trained network will\n","respond correctly when presented with an image or pattern to recognize. A\n","network consists of multiple layers of feature-detecting “neurons”. Each layer\n","has many neurons that respond to different combinations of inputs from the\n","previous layers"]},{"cell_type":"markdown","metadata":{"id":"dM8vmjipJral"},"source":["### CNN (Convolutional Neural Network)\n","\n","CNN is also referred to as ConvNets. They are part of neural networks that have proven effective in areas as image classification and recognition.\n","\n","While building or training the CNN network we follow  below steps :\n","\n","1. We start with an input image.\n","2. Then we try to apply filters or feature maps to the image, which gives us a convolutional layer.\n","\n","3. Then we break up the linearity of that image using the rectifier function. The image becomes ready for the pooling step.\n","4. Once we're done with the pooling layer, we end up with a pooled feature map.\n","5. Finally, we try to flatten our pooled feature map before inserting it into an artificial neural network.\n","\n","By following the above steps recurrently, we get the network's building blocks, like the weights and the feature maps, are trained and repeatedly altered in order for the network to reach the optimal performance. This will make the network to classify images and objects as accurately as possible.\n","\n","![alt text](https://cdn.talentsprint.com/aiml/Experiment_related_data/IMAGES/16.png)\n","\n","\n","While working on the experiment you will be able to understand different layers involved in CNN's architecture and their importance."]},{"cell_type":"markdown","metadata":{"id":"btdbDNPstOyG"},"source":["In this experiment, we build a neural network consisting of convolutional, pooling and fully connected layers to classify handwritten digits of the MNIST dataset."]},{"cell_type":"markdown","metadata":{"id":"DlEtqiEzC24u"},"source":["As we learned during the lecture sessions, CNN programming involves the following steps:\n","\n","1. Load the data\n","2. Specify a Neural Network Model \n","3. Specify the loss function and optimizer\n","4. Train the model and compute the accuracy on the training dataset\n","5. Compute the accuracy on the testing dataset\n"]},{"cell_type":"markdown","metadata":{"id":"Bikcf-BRC24z"},"source":["### Importing required packages"]},{"cell_type":"code","metadata":{"id":"3GuIxHsqC240"},"source":["# Importing Pytorch library\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torch\n","import torchvision\n","from torchvision import datasets, transforms\n","\n","# Matplotlib is used for ploting graphs\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EUarXxbEC246"},"source":["### Loading the data\n"]},{"cell_type":"markdown","metadata":{"id":"s0wMGecqu5Ic"},"source":["The database contains 60,000 training images and 10,000 testing images each of size 28x28. Loading the dataset can be easily done through the torch.utils package. The dataset is downloaded automatically when you run the below cell for the first time."]},{"cell_type":"code","metadata":{"id":"CWvuH-yKDv_1"},"source":["# Normalize with mean and std (0.1307 and 0.3081 are the mean and std of MNIST data)\n","transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ENEeWQzZD0x2"},"source":["# Loading the train set file\n","mnist_train = datasets.MNIST(root='../data', \n","                            train=True, \n","                            transform=transform,  \n","                            download=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ssNtVBHvFOgL"},"source":["# Loading the test set file\n","mnist_test = datasets.MNIST(root='../data', \n","                           train=False, \n","                           transform=transform)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bmxkoOr_v6oh"},"source":[" Let’s visualize a few data from the training set to get a better idea about the purpose of using the deep learning model."]},{"cell_type":"code","metadata":{"id":"ywedmu7Rv0dJ"},"source":["# Plotting one example\n","print(\"Shape of the training data (no of images, height, width) : \", mnist_train.train_data.size()) # (60000, 28, 28)\n","print(\"Shape of the testing data (no of images, height, width) : \", mnist_test.test_data.size())  # (10000, 28, 28)  \n","print(\"\\n\")\n","print(\"#### An Example Image, Label pair #####\")\n","plt.imshow(mnist_train.train_data[0].numpy(), cmap='gray')\n","plt.title('Label : %i' % mnist_train.train_labels[0])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z2--teHtC25E"},"source":["#### Minibatch\n","The Machine learning dataset can be really large. Hence we cannot often load the entire data into the memory. Hence neural network training is done by loading small batches (commonly called minibatch) of data and using it to update the learnable parameters (weights and biases) of the model."]},{"cell_type":"code","metadata":{"id":"4NDlkt8UGQGX"},"source":["# The mini batch size used for training\n","batch_size = 1000 \n","\n","# Loading the train dataset\n","# Data Loader loads the images and corresponding labels of defined mini batch size.\n","# the image batch shape will be (batch_size, 1, 28, 28)\n","train_loader = torch.utils.data.DataLoader(dataset=mnist_train, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","# Loading the test dataset\n","# Data loader will behave like an iterator, so we can loop over it and fetch a different mini-batch every time.\n","test_loader = torch.utils.data.DataLoader(dataset=mnist_test, \n","                                          batch_size=batch_size, \n","                                          shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"06iKhdT5H9tI"},"source":["Let’s visualize a few images in the mini batch of training set"]},{"cell_type":"code","metadata":{"id":"PfXCm8nTC25F"},"source":["batch_count = 0\n","for mini_batch in train_loader:\n","    images, labels = mini_batch    \n","    print('Mini batch size: images -', images.size(), ' labels - ', labels.size())\n","    for j in range(5):  # Basically iterating a few times (hence range(5)) to print a few images in this mini-batch\n","        print(images[j].size(), labels[j])\n","        plt.imshow(images[j][0].numpy(), cmap='gray')\n","        plt.title('Label : %i' % labels[j])\n","        plt.show()\n","\n","        # To plot only 2 images from each batch, applied logic to break out of the loop at range = 1.\n","        if j == 1:\n","            print(j)\n","            break\n","            \n","    # If you want to visualize images in the next mini-batches you can increase the Batch count value.\n","    if batch_count == 1:\n","        break\n","\n","    batch_count +=1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e8aYrO1awfiV"},"source":["### Defining a CNN based Neural Network"]},{"cell_type":"markdown","metadata":{"id":"cC1rDpB5wj58"},"source":["Now we will define a CNN based neural network, that takes the input as 28x28 MNIST images and predicts a label from 0 to 9. The predictions will be of the form of a probability distribution given as an array $P$ of length 10, where each entry $P_i$  denotes the probability of the input image being the digit $i$.\n","\n","\n","We will divide the neural network into two parts. First is the feature extractor, which given the 28x28 images, gives a feature vector. The feature extractor is a CNN based neural network. Second is a classifier, which takes the feature vector as input and produces a 10 dimensional vector called the logits. Finally the logits are converted in the prediction probabilities by applying the softmax function"]},{"cell_type":"markdown","metadata":{"id":"epKavSwZwvFs"},"source":["The Deep CNN we will be using is called LeNet. A pictorial representation is given below: </br>\n","**NOTE: The diagram below assumes the image of size 32 \\* 32, however, MNIST is 28 \\* 28; So the diagram is not a representation of the problem dataset, but a LeNet architecture in general. It could however be treated as an interesting exercise for you to recompute each of the layers gives the slight change in the input dimension.**\n","\n","![alt text](https://cdn.talentsprint.com/aiml/Experiment_related_data/IMAGES/cnn.png)\n"]},{"cell_type":"markdown","metadata":{"id":"QIgeu0AqC25L"},"source":["\n","\n","\n","\n","As you can see, the neural network has multiple operations happening one after another. Each operation has learnable parameters (weights and biases). Typically we call them the layers of a neural network. Neural networks can have many layers, and are hence called Deep Neural Networks (DNNs) or Deep CNNs. \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nxyDKtLlw6Pq"},"source":["LeNet feature extractor shown above has the following layers:\n","\n","1. Convolutional layer which:\n","    1. takes an image with 1 channel (since MNIST digits are black and white; for color images, they are represented by 3 channels giving the intensities of Red, Blue and Green) : 1x28x28\n","    2. convolves with 6 filters (weights) of kernel size 5x5 and stride 1\n","    3. without padding\n","    4. so, gives a 6x24x24 tensor as output\n","2. Subsampling or MaxPooling (which reduces the height and width by half). Here we are doing 2x2-MaxPooling which takes the maximum value of every non-overlapping 2x2 window: outputs a 6x12x12 tensor\n","3. ReLU activation function applied to every entry of the tensor\n","4. Convolutional layer which:\n","    1. takes a tensor with 6 channels: 6x12x12\n","    2. convolves with 16 filters of kernel size 5x5 and stride 1\n","    3. so, gives a 16x8x8 tensor as output\n","4. MaxPooling: gives a 16x4x4 tensor as output\n","5. ReLU"]},{"cell_type":"markdown","metadata":{"id":"EMjkQOxyw0hz"},"source":["Note that the output of the below neural network is a 3D tensor. This is because the input is a 3D tensor (with one dimension =1) and Convolutional and Max-Pooling layers give 3D tensors as output. Next, we will reshape this 3D tensor into a long vector and pass it through the classifier network. The Classifier network is typically a Multi-Layered Perceptron Network that you have seen previously."]},{"cell_type":"code","metadata":{"id":"4KFQv7tOC25M"},"source":["# A CNN based Feature extractor\n","# Defining neural network in python by a class that inherits from nn.Module\n","class LeNet(nn.Module):\n","    \"\"\"LeNet feature extractor model.\"\"\"\n","\n","    def __init__(self):\n","        \"\"\"Init LeNet feature extractor model.\"\"\"\n","        super(LeNet, self).__init__()\n","\n","        # Defining the CNNfeature Extractor\n","        self.feature_extractor = nn.Sequential(\n","            # input [1 x 28 x 28]\n","            # 1st conv layer\n","            # Conv which convolves input image with 6 filters of 5x5 size, without padding\n","            nn.Conv2d(1, 6, kernel_size=5),\n","            # [6 x 24 x` 24]\n","            nn.MaxPool2d(kernel_size=2), # Max pooling subsampling operation\n","            # [6 x 12 x 12]\n","            nn.ReLU(), # Non linear activation function\n","            # 2nd conv layer\n","            # input [6 x 12 x 12]\n","            # Conv which convolves input image with 16 filters of 5x5 size, without padding\n","            nn.Conv2d(6, 16, kernel_size=5),\n","            # [16 x 8 x 8]\n","            nn.MaxPool2d(kernel_size=2),\n","            # [16 x 4 x 4]\n","            nn.ReLU()\n","        )\n","        \n","        # Defining the Classifier\n","        self.classifier = nn.Sequential(\n","            # Linear layer with 120 hidden nodes, taking a flattened [16 x 4 x 4] as input\n","            nn.Linear(16 * 4 * 4, 120),\n","            # Linear layer with 84 hidden nodes\n","            nn.Linear(120, 84),\n","            # ReLU\n","            nn.ReLU(),\n","            # Output layer with as many nodes as number of classes\n","            nn.Linear(84, 10)         \n","        )\n","        \n","    def forward(self, input):\n","        \"\"\"Define a Forward pass of the LeNet.\"\"\"\n","        out = self.feature_extractor(input) # Pass input through the feature extractor\n","        out = out.view(-1, 16 * 4 * 4) # Reshape the 2D to a vector\n","        out = self.classifier(out) # Pass features through the classifier to get predictions\n","        # Convert the predictions to probabilities, by applying the softmax function\n","        out = F.softmax(out)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vFmW4izimMaM"},"source":["Every Tensor in PyTorch has a **to()** member function. Its job is to put the tensor on which it's called to a certain device whether it be the CPU or a certain GPU.\n","\n","Input to the to function is a torch.device object which can be initialized with either of the following inputs. \n","* cpu for CPU \n","* cuda:0 for putting it on GPU number 0. Similarly, if your system has multiple GPUs, then the respective number would be considered while initializing the device.\n","\n","Generally, whenever you initialize a Tensor, it’s put on the CPU. You should move it to the GPU to make the related calculation faster.\n"]},{"cell_type":"code","metadata":{"id":"NeuqAK-Il3yj"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1ElGuL0rLgSj"},"source":["### Creating an instance of the network\n","Let us declare an object of class LeNet, and make it a CUDA model if CUDA is available:"]},{"cell_type":"markdown","metadata":{"id":"QTCduCI1cusJ"},"source":["Next we will inspect our model, and see the parameters in each layer. Note that the activation and MaxPooling layers do not have any learnable parameters. Also note the sizes of parameters for each layer.\n","\n","- For convolutional layer weights, it is output_channels x input_channels x window_width x window_height.\n","- For convolutional layer biases, it is output_channels.\n","- For linear layer weights, it is output_size x input_size\n","- For linear layer biases, it is output_size"]},{"cell_type":"code","metadata":{"id":"4uPkNRmsC25R"},"source":["lenet = LeNet()\n","lenet = lenet.to(device)  # Making the lenet to run on available runtime\n","\n","# Print out the size of parameters of each layer\n","# state_dict() is simply a Python dictionary object that maps each layer to its parameter tensor\n","for name, param in lenet.state_dict().items():\n","    print(name, '\\n', param.size(), '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pox6ItueC25X"},"source":["### Do a Forward Pass (an example), and compute the accuracy\n","\n","The code below randomly loops over the train-data, does forward pass and compute the accuracy on the same. The weights and biases of the network are randomly initialized by default. \n","\n","Hence the prediction accuracy currently is very close to a random guess of the labels which is 1/10 = 10%.\n","\n","The step is done as the last step in the typical deep learning program. It is given here just for illustrating Forward pass."]},{"cell_type":"code","metadata":{"id":"y7mMsccnC25Z"},"source":["correct = 0\n","total = 0\n","\n","for images, labels in train_loader:\n","    # Convert the images and labels to gpu for faster execution\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    \n","    # Do the Forward pass\n","    result = lenet(images)\n","\n","    # Find the prediction with the largest probability\n","    _,pred = torch.max(result,1)\n","    total += labels.size(0)\n","\n","    # increments by the numer of correct predictions (equal to the ground truth labels)\n","    correct += (pred == labels).sum().item()\n","\n","print('Accuracy of random Train Data:', 100 * correct/total)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R8ZaomZlC25e"},"source":["### Defining Loss Function and Optimizer\n"]},{"cell_type":"markdown","metadata":{"id":"2mzSRNhyxt_L"},"source":["The **loss function** is a way of measuring the difference between the current prediction of the network and the correct prediction. As we saw in the lecture, the gradient descent algorithm is essentially adjusting the learnable parameters (weights and biases) of the network so as to decrease the loss. Here we will be using the **cross entropy loss**, which is commonly used for classification tasks (predicting a class from 0 to 9).\n","\n","The **learning rate** is a small fraction which is used to multiply the gradients of the loss function with respect to the weights. The idea behind doing this is that, we do not want to make drastic change to the weights of the neural network in each step, but rather a gradual one. \n"]},{"cell_type":"code","metadata":{"id":"iQRWcL7fC25f"},"source":["criterion = nn.CrossEntropyLoss()\n","\n","# Set the learning rate\n","# Try with different learning rates\n","learning_rate = 0.001\n","\n","optimizer = torch.optim.Adam(lenet.parameters(), lr=learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V5vKPAKCC25k"},"source":["### Training the Model\n","\n","\n","Now that we have loaded the data, defined the neural network, specified the loss function and optimizer algorithm, we can do the training. The training is done by loading a part of the training data, called minibatch. The size of the minibatch is specified by the batch_size. We will load one minibatch at a time and do forward as well as backward pass on the model. We will keep doing things by looping over the entire dataset.\n"]},{"cell_type":"code","metadata":{"id":"kNjXeIwM0qBv"},"source":["# No of Epochs\n","epoch = 8\n","\n","# First switch the module mode to lenet.train() so that new weights can be learned after every epoch. \n","lenet.train()\n","train_losses, train_accuracy = [], []\n","\n","# Loop for no of epochs\n","for e in range(epoch):\n","    train_loss = 0\n","    correct = 0\n","    # Iterate through all the batches in each epoch\n","    for images, labels in train_loader:\n","\n","      # Convert the image and label to gpu for faster execution\n","      images = images.to(device)\n","      labels = labels.to(device)\n","\n","      # Zero the parameter gradients\n","      optimizer.zero_grad()\n","\n","      # Passing the data to the model (Forward Pass)\n","      predictions = lenet(images)\n","\n","      # Calculating the loss\n","      loss = criterion(predictions, labels)\n","      train_loss += loss.item()\n","\n","      # Performing backward pass (Backpropagation)\n","      loss.backward()\n","\n","      # optimizer.step() updates the weights accordingly\n","      optimizer.step()\n","\n","      # Accuracy calculation\n","      _, predicted = torch.max(predictions, 1)\n","      correct += (predicted == labels).sum().item()\n","\n","    train_losses.append(train_loss/len(mnist_train))\n","    train_accuracy.append(100 * correct/len(mnist_train))\n","    print('Epoch: {}, Train Accuracy: {:.2f} '.format(e+1, train_accuracy[-1]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j2fo6SPxC25r"},"source":["### Compute the Accuracy of the Model on the Test data\n","Finally, we need to check how well the model is doing on the testing data. This step is also done by loading the data one minibatch at a time and computing the accuracy, which is finally averaged."]},{"cell_type":"code","metadata":{"id":"CKk8LeBdC25t"},"source":["correct = 0\n","total = 0\n","\n","for images, labels in test_loader:\n","    \n","    # Convert images and labels to gpu runtime for faster execution\n","    images = images.to(device)\n","    labels = labels.to(device)\n","        \n","    # Passing the data to the model (Forward Pass)\n","    result = lenet(images)\n"," \n","    # Finding the prediction with the max probability\n","    _,pred = torch.max(result, 1)\n","    total += labels.size(0)\n","    \n","    # correct is incremented by the numer of prediction which are correct (equal to the ground truth labels)\n","    correct += (pred == labels).sum().item()\n","    \n","print(\"Accuracy of Test Data: {0:.2f}%\".format(correct/total *100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"McTfVj_D0Ro0"},"source":["**Ungraded Exercise:** Try with different values of the learning rate and see how it affects the training. You should observe that if the learning rate is very small, the model hardly learns (that produces less accuracy). \n","\n","Finding the optimal learning rate is often a trial and error method."]}]}