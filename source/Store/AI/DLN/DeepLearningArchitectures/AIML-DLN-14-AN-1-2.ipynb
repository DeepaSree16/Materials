{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-DLN-14-AN-1-1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8YaqWn-bOGT4"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"VpqzqfEYRnDE"},"source":["## Not for Grading"]},{"cell_type":"markdown","metadata":{"id":"lb-c0Elacafg"},"source":["## Rocchio feedback search updated (Pseudo feedback and Query Expansion)"]},{"cell_type":"code","metadata":{"id":"QkMXs2EHcfSf","cellView":"form"},"source":["#@title Case Study Walkthrough\n","#@markdown   Rocchio feedback search updated (Pseudo feedback and Query Expansion)\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"320\" height=\"240\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_b7_hyd/preview_videos/rocchio_feedback_search.mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! wget https://cdn.talentsprint.com/aiml/CaseStudies/feedback_search.zip  \n","! unzip feedback_search.zip"],"metadata":{"id":"sFYYKhftpvMt"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2sCIol2y64Qr"},"source":["%cd feedback_search/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mkW__ryEFdaJ"},"source":["%ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_MK8hQAzPZ0b"},"source":["##Implementing Rocchio feedback  search\n","\n","Implementation of an information retrieval system that exploits user-provided relevance feedback to improve the search results returned by Google.\n"]},{"cell_type":"markdown","metadata":{"id":"SPG60Z3FqLSv"},"source":["### Import required packages"]},{"cell_type":"code","metadata":{"id":"Z_Ct1Por8q1U","scrolled":false},"source":["import sys\n","import logging\n","import threading\n","import os\n","import mock_feedback, mock_query_and_scraping\n","import query as query_file\n","import feedback\n","import enhance_query\n","import index\n","import scrape\n","import preprocess\n","import constants"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rBHNawFSso_T"},"source":["### Setting up the logging for the feedback application with the required parameters"]},{"cell_type":"code","metadata":{"id":"-AwnlCosLyRz"},"source":["# Create a logger\n","logger = logging.getLogger('feedback_search')\n","# Do not log in console\n","logger.propagate = False\n","# Create directory for logs if it's not there already\n","os.makedirs('logs', exist_ok=True) \n","# Create handler\n","handler = logging.FileHandler('logs/feedback_search.log')\n","# Create formatter and add it to handler\n","formatter = logging.Formatter(\n","    fmt='[%(asctime)s %(levelname)s]\\t%(message)s',\n","    datefmt='%d-%m-%Y %H:%M:%S')\n","handler.setFormatter(formatter)\n","# Add handler to the logger\n","logger.addHandler(handler)\n","# Create a set level to get INFO\n","logger.setLevel(logging.INFO)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hzvn58bwL6UH"},"source":["For more information on logging module. Click on this [link](https://realpython.com/python-logging/).\n","\n","**Note:** The below code executes untill it meets the precision value."]},{"cell_type":"code","metadata":{"id":"Fc6ymzutLy99"},"source":["def main(query, precision=0.8, is_test=False):\n","    \"\"\"\n","    Main routine, \n","    Takes initial query and target_precision provided as input,\n","    Until target_precision is achieved:\n","        Runs enhanced query, asks user's feedback, computes new precision.\n","    \"\"\"\n","\n","    try:\n","        target_precision = float(precision)\n","    except ValueError:\n","        print('<precision> must be a float between 0 and 1 !')\n","        return\n","\n","    if target_precision > 1 or target_precision <0:\n","        print('<precision> must be a float between 0 and 1 !')\n","        return\n","\n","    logger.info('\\n\\n ========================================================================\\n\\n')\n","    logger.info('[MAIN]\\t\\t Started with args: QUERY = %s, PRECISION = %s', query, target_precision)\n","\n","    #import pdb; pdb.set_trace()\n","    achieved_precision = 0\n","\n","    # Build one index for each zone of the documents (see enhance_query):\n","    indexers = {zone: index.UnigramIndexer(zone) for zone in ['title', 'summary', 'content']}\n","    bigram_indexers = {zone: index.BigramIndexer(zone) for zone in ['title', 'summary', 'content']}\n","\n","    query_optimizer = enhance_query.RocchioQueryOptimizer()\n","\n","    while (achieved_precision < target_precision):\n","        logger.info('[MAIN]\\t\\t achieved precision = %s vs target precision = %s, optimizing...', achieved_precision, target_precision)\n","        print('Parameters:')\n","        print('Query = {}'.format(query))\n","        print('Precision = {}'.format(target_precision))\n","        print('')\n","        \n","        if not is_test:\n","            results = query_file.query_google(query)\n","\n","            # Fetch the whole documents by scraping the urls in results, as a background task\n","            scraping_thread = threading.Thread(target=scrape.add_url_content, args=(query, results))\n","            scraping_thread.start()\n","\n","            if len(results) < 10:\n","                print('Too few results, aborting...')\n","                break\n","\n","            # Ask feedback to user, store feedback in results dict directly\n","            feedback.ask_feedback(results)\n","            scraping_thread.join() # make sure all the documents have been scrapped\n","\n","        elif is_test:\n","            results = mock_query_and_scraping.load_query_results(query)\n","            mock_feedback.mock_feedback(results, query=query)\n","\n","        relevant = [doc['id'] for doc in results if doc['relevant']]\n","        non_relevant = [doc['id'] for doc in results if not doc['relevant']]\n","        achieved_precision = len(relevant)/len(results) if results else 0\n","\n","        if achieved_precision == 0:\n","            print('Precision@10 is 0, aborting...')\n","            break\n","\n","        logger.info('[MAIN]\\t\\t orginal query: %s', query)\n","        query = preprocess.split_remove_punctuation(query)\n","        if constants.USE_STEMMING:\n","            query = preprocess.stem(query)\n","        logger.info('[MAIN]\\t\\t preprocessed query: %s', query)\n","\n","        indexing_threads = []\n","        for zone in indexers:\n","            indexers[zone].reset()\n","            t = threading.Thread(target=indexers[zone].index, args=(results, query))\n","            t.start()\n","            indexing_threads.append(t)\n","        \n","        for zone in bigram_indexers:\n","            bigram_indexers[zone].reset()\n","            t = threading.Thread(target=bigram_indexers[zone].index, args=(results, query))\n","            t.start()\n","            indexing_threads.append(t)\n","\n","        for t in indexing_threads:\n","            t.join()\n","\n","        print('Achieved precision: ', achieved_precision)\n","\n","        query = query_optimizer.enhance(query, indexers, relevant, non_relevant, bigram_indexers=bigram_indexers)\n","\n","        if is_test:\n","            # in tests we do Only run one of the query optimizer with mock feedback and analyze it\n","            return query\n","\n","if __name__ == '__main__':\n","    main('research library journal study', precision=0.9)"],"execution_count":null,"outputs":[]}]}