{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-DLN-22-AN-1-1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hsglmGBRW8No"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XPH70RJcXFWG"},"source":["### Not for Grading"]},{"cell_type":"markdown","metadata":{"id":"Id0tl2OVhtG3"},"source":["## Image to image translations"]},{"cell_type":"code","metadata":{"id":"f2rv0M1Khugf","cellView":"form"},"source":["#@title Case Study Walkthrough\n","#@markdown  Image to image translations\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"320\" height=\"240\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_b7_hyd/preview_videos/image_to_image_translation_with_cnn.mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hbO8eWe1XJnR"},"source":["This experiment is based on the Image-to-Image Translation with Conditional Adversarial Networks.\n","\n","####Note that this case study based on this [paper.](https://arxiv.org/pdf/1611.07004.pdf)\n"]},{"cell_type":"code","source":["! wget -qq https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/facades.tar.gz\n","! tar -xvf facades.tar.gz"],"metadata":{"id":"PNQbwAp4eECU"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jVOe8J5A0xnp"},"source":["ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DlnWRXCUYMBU"},"source":["###Importing required packages\n"]},{"cell_type":"code","metadata":{"id":"HP5b4kd2_PFY"},"source":["import torch\n","import torch.nn as nn\n","from google.colab import files\n","import torch.optim as optim\n","import torch.utils.data\n","from torch.autograd import Variable"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TZpo0AtG8dda"},"source":["### Define Discriminator architecture"]},{"cell_type":"code","metadata":{"id":"O0OJccy-_PFd"},"source":["def conv_block(in_feat, out_feat, ksize, stride, padding, \n","               activation=nn.LeakyReLU(0.2, inplace=True), use_batchnorm=True):\n","    layers = [nn.Conv2d(in_feat, out_feat, ksize, stride, padding, bias=not use_batchnorm)]\n","    if use_batchnorm:\n","        layers.append(nn.BatchNorm2d(out_feat)) \n","    if activation:\n","        layers.append(activation)\n","    return nn.Sequential(*layers)\n","\n","class BASIC_D(nn.Module):\n","    def __init__(self, nc_in, nc_out, ndf, max_layers=3):\n","        super(BASIC_D, self).__init__()       \n","        main = nn.Sequential()\n","        # input is nc x isize x isize\n","        main.add_module('initial{0}-{1}'.format(nc_in+nc_out, ndf),\n","                        conv_block(nc_in+nc_out, ndf, 4, 2, 1, use_batchnorm=False))\n","        out_feat = ndf\n","        for layer in range(1, max_layers):\n","            in_feat = out_feat\n","            out_feat = ndf * min(2**layer, 8)\n","            main.add_module('pyramid{0}-{1}'.format(in_feat, out_feat),\n","                                conv_block(in_feat, out_feat, 4, 2, 1, ))           \n","        in_feat = out_feat\n","        out_feat = ndf*min(2**max_layers, 8)\n","        main.add_module('last{0}-{1}'.format(in_feat, out_feat),\n","                        conv_block(in_feat, out_feat, 4, 1, 1))\n","        \n","        in_feat, out_feat = out_feat, 1        \n","        main.add_module('output{0}-{1}'.format(in_feat, out_feat),\n","                        conv_block(in_feat, out_feat, 4, 1, 1, nn.Sigmoid(), False))\n","        self.main = main\n","\n","    def forward(self, a, b):\n","        x = torch.cat((a, b), 1)        \n","        output = self.main(x)                    \n","        return output\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zopraf5N81SX"},"source":["### Define Generator architecture"]},{"cell_type":"code","metadata":{"id":"6Eswuizk_PFf"},"source":["#Define encoder and decoder\n","class UBlock(nn.Module):\n","    def __init__(self, s, nf_in, max_nf, use_batchnorm=True, nf_out=None, nf_next=None):\n","        super(UBlock, self).__init__()\n","        assert s>=2 and s%2==0\n","        nf_next = nf_next if nf_next else min(nf_in*2, max_nf)\n","        nf_out = nf_out if nf_out else nf_in            \n","        self.conv = nn.Conv2d(nf_in, nf_next, 4, 2, 1, bias=not (use_batchnorm and s>2) )\n","        if s>2:\n","            next_block = [nn.BatchNorm2d(nf_next)] if use_batchnorm else []\n","            next_block += [nn.LeakyReLU(0.2, inplace=True), UBlock(s//2, nf_next, max_nf)]\n","            self.next_block = nn.Sequential(*next_block)\n","        else:\n","            self.next_block = None\n","        convt = [nn.ReLU(), \n","                 nn.ConvTranspose2d(nf_next*2 if self.next_block else nf_next, nf_out,\n","                                        kernel_size=4, stride=2,padding=1, bias=not use_batchnorm)]    \n","        if use_batchnorm:\n","            convt += [nn.BatchNorm2d(nf_out)]        \n","        if s <= 8:\n","            convt += [nn.Dropout(0.5, inplace=True)]\n","        self.convt = nn.Sequential(*convt)  \n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        if self.next_block:\n","            x2 = self.next_block(x)\n","            x = torch.cat((x,x2),1)\n","        return self.convt(x)        \n","#U-Net decoder\n","\n","def UNET_G(isize, nc_in=3, nc_out=3, ngf=64):\n","    return nn.Sequential(\n","                  UBlock(isize, nc_in, 8*ngf, False, nf_out=nc_out, nf_next=ngf),\n","                  nn.Tanh() )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kyjgwb4l9UVQ"},"source":["### Weight initialization"]},{"cell_type":"code","metadata":{"id":"0Pzm6P8C_PFi"},"source":["def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        m.weight.data.normal_(0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wHQ-U9iCvUw2"},"source":["### Set the parameters"]},{"cell_type":"code","metadata":{"id":"lbthBdfQ_PFk"},"source":["nc_in = 3\n","nc_out = 3\n","ngf = 64\n","ndf = 64\n","loadSize = 286\n","imageSize = 256\n","batchSize = 1\n","lrD = 2e-4\n","lrG = 2e-4"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Y3HneUa92I8"},"source":["### Initialize the discriminator with the defined parameters "]},{"cell_type":"code","metadata":{"id":"Q54kg7Me_PFn"},"source":["netD = BASIC_D(nc_in, nc_out, ndf)\n","netD.apply(weights_init)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zo87_5go9_DA"},"source":["### Initialize the Generator with the defined parameters "]},{"cell_type":"code","metadata":{"id":"p4aZhcZ4_PFs"},"source":["netG = UNET_G(imageSize, nc_in, nc_out, ngf)\n","netG.apply(weights_init)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vc5ipmTZt_2L"},"source":["### Set the device to CUDA for both discriminator and generator networks"]},{"cell_type":"code","metadata":{"id":"X_c-g-oG_PFz"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lXjX2nQ1_PF2"},"source":["netD.to(device)\n","netG.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vEklw2Pn-7Mo"},"source":["### Define functions to load and read the images"]},{"cell_type":"code","metadata":{"id":"ntnZEtW5_PF4"},"source":["from PIL import Image\n","import numpy as np\n","import glob\n","from random import randint, shuffle\n","\n","def load_data(file_pattern):\n","    return glob.glob(file_pattern)\n","def read_image(fn, direction=0):\n","    im = Image.open(fn)\n","    im = im.resize( (loadSize*2, loadSize), Image.BILINEAR )\n","    arr = np.array(im)/255*2-1\n","    w1,w2 = (loadSize-imageSize)//2,(loadSize+imageSize)//2\n","    h1,h2 = w1,w2\n","    imgA = arr[h1:h2, loadSize+w1:loadSize+w2, :]\n","    imgB = arr[h1:h2, w1:w2, :]\n","    if randint(0,1):\n","        imgA=imgA[:,::-1]\n","        imgB=imgB[:,::-1]\n","    if channel_first:\n","        imgA = np.moveaxis(imgA, 2, 0)\n","        imgB = np.moveaxis(imgB, 2, 0)\n","    if direction==0:\n","        return imgA, imgB\n","    else:\n","        return imgB,imgA"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zphHiIoq_CUN"},"source":["### Load the facades train and validation data"]},{"cell_type":"code","metadata":{"id":"aIKwzbYo-gFV"},"source":["direction = 0\n","train_path = './facades/train/*.jpg'\n","val_path = './facades/val/*.jpg'\n","trainAB = load_data(train_path)\n","valAB = load_data(val_path)\n","assert len(trainAB) and len(valAB)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-hbDchbR_c2g"},"source":["### Define a function for creating mini batches"]},{"cell_type":"code","metadata":{"id":"hxDDod8-_PF6"},"source":["def minibatch(dataAB, batchsize, direction=0):\n","    length = len(dataAB)\n","    epoch = i = 0\n","    tmpsize = None    \n","    while True:\n","        size = tmpsize if tmpsize else batchsize\n","        if i+size > length:\n","            shuffle(dataAB)\n","            i = 0\n","            epoch+=1        \n","        dataA = []\n","        dataB = []\n","        for j in range(i,i+size):\n","            imgA,imgB = read_image(dataAB[j], direction)\n","            dataA.append(imgA)\n","            dataB.append(imgB)\n","        dataA = np.float32(dataA)\n","        dataB = np.float32(dataB)\n","        i+=size\n","        tmpsize = yield epoch, dataA, dataB        "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LgmlWPVd_kzr"},"source":["### Define a function to display the image "]},{"cell_type":"code","metadata":{"id":"sfe2T7kX_PF9"},"source":["from IPython.display import display\n","def showX(X, rows=1):\n","    assert X.shape[0]%rows == 0\n","    int_X = ( (X+1)/2*255).clip(0,255).astype('uint8')\n","    if channel_first:\n","        int_X = np.moveaxis(int_X.reshape(-1,3,imageSize,imageSize), 1, 3)\n","    else:\n","        int_X = int_X.reshape(-1,imageSize,imageSize, 3)\n","    int_X = int_X.reshape(rows, -1, imageSize, imageSize,3).swapaxes(1,2).reshape(rows*imageSize,-1, 3)\n","    display(Image.fromarray(int_X))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TxUeuIXs_75v"},"source":["### Visualize the facades and photos in the train data of a mini batch of size 6"]},{"cell_type":"code","metadata":{"id":"Y-IKU7_R_PGA"},"source":["channel_first=True\n","train_batch = minibatch(trainAB, 6, direction=direction)\n","_, trainA, trainB = next(train_batch)\n","showX(trainA)\n","showX(trainB)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"juY9rob8AOue"},"source":["### Define the optimizers"]},{"cell_type":"code","metadata":{"id":"VTsHrXf-_PGL"},"source":["optimizerD = optim.Adam(netD.parameters(), lr = lrD, betas=(0.5, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr = lrG, betas=(0.5, 0.999))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n87z4mLiAh-i"},"source":["### Define a function for training the discriminator and generator"]},{"cell_type":"code","metadata":{"id":"hCLijo0w_PGP"},"source":["loss = nn.BCELoss()\n","lossL1 = nn.L1Loss()\n","one = None\n","zero = None\n","def netD_train(A, B):    \n","    global one, zero\n","    netD.zero_grad()\n","    output_D_real = netD(A, B)\n","    if one is None:\n","        one = Variable(torch.ones(*output_D_real.size()).to(device))\n","    errD_real = loss(output_D_real, one)\n","    errD_real.backward()\n","\n","    output_G = netG(A)\n","    output_D_fake = netD(A, output_G)\n","    if zero is None:\n","        zero = Variable(torch.zeros(*output_D_fake.size()).to(device))\n","    errD_fake = loss(output_D_fake, zero)\n","    errD_fake.backward()\n","    optimizerD.step()\n","    return (errD_fake.item()+errD_real.item())/2,\n","\n","\n","def netG_train(A, B):\n","    global one\n","    netG.zero_grad()\n","    output_G = netG(A)\n","    output_D_fake = netD(A, output_G)\n","    if one is None:\n","        one = Variable(torch.ones(*output_D_fake.size()).to(device))\n","    errG_fake = loss(output_D_fake, one)    \n","    errG_L1 = lossL1(output_G, B)\n","    errG = errG_fake + 100 * errG_L1\n","    errG.backward()\n","        \n","    optimizerG.step()\n","    return errG_fake.item(), errG_L1.item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jzc3OLmq_PGS"},"source":["def V(x):\n","    return Variable(torch.from_numpy(x).to(device))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IWzgcibd_PGX"},"source":["def netG_gen(A):\n","    return np.concatenate([netG(A[i:i+1]).data.cpu().numpy() for i in range(A.size()[0])], axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YeHY_uUNRoUg"},"source":["import time\n","from IPython.display import clear_output\n","t0 = time.time()\n","niter = 300\n","gen_iterations = 0\n","errL1 = epoch = errG = 0\n","errL1_sum = errG_sum = errD_sum = 0\n","display_iters = 500\n","val_batch = minibatch(valAB, 6, direction)\n","train_batch = minibatch(trainAB, batchSize, direction)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1UOE09qHstaI"},"source":["###Note :  The block below will take longer time to run, sometimes it might lose runtime connection"]},{"cell_type":"code","metadata":{"id":"OZAwuCkJ_PGb"},"source":["while epoch < niter: \n","    epoch, trainA, trainB = next(train_batch)   \n","    vA, vB = V(trainA), V(trainB)\n","    errD,  = netD_train(vA, vB)\n","    errD_sum +=errD\n","\n","    # epoch, trainA, trainB = next(train_batch)\n","    errG, errL1 = netG_train(vA, vB)\n","    errG_sum += errG\n","    errL1_sum += errL1\n","    gen_iterations+=1\n","    if gen_iterations%display_iters==0:\n","        if gen_iterations%(5*display_iters)==0:\n","            clear_output()\n","            torch.save(netG.state_dict(), 'pix2pix_facades_Generator_{}_{}.pth'.format(epoch, gen_iterations))\n","            torch.save(netD.state_dict(), 'pix2pix_facades_Discriminator_{}_{}.pth'.format(epoch, gen_iterations))\n","        \n","        print('[%d/%d][%d] Loss_D: %f Loss_G: %f loss_L1: %f'\n","        % (epoch, niter, gen_iterations, errD_sum/display_iters, \n","           errG_sum/display_iters, errL1_sum/display_iters), time.time()-t0)\n","        _, valA, valB = train_batch.send(6)\n","        vA, vB = V(valA),V(valB)\n","        fakeB = netG_gen(vA)\n","        showX(np.concatenate([valA, valB, fakeB], axis=0), 3)\n","        \n","        errL1_sum = errG_sum = errD_sum = 0\n","        _, valA, valB = next(val_batch)\n","        fakeB = netG_gen(V(valA))\n","        showX(np.concatenate([valA, valB, fakeB], axis=0), 3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6wZyYgTUnCFc"},"source":["###Visualize the output image after training"]},{"cell_type":"code","metadata":{"id":"RWRAEPWcj_HB"},"source":["for _, trainA, trainB in train_batch:\n","    fakeB = netG_gen(V(trainA))\n","    showX(np.concatenate([trainA, trainB, fakeB], axis=0), 3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zP0JOOYFgu2S"},"source":["files.download('pix2pix_facades_Generator_{}_{}.pth'.format(epoch, gen_iterations))\n","files.download('pix2pix_facades_Discriminator_{}_{}.pth'.format(epoch, gen_iterations))"],"execution_count":null,"outputs":[]}]}