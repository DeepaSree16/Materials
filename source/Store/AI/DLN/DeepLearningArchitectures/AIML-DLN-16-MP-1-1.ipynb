{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-DLN-16-MP-1-1.ipynb","provenance":[],"collapsed_sections":["YnkmRa9Uozvd","gsyDey3To9hE"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hVMoZwHL4RTh"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"4EX7dr584we6"},"source":["## Problem Statement\n","\n","Denoise the leaf images using deep learning techniques"]},{"cell_type":"markdown","metadata":{"id":"JwfwDwfu6MXx"},"source":["## Learning Objectives\n","\n","At the end of the Mini Hackathon, you will be able to :\n","* Denoise healthy/diseased leaf images using Autoencoder\n","* Visualize the denoised images"]},{"cell_type":"markdown","metadata":{"id":"YnkmRa9Uozvd"},"source":["## Background\n","\n","Crop losses due to diseases are a major threat to food security every year, across countries.  Conventionally, plant diseases were detected through a visual examination of the affected plants by plant pathology experts. This was often possible only after major damage had already occurred, so treatments were of limited or no use. Recently, access to smartphone based image capturing has highly increased amongst farmers and agriculturists. This has led to the successful adoption of plant disease diagnostic applications based on deep learning techniques. This is of immense value in the field of agriculture and an excellent tool for faster identification and treatment of crop diseases. It holds key importance in preventing crop based food and economic losses. \n","## Dataset and Methodology\n","\n","The dataset for this Mini-Hackathon is derived from the 'Plant Village' Dataset.Around 4500 images of healthy and diseased leaves and their labels have been taken from the 'Plant Village' Dataset. The 4500 images consist of 5 different classes - Bell Pepper Healthy, Bell Pepper Bacterial Spot, Potato Healthy, Potato Early Blight and Potato Late Blight. The original pictures have been clicked in a well controlled environment with very less noise in the images. This is not how real world data may look like.  So we have added noise to the original images to form a noisy dataset. We can use deep learning techniques such as an autoencoder for obtaining denoised images. \n"]},{"cell_type":"markdown","metadata":{"id":"2Aa54Z9uJXHW"},"source":["## References:\n","\n","[Plant Village Dataset Description](https://drive.google.com/file/d/1xGhK-KhhE8W_lfr3l6KT_9K8prHDRb9_/view?usp=sharing)\n","\n","\n","[Deep Learning for Plant Disease Detection](https://drive.google.com/file/d/1V7NgFs-YGG3G-pz3OJf2X-KQxOGRZzRu/view?usp=sharing)\n","\n","[Denoising Autoencoder motivational expt](https://drive.google.com/file/d/1Sm1CDAhXDVlv9nFEjFMeYJ9eIwvoQIIZ/view?usp=sharing)\n"]},{"cell_type":"markdown","metadata":{"id":"gsyDey3To9hE"},"source":["## Grading = 20 Marks"]},{"cell_type":"markdown","metadata":{"id":"0vt5qAcHpBPO"},"source":["## Setup Steps"]},{"cell_type":"code","source":["! wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/PlantVillage_Noisy_Dataset.zip\n","! unzip -qq PlantVillage_Noisy_Dataset.zip"],"metadata":{"id":"dfPW2buqO3Mw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iiyh3-5xWd9c"},"source":["**Import Libraries**"]},{"cell_type":"code","metadata":{"id":"FSjFbBqMBfKW"},"source":["import matplotlib.pyplot as plt\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models\n","from torch.autograd import Variable"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A-B9q2loRGyH"},"source":["## **Stage 1:** Data Preparation"]},{"cell_type":"markdown","metadata":{"id":"J6XWrer9It5R"},"source":["### 2 Marks - > Prepare the dataset\n","\n","1. Define transformations:\n","   * Transform image size to 128 by using Resize()\n","   * Transform the image into a number using tensor\n","2. Load the dataset with the defined transformations."]},{"cell_type":"code","metadata":{"id":"QtMyxbtwPySf"},"source":["# YOUR CODE HERE for the transforming the dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v2Ht9YL16GN0"},"source":["# YOUR CODE HERE for preparing trainloader and testloader set"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gkXILlc8loSQ"},"source":["## **Stage 2:** Build and Train the Model\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rX2wyeqdQ68L"},"source":["### 4 Marks -> Write the encoder and decoder layers in one class\n","\n","* Define the Autoencoder neural network\n","    *  First define the layers required in the  __init__ function.\n","    *  Build the neural network in the forward() function.\n","\n","[Hint for saving the images](https://debuggercafe.com/implementing-deep-autoencoder-in-pytorch/)"]},{"cell_type":"code","metadata":{"id":"P5o69BPy5OZk"},"source":["\n","# YOUR CODE HERE for constructing an autoencoder model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qnqhmTwaOMT2"},"source":["### 4 Marks -> Train the Model and calculate the loss for dataset for each epoch.\n","\n","1. Declare the loss function and optimizer\n","2. Create a directory for saving the output images.\n","2. Train the model\n","   *  Extract the image features only as we do not take the labels to train the autoencoder network.\n","   * Calculate the loss.\n","   * Append the loss values after every epoch and print them.\n","   * Save the output (denoised) images in a directory. "]},{"cell_type":"code","metadata":{"id":"U8GdSI9F_Oos"},"source":["# YOUR CODE HERE for declaring the loss function and optimizer "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EkU5hMyqCiz5"},"source":["# YOUR CODE HERE for defining a function for creating the directory"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e4YFKBaAOLwR"},"source":["# YOUR CODE HERE. \n","\n","# Train the model and print the loss at each epoch. Also save the output (denoised) images in a directory. "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-HADegiABdfw"},"source":["# YOUR CODE HERE \n","\n","# Record loss of the train denoised images"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MnyGPpUq3YDK"},"source":["## **Stage 3:** Visualize the Denoised images \n","\n","### 3 Marks -> Verify the denoised images and compare with original noisy images\n","1. Plot the original noisy images.\n","2. Plot denoised images which are saved in the directory.\n","3. Verify whether denoised images have less noise compared to original noisy images\n","\n","**Hint:** If the noise is not reduced in the denoised images then revise the autoencoder architecture."]},{"cell_type":"code","metadata":{"id":"D4lHrYku3Xno"},"source":["# YOUR CODE HERE for plotting and verifying the images (original noisy images and denoising images)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U5BQCPZKOaN8"},"source":["## **Stage 4:** Test the Model"]},{"cell_type":"markdown","metadata":{"id":"MHIYLJXFPMJJ"},"source":["### 4 Marks -> Evaluate model with the given test data\n","\n","1. Extract only the images of test loader data as we do not use the labels for the autoencoder network\n","2. Pass the test images through the autoencoder model to get the denoised images of the test data. \n","3. Calculate the loss of the test images"]},{"cell_type":"code","metadata":{"id":"L_0Uap9gayxg"},"source":["# YOUR CODE HERE for recording the loss of the test dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EU6mxH9v5a57"},"source":["### 3 Marks -> Visualizing and verifying test images with the original test noisy dataset"]},{"cell_type":"code","metadata":{"id":"dIuhWuxC5l84"},"source":["# YOUR CODE HERE for verification and visualization of the test denoised images and original test noisy images"],"execution_count":null,"outputs":[]}]}