{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-DLN-23-AS-3-3.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"i35LuPCsxJaQ"},"source":["\n","# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n"]},{"cell_type":"markdown","metadata":{"id":"x9wLqIUIyML-"},"source":["## Learning Objective"]},{"cell_type":"markdown","metadata":{"id":"lD86AWh0yHG4"},"source":["At the end of the experiment, you will be able to :\n","\n","* perform sentiment classification from movie reviews, using a Recurrent Neural Network (RNN)\n","\n"]},{"cell_type":"code","metadata":{"id":"OvDJsz_mnH9j","cellView":"form"},"source":["#@title Experiment Walkthrough Video\n","\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"850\" height=\"480\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/movie_sentiment_analysis.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ox5WyF0y4dMz"},"source":["## Recurrent neural network (RNN)"]},{"cell_type":"markdown","metadata":{"id":"h7znelX-BRG1"},"source":["RNN is a type of neural network that is proven to work well with sequence data. Since text is actually a sequence of words, a recurrent neural network is an automatic choice to solve text-related problems. Here, we will use an LSTM (Long Short Term Memory network) which is a variant of RNN, to solve a movie reviews based sentiment classification problem. \n","\n","An LSTM unit consists of a cell, an input gate, an output gate and a forget gate. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell.\n","\n","LSTM networks are well-suited to classification based on time series data and deal well with the exploding and vanishing gradient problems that can be encountered when training traditional RNNs\n","\n","<img style=\"-webkit-user-select: none;margin: auto;\" src=\"https://miro.medium.com/max/1302/1*yr0820z7YNRcDCWGisLC4g.png\" width=\"450\" height=\"250\">\n","\n","\n","<img style=\"-webkit-user-select: none;margin: auto;\" src=\"https://miro.medium.com/max/1276/1*mvxPFvnDqj2jJrsjevD41A.png\" width=\"450\" height=\"250\">\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"25xeb09mMs0B"},"source":["## Dataset Description\n","\n","The IMDB dataset from [stanford](http://ai.stanford.edu/~amaas/data/sentiment/) has around 50K movie reviews with the following attributes:\n","* **review:** review of any movie\n","* **sentiment:** positive or negative sentiment value\n","\n","The dataset contains equal number of positive and negative sentiment reviews\n"]},{"cell_type":"code","source":["! wget -qq https://cdn.talentsprint.com/aiml/Experiment_related_data/IMDB_Dataset.csv\n"],"metadata":{"id":"mfqoDFDgpe4h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eN9xA1xMwIq0"},"source":["### Importing required packages"]},{"cell_type":"code","metadata":{"id":"sdz-3IanrBiU"},"source":["import pandas as pd\n","import numpy as np\n","import re\n","from numpy import array\n","from tensorflow.keras.preprocessing.text import one_hot\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from keras.layers.core import Activation, Dropout, Dense\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import GlobalMaxPooling1D\n","from keras.layers.embeddings import Embedding\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QdT0aESgsVPU"},"source":["### Dataset analysis"]},{"cell_type":"code","metadata":{"id":"PAzdHqulsRbv"},"source":["movie_reviews = pd.read_csv(\"IMDB_Dataset.csv\")\n","\n","movie_reviews.isnull().values.any()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WJcLZO2aN_kl"},"source":["print(movie_reviews.shape)\n","movie_reviews.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ol2PIDSMtCwN"},"source":["# Let us view one of the reviews\n","movie_reviews[\"review\"][5]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eMIU5YtCv0k8"},"source":["### Data Preprocessing\n","\n","Remove html tags, punctuations, special characters etc. from the review text"]},{"cell_type":"code","metadata":{"id":"NI7nx3eFuLGD"},"source":["# Data Preprocessing \n","def preprocess_text(sen):\n","    # PRE-PROCESS A GIVEN REVIEW\n","    sen = re.sub('<.*?>', ' ', sen) # remove html tag\n","    sen = re.sub('[^a-zA-Z]', ' ', sen)    # remove non alphabet\n","    sen = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sen)    # remove Single characters\n","    sen = re.sub(r'\\s+', ' ', sen)     # remove multiple spaces\n","    sen = sen.lower() # lower case\n","    return sen"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wjzvZSmwvO5O"},"source":["# Store the preprocessed reviews in a new list\n","X = []\n","sentences = list(movie_reviews['review'])\n","for sen in sentences:\n","    X.append(preprocess_text(sen))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"viX5aijFhlGf"},"source":["print(X[5])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M-kFMtmcv6as"},"source":["# Convert labels to integers\n","y = movie_reviews['sentiment']\n","y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K-KenTlzwN5x"},"source":["### Training and Testing"]},{"cell_type":"code","metadata":{"id":"bLuY71VzwK1A"},"source":["# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n","\n","print('Train Set',len(X_train))\n","print('Test Set',len(X_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQjh4D4eUjWP"},"source":["print(X_train[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x6W_D9WnwiR5"},"source":["### Prepare the Embedding Layer\n","\n","The embedding layer converts our textual data into a dense vector representation and is used as the first layer for the deep learning models in Keras\n","\n","Steps:\n","\n","1. Tokenization \n","\n","2. Padding\n","\n","3. Embedding"]},{"cell_type":"code","metadata":{"id":"iA-C8sYnwyrR"},"source":["# Tokenizer class from the keras.preprocessing.text module creates a word-to-index integer dictionary\n","tokenizer = Tokenizer(num_words=5000)\n","tokenizer.fit_on_texts(X_train)\n","X_train = tokenizer.texts_to_sequences(X_train)\n","X_test = tokenizer.texts_to_sequences(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sp6sMPAvgU0C"},"source":["print(np.asarray(X_train).shape)\n","print(np.asarray(X_test).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f7iUq1nGyOzx"},"source":["The X_train set contains 40,000 lists of integers, each list corresponding to the sentences in a review. Set the maximum length of each list to 100 and add 0 padding to those lists that have a length < 100, until they reach a length of 100"]},{"cell_type":"code","metadata":{"id":"NPEFSkxZxyRJ"},"source":["# Perform padding on both train and test set\n","max_length = 100\n","\n","X_train = pad_sequences(X_train, maxlen=max_length, padding='post', truncating='post')\n","X_test = pad_sequences(X_test, maxlen=max_length, padding='post', truncating='post')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pakh5BOKWKgA"},"source":["print('Encoded X Train\\n', X_train, '\\n')\n","print('Encoded X Test\\n', X_test, '\\n')\n","print('Maximum review length: ', max_length)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6dm4lLnz_TE"},"source":["### Build LSTM Model for text classification"]},{"cell_type":"code","metadata":{"id":"XaYKsRLi3Q0F"},"source":["from tensorflow.python.keras.models import Sequential\n","from tensorflow.python.keras.layers import Dense, Embedding, LSTM\n","from tensorflow.python.keras.layers.embeddings import Embedding\n","\n","EMBEDDING_DIM = 100\n","\n","print('Build model...')\n","\n","model = Sequential()\n","model.add(Embedding(5000, EMBEDDING_DIM, input_length = max_length))\n","model.add(LSTM(units=32,  dropout=0.2))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# try using different optimizers and different optimizer configs\n","model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","\n","print('Summary of the built model...')\n","print(model.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v1yM4QUJ370N"},"source":["### Training and Validation"]},{"cell_type":"code","metadata":{"id":"TBo01v6A4KPL"},"source":["history = model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=2, validation_split=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V-eeqc306cjK"},"source":["### Testing"]},{"cell_type":"code","metadata":{"id":"JZoUVfwn6e13"},"source":["print('Testing...')\n","y_test = np.array(y_test)\n","loss, accuracy = model.evaluate(X_test, y_test, batch_size=128)\n","\n","print('Test loss:', loss)\n","print('Test accuracy:', accuracy)\n","print(\"Accuracy: {0:.2%}\".format(accuracy))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s0ZC_I9h6xTd"},"source":["# Let us test some  samples\n","test_sample_1 = \"This movie is fantastic! I really like it because it is so good!\"\n","test_sample_2 = \"Good movie!\"\n","test_sample_3 = \"Maybe I like this movie.\"\n","test_sample_4 = \"Not to my taste, will skip and watch another movie\"\n","test_sample_5 = \"if you like action, then this movie might be good for you.\"\n","test_sample_6 = \"Bad movie!\"\n","test_sample_7 = \"Not a good movie!\"\n","test_sample_8 = \"This movie really sucks! Can I get my money back please?\"\n","test_samples = [test_sample_1, test_sample_2, test_sample_3, test_sample_4, test_sample_5, test_sample_6, test_sample_7, test_sample_8]\n","\n","for each in test_samples:\n","  filtered = [preprocess_text(each)]\n","  tokenize_words = tokenizer.texts_to_sequences(filtered)\n","  tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\n","  result = model.predict(tokenize_words)\n","  if result >= 0.7:\n","      print('positive == ',each)\n","  else:\n","      print('negative == ',each)"],"execution_count":null,"outputs":[]}]}