%\tolerance=10000
%\documentclass[prl,twocoloumn,preprintnumbers,amssymb,pla]{revtex4}
\documentclass[prl,twocolumn,showpacs,preprintnumbers,superscriptaddress]{revtex4}
\documentclass{article}
\usepackage{graphicx}
\usepackage{color}
\usepackage{dcolumn}
%\linespread{1.7}
\usepackage{bm}
%\usepackage{eps2pdf}
\usepackage{graphics}
\usepackage{pdfpages}
\usepackage{caption}
%\usepackage{subcaption}
\usepackage[demo]{graphicx} % omit 'demo' for real document
%\usepackage{times}
\usepackage{multirow}
\usepackage{hhline}
\usepackage{subfig}
\usepackage{amsbsy}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{float}
\documentclass{article}
\usepackage{amsmath,systeme}
\usepackage{tikz}

\sysalign{r,r}

% \textheight = 8.5 in
% \topmargin = 0.3 in

%\textwidth = 6.5 in
% \textheight = 8.5 in
%\oddsidemargin = 0.0 in
%\evensidemargin = 0.0 in

%\headheight = 0.0 in
%\headsep = 0.0 in
%\parskip = 0.2in
%\parindent = 0.0in

% \newcommand{\ket}[1]{\left|#1\right\rangle}
% \newcommand{\bra}[1]{\left\langle#1\right|}
\newcommand{\ket}[1]{| #1 \rangle}
\newcommand{\bra}[1]{\langle #1 |}
\newcommand{\braket}[2]{\langle #1 | #2 \rangle}
\newcommand{\ketbra}[2]{| #1 \rangle \langle #2 |}
\newcommand{\proj}[1]{| #1 \rangle \langle #1 |}
\newcommand{\al}{\alpha}
\newcommand{\be}{\beta}
\newcommand{\op}[1]{ \hat{\sigma}_{#1} }
\def\tred{\textcolor{red}}
\def\tgre{\textcolor{green}}


\theoremstyle{plain}
\newtheorem{theorem}{Theorem}

\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}


\begin{document}
\begin{widetext}
\\
\\
\\

\begin{wrapfigure}
\centering
%\includegraphics[\textwidth]{TS_IISc.png}
\end{wrapfigure}
\begin{figure}[h!]
 \begin{right}
  \hfill\includegraphics[\textwidth, right]{TS_IISc.png}
 \end{right}
\end{figure}
%\noindent\textbf{1. Which is the metric used to evaluate the performance of Text to Speech Synthesis?}
\noindent\textbf{Study the given below statements with respect to the architecture of a GAN (Generative Adversarial Network and answer the first question.}
\\
\\
\\
$i.$ The Generator, initially generates a random data distribution (Noise) and eventually with training it generates samples from training data distribution.
\\
\\
$ii.$ The goal of the Discriminator is to identify fake images generated by the Generator. 
\\
\\
$iii.$ The Discriminator, through subsequent training, gets better at classifying a fake image from a real one.
\\
\\
$iv.$ The Discriminator, starts off with a random data distribution (Noise) and tries to replicate a particular type of distribution.
\\
\\
$v.$ The Generator, through subsequent training, gets better at classifying a fake image from a real one.
\\
\\
%$vi.$ The goal of the Generator is not to get fooled by the Discriminator.
\\
\\
\\
\textbf{1. Which of the statement(s) given above is/are FALSE?}
\\
\\
\\
A. $i.$ and $iii.$ only
\\
\\
B. $ii.$ and $v.$ only
\\
\\
C. $ii.$ only
\\
\\
D. $iv.$ and $v.$ only
\\
\\
\\
\textbf{Answer: D}
\\
\\
\\
\\
\textbf{2. In the context of adversarial attack, which of the following statement(s) applies to transferability?}
\\
\\
\\
A. When we generate perturbations on our own model, use these perturbations to attack many other target systems and we don’t need to know the architecture of the target model and we also don’t need the same data on which the target is trained.
.
\\
\\
\\
B. When we generate perturbations on our own model, use these perturbations to attack many other target systems and we need to know the architecture of the target model and we also need the same data on which the target is trained.
\\
\\
\\
C. When we generate perturbations on our own model, use these perturbations to attack many other target systems and we need to know the architecture of the target model and we also don’t need the same data on which the target is trained.
\\
\\
\\
D. None of the above.
\\
\\
\\
\\
\textbf{Answer: A}
\\
\\
\\
\\
\textbf{3. Which of the following statement(s) is/are true regarding evaluation of object detection?}
\\
\\
\\
A. In object detection, we use an evaluation metric called "mean average precision" (mAP) 
\\
\\
\\
B. The mean average precision is calculated by computing the average precision (AP) separately for each class and then average over the classes
\\
\\
\\
C. An object detection is true positive if it has IoU with a ground-truth box greater than a specified threshold (usually 0.5)
\\
\\
\\
D. All of the above
\\
\\
\\
E. None of the above
\\
\\
\\
\\
\textbf{Answer: D}
\\
\\
\\
\\
%\textbf{4. Select the correct statement from the following in order of increasing number of parameters?}
%and what is the type of the neural network used for image segmentation?}
\textbf{4. Which of the following statement is false with respect to FGSM?}
\\
\\
\\
A. FGSM stands for Fast Gradient Sign Method and it is a simple yet effective method to generate adversarial images.
\\
\\
B. The FGSM exploits the gradients of a neural network to build an adversarial image.
\\
\\
C. FGSM computes the gradients of a loss function (e.g., mean-squared error or categorical cross-entropy) with respect to the input image and then uses the sign of the gradients to create a new image (i.e., the adversarial image) that minimises the loss.
\\
\\
D. FGSM computes the gradients of a loss function (e.g., mean-squared error or categorical cross-entropy) with respect to the input image and then uses the sign of the gradients to create a new image (i.e., the adversarial image) that maximizes the loss.
\\
\\
\\
\textbf{Answer: C}
\\
\\
\\
\\
\textbf{5. In a GAN, the Generator is trained to create/generate images such that the Discriminator cannot distinguish between real and fake generated images.}
\\
\\
\\
A. False
\\
\\
B. True
\\
\\
\\
\textbf{Answer: B}
\\
\\
\\
\\
\\
\\
\end{widetext}
\end{document}