{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-DLN-11-AS-1-1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"4fpVc1Qdu-Uq"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"dWrO0ier8ygw"},"source":["##Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"w2XhNmWh4teT"},"source":["\n","At the end of the experiment, you will be able to:\n","\n","* extract meaningful features from the images using PCA\n","\n","* apply SVM on the extracted data and recognize the face\n","\n","**NOTE:**  The intent of this experiment is to understand the SVM parameters and tune your classifier"]},{"cell_type":"code","metadata":{"id":"mj2Y2HwZ9fzW","cellView":"form"},"source":["#@title Experiment Walthrough Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"854\" height=\"480\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint1/archives/sc/misc/svm_facerecognition.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W2INZXkO87ld"},"source":["##Dataset "]},{"cell_type":"markdown","metadata":{"id":"_reikMZBdZ0o"},"source":["### Description \n","\n","The dataset chosen for this experiment is a preprocessed excerpt of the “Labeled Faces in the Wild”, aka LFW. \n","\n","Labeled Faces in the Wild, a database of face photographs designed for studying the problem of unconstrained face recognition. The data set contains more than 13,000 images of faces collected from the web. Each face has been labeled with the name of the person pictured. 1680 of the people pictured have two or more distinct photos in the data set. The only constraint on these faces is that they were detected by the Viola-Jones face detector. \n","\n","\n","To know more about the dataset you can refer below link :\n","\n","\n","http://vis-www.cs.umass.edu/lfw/"]},{"cell_type":"markdown","metadata":{"id":"NxwqZ2bz9DKq"},"source":["##Domain Information"]},{"cell_type":"markdown","metadata":{"id":"ogwMiFMv5Ehn"},"source":["\n","As it is known by you that every face is different and a face has various features. Some of us have a broad forehead, some have narrow, some have fuller lips whereas some have thinner lips, etc. Additionally, every feature of the face has different variations. An ideal face recognition system should be able to consider all the variations and the challenges faced to recognize a face accurately.\n","\n","\n","###Below we have listed a few challenges\n","\n","\n","**Illumination:** Lighting aspect\n","\n","**Background:** The placement of the subject also serves as a significant contributor to the limitations.\n","\n","**Pose:** The movements of the head \n","\n","**Occlusion:**  beard, mustache, accessories (goggles, caps, mask, etc.) also meddle with the evaluation of a face recognition system. The Presence of such components makes the subject diverse and hence it becomes difficult for the system to operate in a non-simulated environment. \n","\n","**Expressions:** A change is an expression brings a change into all the aspects of the face.\n","\n","All these make the problem very complex."]},{"cell_type":"markdown","metadata":{"id":"m46mVe379I4w"},"source":["##AI/ML Technique"]},{"cell_type":"markdown","metadata":{"id":"CCP6ASsNSHZn"},"source":["### SVM\n","\n","SVM stands for Support vector machines. It used for both classification and regression tasks. SVM works by searching the linear optimal separating hyperplane (decision boundary). The logic is that decision boundary with large margin is better when handling unseen data compared to decision boundary with a small margin. When the data is not\n","linearly separable, SVM transforms original data into a higher dimension using a nonlinear mapping to obtain the separating hyperplane.\n","\n","\n","To know more about SVM you can refer the below link :\n","\n","https://www.quantstart.com/articles/Support-Vector-Machines-A-Guide-for-Beginners\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mcuHkugaj3m3"},"source":["As an example of support vector machines in action, let's take a look at the facial recognition problem"]},{"cell_type":"markdown","metadata":{"id":"EbslM_liu-Uw"},"source":["### Importing the required packages"]},{"cell_type":"code","metadata":{"id":"LELdxmTXu-Ux"},"source":["from sklearn.datasets import fetch_lfw_people\n","from sklearn.svm import SVC\n","from sklearn.decomposition import PCA\n","from sklearn.pipeline import make_pipeline\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from time import time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KQVakGy5u-U6"},"source":["### Loading the dataset from sklearn datasets"]},{"cell_type":"code","metadata":{"id":"I54otvVpu-U8"},"source":["faces = fetch_lfw_people(min_faces_per_person = 60)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sXgdNxglu-VB"},"source":["# Checking for the target names (Label names)\n","print(faces.target_names)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2mGgg2NIu-VH"},"source":["# Checking for the shape of images\n","print(faces.images.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dJme-tkHu-VM"},"source":["To get a sense of the data, let us visualize the faces"]},{"cell_type":"code","metadata":{"id":"PBjw0WRI44Vx"},"source":["# Plotting the images in subplots\n","n_row, n_col = 3, 3\n","plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n","\n","for i in range(n_row * n_col):\n","    plt.subplot(n_row, n_col, i + 1)\n","    plt.imshow(faces.images[i], cmap='gray')\n","    plt.title(faces.target_names[faces.target[i]], size=12)\n","    plt.xticks(())\n","    plt.yticks(())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qtV2dvi5u-VT"},"source":["Each image contains [62×47] or nearly 3,000 pixels. We could proceed by simply using each pixel value as a feature, but often it is more effective to use some sort of preprocessor to extract more meaningful features; here we will use a principal component analysis to extract 150 fundamental components to feed into our support vector machine classifier. We can do this most straightforwardly by packaging the preprocessor and the classifier into a single pipeline:"]},{"cell_type":"markdown","metadata":{"id":"cTj1BLlm2c8J"},"source":["In PCA, the parameter `Whiten = True`, will remove some information from the transformed signal (the relative variance scales of the components) but can sometime improve the predictive accuracy of the downstream estimators by making their data respect some hard-wired assumptions. Whitening just makes our resulting data have a unit variance, which has been shown to produce better results"]},{"cell_type":"markdown","metadata":{"id":"1lgafnt5KkjS"},"source":["In support vector machines, 'C' is a hyperparameter determining the penalty for misclassifying an sample. One method for handling imbalanced classes in support vector machines is to weight 'C' by classes, so that\n","\n","$C_k = C∗w_j$\n","\n","where $C$ is the penalty for misclassification, $w_j$ is a weight inversely proportional to class $j$’s frequency and \n","$C_j$ is the $C$ value for class $j$. The general idea is to increase the penalty for misclassifying minority classes to prevent them from being “overwhelmed” by the majority class.\n","\n","In scikit-learn, for SVC we can set the values for $C_j$\n"," automatically by setting **class_weight='balanced'**.  The balanced argument automatically weighs classes such that:\n","\n","  $w_j = \\frac{n}{kn_j}$\n","\n","where $w_j$ is the weight to class $j$,  n is the number of samples, $n_j$ is the number of samples in class $j$\n",", and k is the total number of classes.\n"]},{"cell_type":"markdown","metadata":{"id":"8QQCSwG03EYV"},"source":["Note: Refer [make_pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html) from sklearn"]},{"cell_type":"code","metadata":{"id":"w7eea2_hu-VU"},"source":["pca = PCA(n_components=150, whiten=True, random_state=42)\n","svc = SVC(kernel='rbf', class_weight='balanced')\n","model = make_pipeline(pca, svc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HiE2ZI-8u-VY"},"source":["For testing our classifier output, we will split the data into a training and testing set:"]},{"cell_type":"code","metadata":{"id":"UUBB11zDu-VZ"},"source":["Xtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J1vBhuOUtezl"},"source":["# Checking for the shape of Xtest\n","Xtest.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CyTANFGBbzxy"},"source":["# Checking for the shape of Xtrain\n","Xtrain.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jH1nwRcfu-Ve"},"source":["Finally, we can use a grid search to explore combinations of parameters. Here we will adjust C (which controls the margin hardness) and gamma (which controls the size of the radial basis function kernel), and determine the best model:"]},{"cell_type":"code","metadata":{"id":"ICQ49mEXu-Vf"},"source":["param_grid = {'svc__C': [1, 5, 10, 50],      # It takes some time to run this cell\n","              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n","grid = GridSearchCV(model, param_grid)\n","\n","# Starting the timer\n","t0 = time()\n","\n","grid.fit(Xtrain, ytrain)\n","\n","print(\"done in %0.3fs\" % (time() - t0))\n","print(grid.best_params_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d53OmgcMu-Vl"},"source":["The optimal values fall toward the middle of our grid; if they fell at the edges, we would want to expand the grid to make sure we have found the true optimum. "]},{"cell_type":"markdown","metadata":{"id":"rxMKr5QLu-Vm"},"source":["Now with this model, we can predict the labels for the test data, which the model has not yet seen:"]},{"cell_type":"code","metadata":{"id":"xZ4XreUeu-Vo"},"source":["model = grid.best_estimator_\n","y_pred = model.predict(Xtest)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VJ0WkHsmu-Vs"},"source":["Let's take a look at a few of the test images along with their predicted values:"]},{"cell_type":"code","metadata":{"id":"PBskyaEQu-Vt"},"source":["# Plotting the images in subplots\n","n_rows, n_cols = 4, 6\n","plt.figure(figsize=( 8, 6))\n","\n","for i in range(n_rows * n_cols):\n","    plt.subplot(n_rows, n_cols, i + 1)\n","    plt.imshow(Xtest[i].reshape(62, 47), cmap='gray')\n","    plt.xticks(())\n","    plt.yticks(())\n","    plt.ylabel(faces.target_names[y_pred[i]].split()[-1],\n","                   color='black' if y_pred[i] == ytest[i] else 'red')\n","plt.suptitle('Predicted Names; Incorrect Labels in Red', size = 15)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IMz7csuUu-Vz"},"source":["Out of this small sample, our optimal estimator mislabeled only a single face (Bush’s face in the bottom row was mislabeled as Blair). We can get a better sense of our estimator's performance using the classification report, which lists recovery statistics label by label"]},{"cell_type":"code","metadata":{"id":"sV9rW5o4u-V0"},"source":["print(classification_report(ytest, y_pred,\n","                            target_names=faces.target_names))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZYBEB5PCu-V8"},"source":["Display the confusion matrix between these classes"]},{"cell_type":"code","metadata":{"id":"eDpXQf_Yu-V-"},"source":["from sklearn.metrics import confusion_matrix\n","mat = confusion_matrix(ytest, y_pred)\n","sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n","            xticklabels=faces.target_names,\n","            yticklabels=faces.target_names)\n","plt.xlabel('true label')\n","plt.ylabel('predicted label');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-1Akml4Tu-WF"},"source":["For a real-world facial recognition task, in which the photos do not come pre-cropped into nice grids, the only difference in the facial classification scheme is the feature selection: you would need to use a more sophisticated algorithm to find the faces, and extract features that are independent of the pixelation."]},{"cell_type":"markdown","metadata":{"id":"noKU-O22u-WG"},"source":["#### Acknowledgment:  Python Data Science Handbook by Jake VanderPlas"]}]}