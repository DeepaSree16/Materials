{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-DLN-04-AN-2-2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RWR22OAlTBlU"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n","\n"]},{"cell_type":"markdown","metadata":{"id":"u1zKf9UCTFQW"},"source":["### Not for Grading"]},{"cell_type":"markdown","metadata":{"id":"fcOK1wB_sCou"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"yETAUjEur-48"},"source":["At the end of the experiment, you will be able to\n","\n","*   extract data from web page\n","*   understand Beautiful Soup"]},{"cell_type":"markdown","metadata":{"id":"a2EYU92sKaZL"},"source":["## Web Scraping\n","Web scraping is a technique that automatically access and extracts large amount of information from a website. \n","It is also known as web data extraction, which is the process of retrieving or scraping data from a website. The Python libraries requests and Beautiful Soup are powerful tools for web scraping."]},{"cell_type":"markdown","metadata":{"id":"QPU_v9UQnHIF"},"source":["### Importing required packages\n"]},{"cell_type":"code","metadata":{"id":"9qnzJ-Aclz5D"},"source":["import requests         # request is a library to send HTTP request in Python\n","import urllib.request   # urllib.request is a python module for fetching URLs\n","\n","# Importing BeautifulSoup package\n","from bs4 import BeautifulSoup as bs  # BeautifulSoup scrapes the information from web pages"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ikUpSW9ftVID"},"source":["### Download the HTML page of a specified path \n","\n","\n","Consider the Shakespeare story for downloading the web page content using urllib library\n","\n","urllib is a package that works with the URL for downloading the web page.\n","\n","\n","Shakespeare web page [Source](http://shakespeare.mit.edu/comedy_errors/full.html)"]},{"cell_type":"code","metadata":{"id":"PXW83m5OqJKW"},"source":["# url is from the Shakespeare stories\n","url = \"http://shakespeare.mit.edu/comedy_errors/full.html\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5SL5j6-JsXZ6"},"source":["# Download the given url to specified path\n","urllib.request.urlretrieve(url, \"shakespeare_comedy_play.html\")  # Retrieves a URL into a temporary location"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1ntvd-6IMEgG"},"source":["### Directly get the HTML page without downloading\n","\n","The **requests** module to directly download the HTML page.\n","\n","\n","The requests module allows you to send HTTP requests using Python.\n","The HTTP request returns a Response Object with all the response data (content, encoding, status, etc).\n","\n","`requests.get()` makes a request to a web page, and returns the status code\n","\n"]},{"cell_type":"code","metadata":{"id":"11pc2ApmDSMh"},"source":["# To avoid URL exception\n","try:  \n","    html_page = requests.get(url) \n","except:\n","  pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"99gLpgrNsYfe"},"source":["# To get the content from requested html page\n","page_content = html_page.content\n","print( page_content)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JzY4WCTeL3IO"},"source":["\n","### Extract data from HTML page using BeautifulSoup\n","\n","\n","BeautifulSoup is a Python package for parsing HTML and XML documents. It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping.\n","\n","html.parser is used to identify the tags and parse the data"]},{"cell_type":"code","metadata":{"id":"PUI_IhKZqisI"},"source":["# Parsing the page content to HTML format\n","shakespeare_bs_object = bs(page_content, \"html.parser\")\n","print( shakespeare_bs_object)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pVvx4NuMgtZs"},"source":["print(shakespeare_bs_object.title.text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PK_CmZg5ErjB"},"source":["### To view the content from the HTML page without any tags\n","\n","get_text() is used for extracting text from HTML page by removing tags"]},{"cell_type":"code","metadata":{"id":"Zomcj3SLDlGy"},"source":["# To see only the text without HTML tags\n","shakespeare_text = shakespeare_bs_object.get_text()\n","print(shakespeare_text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-DVkWCKRLRfd"},"source":["#### Save the extracted text into  `.txt` file"]},{"cell_type":"code","metadata":{"id":"zGxhVwGBFeFT"},"source":["# Open a file and writing to it\n","f = open(\"shakespeare.txt\", \"w\")\n","f.write(shakespeare_text)\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6HfP7oO4m8FW"},"source":["### Other ways to navigate the data using BeautifulSoup\n","\n","BeautifulSoup has different tags such as 'title' tag and 'H3' tag\n","\n","Title tag: To get the title of the HTML page  (Title of the story)\n"]},{"cell_type":"code","metadata":{"id":"LSNyYFqxGsgF"},"source":["# It gives title tag of the HTML page\n","print(shakespeare_bs_object.title)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j7b6v_IBOH6Q"},"source":["# To get only the text between the title tag\n","print(shakespeare_bs_object.title.text) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eyQL-ggwnTO0"},"source":["H3 Tag: To get the heading tags of the web page"]},{"cell_type":"code","metadata":{"id":"OQWeTuRWk8Ld"},"source":["# findAll returns list of elements for the given specified tag\n","# for ex: find all the 3rd level headings in the HTML page and print them\n","h3tags = shakespeare_bs_object.findAll(\"h3\")  \n","print( \"No.of headings in the web page\", len(h3tags))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ojcW4KAOq72"},"source":["# To get only the text between the h3 tag\n","print( h3tags[0].text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B17-O6ITLTl9"},"source":["### Extract tabular data from  the web page\n","\n","\n","Select a list of mountains by elevation table from the Wikipedia page [link](https://en.wikipedia.org/wiki/List_of_mountains_by_elevation) and create the dataframe"]},{"cell_type":"markdown","metadata":{"id":"x4SEUKyowXJM"},"source":["#### Download the HTML page\n","\n","The **requests** module to directly download the HTML page."]},{"cell_type":"code","metadata":{"id":"MqVK3FrmwZvF"},"source":["url2 = \"https://en.wikipedia.org/wiki/List_of_mountains_by_elevation\"\n","\n","try:\n","    wiki_html = requests.get(url2)\n","except:\n","  pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"27h1nlKZH5i-"},"source":["#### Extract data from Wikipedia HTML page using BeautifulSoup\n","\n","BeautifulSoup is a Python package for parsing HTML and XML documents. It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping.\n","\n","html.parser is used to identify the tags and parse the data"]},{"cell_type":"code","metadata":{"id":"uHZG3JIu0zBF"},"source":["# Parsing the page content to HTML format\n","mountains_wiki_page = bs(wiki_html.content, \"html.parser\")\n","mountains_wiki_page"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UkjWpd4TGL-J"},"source":["**The HTML table element represents tabular data which is in a two-dimensional table comprised of rows and columns**\n","\n","`table` represents the table tag\n","\n","`tr` represents each row in table\n","\n","`th` represents headings in the table\n","\n","`td` represents each cell of the table\n","\n","Get the table from the wikipedia page, use `find` function."]},{"cell_type":"code","metadata":{"id":"mObF_ssl-oX8"},"source":["# 'find' extracts only first table tag by default\n","table = mountains_wiki_page.find(\"table\")\n","print(table)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Abua4M3NGvfA"},"source":["Extract the headings (`th` tag) of the table from wikipedia page, use `findAll` and extract text for each heading tag"]},{"cell_type":"code","metadata":{"id":"Zv2Uta_E-hvu"},"source":["th = table.findAll(\"th\")            # Find list of 'th' tags\n","headings = [i.text for i in th]     # Extract text from 'th' tags\n","print(headings)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qJD14DzvG1GG"},"source":["Extract data from each row of the table using `tr` tag, and appending text of the current cell (`td` tag) to data and creating a dataframe"]},{"cell_type":"code","metadata":{"id":"MfBXT4Vt_QOF"},"source":["import pandas as pd\n","\n","data = [ ] \n","\n","# Find all the tr tags and extracting data from each row\n","for row in table.findAll(\"tr\"):\n","    data.append([cell.text for cell in row.findAll(\"td\")])\n","\n","# Create a DataFrame of data\n","df = pd.DataFrame(data, columns = headings)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wh0yHRZmIZiP"},"source":["#### Saving a `.csv` file using dataframe"]},{"cell_type":"code","metadata":{"id":"fUG5TrzfFc_j"},"source":["df.to_csv(\"mountains_list_elevation.csv\")"],"execution_count":null,"outputs":[]}]}