{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-DLN-07-AN-3-3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Txc-ZXeexHdw"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n","### Not for Grading"]},{"cell_type":"markdown","metadata":{"id":"JCG961D0xI44"},"source":["#  Word2Vec Similarity"]},{"cell_type":"code","metadata":{"id":"xTqjplgq9XiN","cellView":"form"},"source":["#@title Case Study Walkthrough\n","#@markdown Word2Vec Similarity\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"520\" height=\"440\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_b7_hyd/preview_videos/word2vec_similarity.mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lHQEW2iOxSA4"},"source":["This experiment is to understand the visualization of Word2Vec representations.\n"]},{"cell_type":"code","source":["! wget https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/experiment_related_data/AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.rar\n","! unrar e /content/AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.rar\n","! wget https://www.dropbox.com/s/fm7nvhyvekhaka4/AIML_DS_WORD2VEC2D_STD.pkl.zip?dl=1\n","! mv AIML_DS_WORD2VEC2D_STD.pkl.zip?dl=1 AIML_DS_WORD2VEC2D_STD.pkl.zip\n","! unzip AIML_DS_WORD2VEC2D_STD.pkl.zip\n","    "],"metadata":{"id":"4ACuQlJPuda4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JMqmyyPq4EBH"},"source":["### Importing required packages"]},{"cell_type":"code","metadata":{"id":"aUl92JWHguCa"},"source":["import numpy as np\n","from sklearn.manifold import TSNE\n","import gensim\n","import matplotlib.pyplot as plt\n","import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S3bnXNtelLa8"},"source":["### Loading Word2vec pretrained model"]},{"cell_type":"code","metadata":{"id":"C91b6oxilK2t"},"source":["model = gensim.models.KeyedVectors.load_word2vec_format('AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.bin', binary=True, limit=500000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4IAf2Z5rlKWN"},"source":["words = ['man', 'woman', 'king', 'queen']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"plV9OmuECa0A"},"source":["### Visualising and plotting the reduced word2vec representations"]},{"cell_type":"code","metadata":{"id":"YTu6MKlonVPr"},"source":["def words_plot(words, word_pairs, elev=20, azim=32, dimensions = 3, lines = True):\n","  #print(word_pairs)\n","  embeddings = []\n","  #print(words)\n","  for word in words:\n","    embeddings.append(model[word])\n","  embeddings = np.array(embeddings)\n","  \n","  \n","  if dimensions == 3:\n","    embedding_3d = TSNE(n_components=3).fit_transform(embeddings)\n","\n","    fig = plt.figure(figsize=(10,10))\n","    ax = fig.add_subplot(111, projection='3d')\n","    for index, ( x, y, z) in enumerate(embedding_3d):\n","      ax.scatter(x, y, z, c='r', marker='o')\n","      ax.text(x, y, z, words[index])\n","    if lines:\n","      for pair in word_pairs:\n","        #print(word_pairs)\n","        xplt, yplt, zplt = [], [], []\n","        for word in pair:\n","          #print(word)\n","          sn = words.index(word)\n","          xw,yw,zw = embedding_3d[sn]\n","          xplt.append(xw)\n","          yplt.append(yw)\n","          zplt.append(zw)\n","\n","          ax.plot3D(xplt, yplt,zplt)\n","\n","    ax.set_xlabel('X')\n","    ax.set_ylabel('Y')\n","    ax.set_zlabel('Z')\n","\n","    ax.grid(True)\n","    ax.view_init(elev=elev, azim=azim)\n","    plt.show()\n","    \n","  else:\n","    embedding_2d = TSNE(n_components=2).fit_transform(embeddings)\n","    fig = plt.figure(figsize=(10,10))\n","    ax = fig.add_subplot(111)\n","    for index, ( x, y) in enumerate(embedding_2d):\n","      ax.scatter(x, y, c='r', marker='o')\n","      ax.text(x, y, words[index])\n","    if lines:    \n","      for pair in word_pairs:\n","        xplt, yplt= [], []\n","        for word in pair:\n","          sn = words.index(word)\n","          xw,yw = embedding_2d[sn]\n","          xplt.append(xw)\n","          yplt.append(yw)\n","\n","          ax.plot(xplt, yplt)\n","\n","    ax.set_xlabel('X')\n","    ax.set_ylabel('Y')\n","\n","    ax.grid(True)\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QbbYGvArFnSV"},"source":["def plot_values(values, labels, figsize = (8,4), c = []):\n","    x = []\n","    y = []\n","    for value in values:\n","        x.append(value[0])\n","        y.append(value[1])\n","        \n","    plt.figure(figsize=figsize) \n","    for i in range(len(labels)):\n","        plt.scatter(x[i],y[i], color=c[i])\n","        plt.annotate(labels[i],\n","                     xy=(x[i], y[i]),\n","                     xytext=(5, 2),\n","                     textcoords='offset points',\n","                     ha='right',\n","                     va='bottom')\n","    plt.show()\n","\n","\n","#.pkl file which is already trainied file which contain two dimentional represenatation of a word\n","two_dim_model = pickle.load(open('AIML_DS_WORD2VEC2D_STD.pkl', 'rb'))\n","\n","wv_labels = {}\n","for vec, word in two_dim_model:\n","    wv_labels[word] = vec\n","    \n","colors = ['blue' for i in range(len(wv_labels))]\n","\n","plot_values(wv_labels.values(), list(wv_labels.keys()), figsize = (16, 9), c = colors)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WN6ImoSNFxCP"},"source":["wv_list = ['king', 'queen', 'man', 'woman', 'Germany', 'France', 'Berlin', 'Paris', 'best', 'good', 'strong', 'strongest']\n","wv_new_labels = {}\n","for word in wv_list:\n","    wv_new_labels[word] = wv_labels[word]\n","\n","colors = ['green' for i in range(len(wv_new_labels))]\n","plot_values(wv_new_labels.values(), list(wv_new_labels.keys()), c = colors)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k0oKFTWoClXQ"},"source":["### Representing Man, Woman, King, queen"]},{"cell_type":"code","metadata":{"id":"StmaNMbttKGr"},"source":["words = ['man', 'woman', 'king', 'queen']\n","word_pairs = [['man', 'woman'], ['king', 'queen']]\n","words_plot(words, word_pairs, dimensions=2, lines=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kimuwZhQCvlP"},"source":["### Representing Countries and its capitals"]},{"cell_type":"code","metadata":{"id":"bgaaPI7jtLSb"},"source":["word_pairs =[['Spain', 'Madrid'], ['Italy', 'Rome'], ['Germany', 'Berlin']\n","              , ['Turkey', 'Ankara'], ['Russia', 'Moscow'], ['Canada', 'Ottawa']\n","              , ['Japan', 'Tokyo'], ['Vietnam', 'Hanoi'], ['China', 'Beijing']]\n","words = list(np.array(word_pairs).flatten())\n","words_plot(words, word_pairs, dimensions=2, lines=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ge7co7j9CyDL"},"source":["### Finding the nearest or most similar words of .a word using Word2vec"]},{"cell_type":"code","metadata":{"id":"ea-pZQVB6eDG"},"source":["words = ['France','JESUS', 'XBOX', 'Reddish', 'Scratched', 'MB']\n","for word in words:\n","  print('Top 10 similar words for {} are:'.format(word))\n","  for index,  (similar_word, similarity) in enumerate(model.most_similar(word)):\n","    print(\"\\t {}. {} (similarity is {})\".format(index+1, similar_word, similarity) )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7TE7p3J6BTkZ"},"source":["### Verify Clusters in the Word2vec from the following link:\n","\n","https://projector.tensorflow.org/"]},{"cell_type":"markdown","metadata":{"id":"FxbMMogcC_y8"},"source":["### Understand the semantics preserved by Word2vec by chosing the words along x and y axis to represents the other words in that co-oridinate system\n","\n","https://lamyiowce.github.io/word2viz/"]}]}