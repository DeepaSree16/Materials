{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-DLN-07-AS-1-1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Txc-ZXeexHdw"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"JCG961D0xI44"},"source":["### Learning Objectives:\n","\n","At the end of the experiment, you will be able to:\n","\n","*  generate the vectors for the given words\n","*  find the similarities between the words\n"]},{"cell_type":"code","metadata":{"id":"hzM6Pm7F5nmz","cellView":"form"},"source":["#@title Experiment Walkthrough Video\n","#@markdown Word2vec similarity\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"520\" height=\"440\" controls>\n","  <source src=\"https://cdn.exec.talentsprint.com/content/2021-06-08_iiith_aiml_word2vec_similarity.mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! wget https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/experiment_related_data/AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.rar\")\n","! unrar e /content/AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.rar\")\n","! wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Word2Vec_Similarity/dimensionality_reduction.py\")"],"metadata":{"id":"b_ceV9emvkk6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JMqmyyPq4EBH"},"source":["### Importing required packages"]},{"cell_type":"code","metadata":{"id":"aUl92JWHguCa"},"source":["import numpy as np\n","import gensim\n","import matplotlib.pyplot as plt\n","from sklearn.metrics.pairwise import cosine_similarity"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RgY07csR3Ku7"},"source":["### Representation using Word2Vec pre-trained model"]},{"cell_type":"markdown","metadata":{"id":"S3bnXNtelLa8"},"source":["Load Gensim pretrained model\n","\n","  * Gensim is an open source Python library for natural language processing. It is developed and is maintained by the Czech natural language processing researcher Radim Rehurek and his company RaRe Technologies. \n","\n","  * Use gensim to load a word2vec model, pretrained on google news, covering approximately 3 million words and phrases. The vector length is 300 features.\n","\n","  * Download the google news bin file with the limit 500000 words and save in a binary word2vec format. If **binary = True**, then the data will be saved in binary word2vec format, else it will be saved in plain text."]},{"cell_type":"code","metadata":{"id":"C91b6oxilK2t"},"source":["# Load 300 vectors directly from the file. As the model is in .bin extension, we need to enable default parameter, binary = True\n","model = gensim.models.KeyedVectors.load_word2vec_format('AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.bin', binary=True, limit=500000)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mEDZysQDTup7"},"source":["Develop Word Embedding for the given list of words"]},{"cell_type":"code","metadata":{"id":"FcvNBc-lOymK"},"source":["words_list = ['India','Delhi','Turkey', 'Ankara', 'Russia', 'Moscow','Japan', 'Tokyo', 'Vietnam', 'Hanoi','China', 'Beijing']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wht_bq83P6ko"},"source":["vect = []\n","for word in words_list:\n","    # Getting vectors of the each word and appending to the list\n","    vect.append(model[word])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-RE1T0dDRd8x"},"source":["###  Visualization and Plotting the reduced Word2Vec representation"]},{"cell_type":"markdown","metadata":{"id":"mEsC9BGORuit"},"source":["The vector size of the given words is 300. To plot the words in 2 dimensions, reduce the  dimensionality of the 300-dimensional vectors to 2 dimensions.\n"]},{"cell_type":"code","metadata":{"id":"Jk16WgM4AUvb"},"source":["from dimensionality_reduction import reduce_dimensions\n","\n","reduced_vector = reduce_dimensions(vect)\n","len(reduced_vector), len(reduced_vector[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9HvqTk4-SdJ_"},"source":["\n","Visualize the words in 2D-plane"]},{"cell_type":"code","metadata":{"id":"ICHyR9AcTUSP"},"source":["plt.figure(figsize=(16,5))\n","plt.scatter(reduced_vector[:,0],reduced_vector[:,1])\n","x, y = reduced_vector[:,0] , reduced_vector[:,1]\n","\n","for i in range(len(x)):\n","  plt.annotate(words_list[i],xy=(x[i], y[i]), xytext=(x[i]+0.02, y[i]+0.02))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bMK9lUwUToH2"},"source":["### Finding the cosine similarity  between the two words "]},{"cell_type":"code","metadata":{"id":"pQ47aWe5TvJ7"},"source":["# As the vectors are in one dimensional, convert it to 2D by reshaping\n","cosine_similarity(model['Tokyo'].reshape(1,-1), model['Japan'].reshape(1,-1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JaSnKLNLT4jY"},"source":["### Finding the nearest or most similar words of a given word using Word2vec"]},{"cell_type":"code","metadata":{"id":"_J-xzybTT2_U"},"source":["model.most_similar('Tokyo', topn=5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Me61wEr-X8gv"},"source":[" A cosine value of 0 means that the two vectors are at 90 degrees to each other (orthogonal) and have no match. The closer the cosine value to 1, the smaller the angle and the greater the match between vectors."]},{"cell_type":"markdown","metadata":{"id":"jaEYuN7r4qnp"},"source":["### Ungraded Exercises"]},{"cell_type":"markdown","metadata":{"id":"-jtKmf5zU3xc"},"source":["### Exercise 01: For the below given words, generate the vectors and visualize them in 2D"]},{"cell_type":"code","metadata":{"id":"PGJqXD3zVk9Y"},"source":["words = ['king', 'queen', 'man', 'woman', 'best', 'good', 'strong', 'strongest']\n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N11qKRYPXAWy"},"source":["### Exercise 02: Find the cosine similarity for 'king' and 'ruler'"]},{"cell_type":"code","metadata":{"id":"oGw8GxbiW-c2"},"source":["# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kNv2Ry4tXjG0"},"source":["###Exercise 03: Find top 5 nearest or most similar words of a word 'king'"]},{"cell_type":"code","metadata":{"id":"AkeaftgXXrhQ"},"source":["# YOUR CODE HERE"],"execution_count":null,"outputs":[]}]}