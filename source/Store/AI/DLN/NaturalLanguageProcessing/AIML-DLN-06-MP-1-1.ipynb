{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-DLN-06-MP-1-1.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"PsKRUcQh27Dp"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"C3BQbYtN2-5L"},"source":["## Problem Statement"]},{"cell_type":"markdown","metadata":{"id":"DP5Nf6UZ3Ej1"},"source":["The problem is to identify the subcategory and classify the question based on the group it belongs to.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WeHg23di3oHF"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"27fwuBVS3tF3"},"source":["At the end of the experiment, you will be able to understand:\n","\n","*   Beautiful Soup\n","*   Use NLTK package\n","*   Text Representation\n","*   Classification"]},{"cell_type":"markdown","metadata":{"id":"FL0Ve1abn6YJ"},"source":["## Dataset\n","Being able to classify the questions will be difficult in natural language processing. The dataset is taken from the TalentSprint aptitude questions which contains more than 20K questions.\n","\n","## Description\n","This dataset has the following columns:\n","1. **Category:** Gives the high-level categorization of the question\n","2. **Sub-Category:** Determines the type of questions\n","3. **Article:** Gives the article name of the question\n","4. **Questions:** Questions are listed\n","5. **Answers:** Contains answers\n"]},{"cell_type":"markdown","metadata":{"id":"ndQNKsjS7c04"},"source":["### Grading = 20 Marks"]},{"cell_type":"code","source":["! wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Aptitude_Classification_data.csv\n","! wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Mentors_Test_Data.csv"],"metadata":{"id":"Kox0qpmDQNUV"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WYyfIzohaMMC"},"source":["# Import Python Libraries\n","from bs4 import BeautifulSoup\n","import nltk\n","import re\n","import string\n","import warnings\n","import numpy as np\n","import pandas as pd\n","from collections import Counter\n","from nltk import word_tokenize\n","from nltk.corpus import stopwords\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","warnings.filterwarnings('ignore')\n","nltk.download('punkt')\n","nltk.download(\"stopwords\")\n","nltk.download('averaged_perceptron_tagger')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2DKmejLMh2YH"},"source":["##   **Stage 1**:  Dataset Preparation\n","\n","### 1 Mark -> Load the data set and prepare the data based on group allocation. \n","\n","Each group should consider their respective sub-categories as mentioned below:\n","\n","> Team A = Groups 1, 4, 7, 10;   &nbsp; &nbsp; Sub-Category = Misspell words, Algebra, Percentages, Mathematical operations, Probability\n","\n","> Team B = Groups 2, 5, 8, 11; &nbsp; &nbsp;   Sub-Category = Finding Errors, Ratio and Proportion, Logarithms, Time and Distance, Simple and Compound Interest\n","\n","> Team C = Groups 3, 6, 9, 12;  &nbsp; &nbsp;  Sub-Category =  Synonyms and Antonyms, Time and Work, Permutations and Combinations, LCM and HCF, Profit and Loss\n","\n","\n","**Hint:** &nbsp; To access Sub-Categories from given Data, refer [link](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isin.html)"]},{"cell_type":"code","metadata":{"id":"rZ1vto-DAAvZ"},"source":["# YOUR CODE HERE TO LOAD THE APTITUDE CLASSIFICATION DATASET & EXTRACT THE DATA BASED ON YOUR SUB-CATEGORIES"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5RzclUxhkn67"},"source":["## **Stage 2:** Data Pre-Processing\n","\n","### 3 Marks -> Clean and Transform the data into a specified format\n","\n","*   Remove the rows of the Questions column which contains blank / NaN.\n","\n","\n","*   Few set of questions have HTML tags within the question.\n","  - You can use Beautiful Soup library to convert HTML into text (Refer **\"Dealing with HTML\"** section from this [link](https://www.nltk.org/book/ch03.html).)\n","\n","\n","*  Consider Question column as feature and Sub-category as target variable. Convert Sub-category into numerical.\n","\n","*  Drop the unwanted columns\n","\n","\n","  **Hint:** Use Label Encoder for obtaining a numeric representation, refer to the [link](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). "]},{"cell_type":"code","metadata":{"id":"Whj-50DlTwyZ"},"source":["# YOUR CODE HERE for BeatifulSoup"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VaMiP9gextc5"},"source":["from sklearn import preprocessing\n","le = preprocessing.LabelEncoder() # DO NOT CHANGE THIS LINE as we will be using for the Test evaluation.\n","\n","# YOUR CODE HERE for Fit label encoder and return encoded labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7AOtxyuBtdKv"},"source":["## **Stage 3:** Text representation using Bag of Words (BOW)\n","\n","### 3 Marks -> a) Get valid words from all questions & add them to a list.\n","\n","\n","Treat each question as a separate document and get the list of words using the following:\n","1.   Split the sentence into words\n","\n","2.   Remove Stop words. Use NLTK packages for getting the Stop words.\n","\n","3.   Replace proper names with \"name\" \n","  - Example: \"Rahul\" -> \"name\"\n","       \n","4.   Remove the single white space character (\\n, \\t, \\f, \\r), refer [link](https://developers.google.com/edu/python/regular-expressions)\n","\n","5.   Ignore words whose length is less than 3 (Eg: 'is', 'a').\n","\n","6.   Remove punctuation and non-alphabetic words\n","\n","7.   Convert the text to lowercase\n","\n","8.   Use the Porter Stemmer to normalize the words\n","\n","\n","Refer [link](https://www.nltk.org/book/ch03.html) for extracting the words.\n","\n","Refer to the below links for more information.\n","\n","1. [link1](https://medium.com/free-code-camp/an-introduction-to-bag-of-words-and-how-to-code-it-in-python-for-nlp-282e87a9da04)\n","\n","2. [link2](https://dataaspirant.com/bag-of-words-bow/)"]},{"cell_type":"code","metadata":{"id":"jLyMy2q9rGK_"},"source":["def extract_words(question):\n","    # YOUR CODE HERE\n","    # Hint: Extract words for each question using the above 8 instructions."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C_eiynShd7bK"},"source":["def tokenize(allquestions):\n","  valid_words = []\n","  for question in allquestions:\n","    words = extract_words(question)\n","    valid_words.extend(words)\n","  return set(valid_words)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ty4DphvV7oM"},"source":["# Use the function to extract words for all questions\n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9csJ86Bivg1H"},"source":["### 4 Marks -> b) Generate vectors that can be used by the machine learning algorithm\n","\n","\n","1.   The length of the vector for each question will be the length of the valid words. Initialize each vector with all Zeros\n","\n","2.   Compare each valid word with the words in question and generate the vectors based on the counter frequency of the word in that question.\n","\n"]},{"cell_type":"code","metadata":{"id":"gbV4VzDOLQ4X"},"source":["def generate_vectors(question):\n","    # YOUR CODE HERE\n","    # Hint: Initialize each vector with all zeros. \n","    \n","\n","    # Extracting words for each question and count the words\n","    words = extract_words(question)\n","    word_dict = Counter(words)\n","    \n","    # YOUR CODE HERE \n","    # Hint: If the word is in valid words then generate the vectors based on the counter frequency of the word in that question.\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mnQEkbj--Zof"},"source":["# Use the above function for collecting the vectors of all questions into a list.\n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I-Og4IX5ZYRm"},"source":["## **Stage 4:** Classification\n","\n","### 3 Marks -> Perform a Classification \n","\n","1.   Identify the features and labels\n","\n","2.   Use train_test_split for splitting the train and test data\n","\n","3.   Fit your model on the train set using fit() and perform prediction on the test set using predict()\n","\n","4. Get the accuracy of the model\n","\n","## Expected Accuracy above 90%\n"]},{"cell_type":"code","metadata":{"id":"FjlN6HSMQkqm"},"source":["from sklearn.model_selection import train_test_split\n","# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"nz6zjx3yYnY8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BHxULg4OggQe"},"source":["## **Stage 5:** Evaluation (This is for Mentors)\n","\n","### 6 Marks -> Evaluate with the given test data \n","\n","1.  Loading the Test data\n","\n","2.  Converting the Test data into vectors\n","\n","3.  Pass through the model and verify the accuracy\n","\n","## Expected Accuracy above 90%\n"]},{"cell_type":"code","metadata":{"id":"BWM4Boa4zXAs"},"source":["# YOUR CODE HERE for selecting the trained classifier model, eg: MODEL = decision_tree\n","MODEL = #ENTER YOUR MODEL\n","\n","Test_data = pd.read_csv(\"Mentors_Test_Data.csv\")\n","Test_data = Test_data[Test_data['Sub-Category'].isin(le.classes_)]\n","labels = le.transform(Test_data['Sub-Category'])\n","Test_questions= Test_data['Questions']\n","\n","Test_BOW=[]\n","for TQ in Test_questions: \n","  Test_vectors = generate_vectors(TQ) \n","  Test_BOW.append(Test_vectors)\n","\n","predict = MODEL.predict(Test_BOW) \n","accuracy_score(labels, predict)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3hHL5Biz_SR"},"source":[""],"execution_count":null,"outputs":[]}]}