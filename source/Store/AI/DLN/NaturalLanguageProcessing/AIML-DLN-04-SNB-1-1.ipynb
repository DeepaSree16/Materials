{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-DLN-04-SNB-1-1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RWR22OAlTBlU"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n","\n"]},{"cell_type":"markdown","metadata":{"id":"u1zKf9UCTFQW"},"source":["### Not for Grading"]},{"cell_type":"markdown","metadata":{"id":"fcOK1wB_sCou"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"yETAUjEur-48"},"source":["At the end of the experiment, you will be able to\n","\n","*   Understand Beautiful Soup\n","*   Use NLTK package"]},{"cell_type":"markdown","metadata":{"id":"0nIAXZNu7WlT"},"source":["### Beautiful soup\n","\n","Beautiful Soup is a Python library for pulling data out of HTML files.\n","\n","### NLTK \n","\n","NLTK is a package in python that provides libraries for different text processing techniques, such as classification, tokenization, stemming, parsing and pos tagging"]},{"cell_type":"code","source":["! wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/ipl.csv\n"],"metadata":{"id":"DkhXyMQYwWDC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HLktlfV0TsBZ"},"source":["### Importing required packages\n"]},{"cell_type":"code","metadata":{"id":"9qnzJ-Aclz5D"},"source":["import requests                                 # request is a library to send HTTP request in Python\n","from bs4 import BeautifulSoup as bs             # BeautifulSoup makes it easy to scrape information from web pages\n","from nltk.tokenize import word_tokenize         # word_tokenize() method is to split a sentence into tokens or words\n","from nltk.tokenize import sent_tokenize         # sent_tokenize() is to split a document or paragraph into sentences\n","import string\n","import nltk\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a2EYU92sKaZL"},"source":["### Extract data from HTML using Beautiful Soup"]},{"cell_type":"code","metadata":{"id":"11pc2ApmDSMh"},"source":["# Specify the url\n","url= \"http://shakespeare.mit.edu/allswell/full.html\"\n","\n","# Make a request to a web page and print the response text\n","try:\n","    r = requests.get(url)\n","    soup = bs(r.content, 'lxml')\n","except:\n","  pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tmnN06a7Epw0"},"source":["text = soup.get_text()\n","text"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tGOnHkKZLNYh"},"source":["### Normalizing Text\n","\n","\n","From the given text, replace newline characters '\\n' with \" \" and convert the text to lowercase\n","\n","Hint: use .replace for replacing the '\\n' and .lower() for converting text to lowercase"]},{"cell_type":"code","metadata":{"id":"aEpE9x9FOmzh"},"source":["# YOUR CODE HERE\n","text = text.replace('\\n',\" \")\n","text = text.lower()\n","print(text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GdOS0uHlFWNV"},"source":["### Tokenization\n"]},{"cell_type":"code","metadata":{"id":"DzvsA_81GZjS"},"source":["nltk.download('punkt')\n","nltk.download('wordnet')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-78Q2AbvOnoB"},"source":["Sentence Level Tokenization\n"]},{"cell_type":"code","metadata":{"id":"6594Cua5OzSK"},"source":["sen_token = sent_tokenize(text)\n","len(sen_token)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ANCIDJB7zWI7"},"source":["sen_token[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hCRxhW_NYxUN"},"source":["Remove Punctuations after sentence tokenize"]},{"cell_type":"code","metadata":{"id":"14tZpUVqYz5K"},"source":["for i, sent in enumerate(sen_token):\n","  sen_token[i] = sent.translate(str.maketrans('', '', string.punctuation))\n","print(sen_token[10])        # print for 10th sentence and verify the punctuation removal"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HsqxaFZhZ87K"},"source":["Average sentence length"]},{"cell_type":"code","metadata":{"id":"Er0wPUprZ8im"},"source":["len_sent = [len(sent.split()) for i, sent in enumerate(sen_token)]\n","Avg_Sent = sum(len_sent)//len(len_sent)\n","print(\"Average sentence length of shakespeare is \", Avg_Sent)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SaeN09igYdRG"},"source":["### Word Level Tokenization\n","\n","Process of converting total text into words"]},{"cell_type":"code","metadata":{"id":"uM_NJE5tFHxT"},"source":["wtokens = word_tokenize(text)\n","print(word_tokenize(text))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X10WI_D4cyL_"},"source":["Remove Punctuations  after word tokenize"]},{"cell_type":"code","metadata":{"id":"FhPW-f9ecLrF"},"source":["# Remove punctuation from each token\n","table = str.maketrans('', '', string.punctuation)\n","wtokens = [w.translate(table) for w in wtokens]\n","wtokens = [w for w in wtokens if len(w) >= 1]\n","wtokens"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4jFCG5hYG9sz"},"source":["### Stemming\n","\n","Stemming is the process of converting the words of a text to its non-changing portions.\n","\n","Hint: Refer to the following link for [Stemmer](https://www.nltk.org/book/ch03.html)"]},{"cell_type":"code","metadata":{"id":"c4m-19AHoTZB"},"source":["porter = nltk.PorterStemmer()\n","# YOUR CODE HERE: Apply stemmer for wtokens\n","stem = [porter.stem(i) for i in wtokens]\n","print(stem)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8BUfwJ8yHuNu"},"source":["#### Lemmatization\n","\n","Lemmatization is the process of converting the words of a sentence to its dictionary form\n","\n","Hint: Refer to the following link for [Lemmatizer](https://www.nltk.org/book/ch03.html)"]},{"cell_type":"code","metadata":{"id":"oD2yqJI6HsJi"},"source":["lemma = nltk.WordNetLemmatizer()\n","# YOUR CODE HERE: Apply lemmatize for wtokens\n","lemmatizer = [lemma.lemmatize(i) for i in wtokens]\n","print(lemmatizer[20:40])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0UjYDKMsI7fR"},"source":["#### Remove Stopwords\n","\n","Hint: Refer to the following link for [Stopwords](https://stackabuse.com/removing-stop-words-from-strings-in-python/)"]},{"cell_type":"code","metadata":{"id":"T-vqqChQi8tx"},"source":["nltk.download('stopwords')\n","from nltk.corpus import stopwords  \n","stop_words = set(stopwords.words('english')) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4DqUaU1JEpg"},"source":["stop_words_removed = []\n","# YOUR CODE HERE: Use NLTK packages for getting the Stop words and remove stopwords from wtokens\n","for i, word in enumerate(wtokens):\n","  if word not in stop_words:\n","    stop_words_removed.append(word)\n","stop_words_removed[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7O37sarOcalJ"},"source":["#### Parts of Speech:\n","\n","\n","Given any sentence, you can classify each word as a noun, verb, conjunction, or any other class of words. When there are hundreds of thousands of sentences, even millions, this is obviously a large and tedious task. But it's not one that can't be solved computationally. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"iPSoIDtpg2WG"},"source":["nltk.download('averaged_perceptron_tagger')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s5zlHD9WnNR6"},"source":["To know what is DT, JJ, or any other tags, use below code to verify\n"]},{"cell_type":"code","metadata":{"id":"sxP1wQwFnNSB"},"source":["nltk.download('tagsets')\n","nltk.help.upenn_tagset('NN')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NfCknvySTH1E"},"source":["Print the parts of speech for the first 20 wtokens using pos_tag \n","\n","Hint: Refer to the following link for[ parts of speech](https://www.nltk.org/book/ch05.html)"]},{"cell_type":"code","metadata":{"id":"b7JiEUnHcaNq"},"source":["# YOUR CODE HERE\n","pos = nltk.pos_tag(wtokens[:20])\n","print(pos)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FouUAfWzTAPA"},"source":["Get the count of NN tag from first 20 words"]},{"cell_type":"code","metadata":{"id":"S9MkCPfsTjKL"},"source":["# YOUR CODE HERE\n","a = [i for i in pos if i[1] == 'NN']\n","print(len(a))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5uHx-2ck36QA"},"source":["Get the count of VBP tag from first 20 words"]},{"cell_type":"code","metadata":{"id":"8oVeOQKY4QN1"},"source":["# YOUR CODE HERE\n","a = [i for i in pos if i[1] == 'VBP']\n","print(len(a))"],"execution_count":null,"outputs":[]}]}