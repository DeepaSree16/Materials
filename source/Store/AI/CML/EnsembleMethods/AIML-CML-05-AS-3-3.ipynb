{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-CML-05-AS-3-3.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"x3A2XBqYQg-N"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n","### Not for Grading"]},{"cell_type":"markdown","metadata":{"id":"Jw4QHJlfsSF4"},"source":["## Learning Objectives\n"]},{"cell_type":"markdown","source":["At the end of the experiment you will be able to:\n","* apply different learning algorithms on **Titanic** dataset\n","* perform VotingClassifier"],"metadata":{"id":"EsSB95vPsoxS"}},{"cell_type":"markdown","metadata":{"id":"Nh70dVHx0G_B"},"source":["## Dataset Description"]},{"cell_type":"markdown","metadata":{"id":"y-GMJTRb0Iyy"},"source":["The sinking of the Titanic is one of the most infamous shipwrecks in history.\n","\n","On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of many passengers and crew.\n","\n","While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n","\n","Build a predictive model that answers the question: “what sort of people were more likely to survive?” using titanic's passenger data (ie name, age, gender, socio-economic class, etc).\n","\n","<br/>\n","\n","### Data Set Characteristics:\n","\n","**PassengerId:** Id of the Passenger\n","\n","**Survived:** Survived or Not information\n","\n","**Pclass:** Socio-economic status (SES)\n","  * 1st = Upper\n","  * 2nd = Middle\n","  * 3rd = Lower\n","\n","**Name:** Surname, First Names of the Passenger\n","\n","**Sex:** Gender of the Passenger\n","\n","**Age:** Age of the Passenger\n","\n","**SibSp:**\tNo. of siblings/spouse of the passenger aboard the Titanic\t\n","\n","**Parch:**\tNo. of parents / children of the passenger aboard the Titanic\t\n","\n","**Ticket:**\tTicket number\n","\n","**Fare:** Passenger fare\n","\n","**Cabin:**\tCabin number\n","\n","**Embarked:** Port of Embarkation\n","  * S = Southampton\n","  * C = Cherbourg\n","  * Q = Queenstown\n"]},{"cell_type":"code","source":["!wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/titanic.csv"],"metadata":{"id":"Ivy3LZfJN17o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gn6HQH7abkyL"},"source":["## Import Required Packages"]},{"cell_type":"code","metadata":{"id":"eiNOMhdK5n-d"},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import VotingClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g5fBLdQaJtd4"},"source":["### Exercise 01: Load the data\n","\n","* Understand different features in the training dataset\n","\n","* Drop the unwanted columns, which are unlikely to contribute for the prediction of Survived\n"]},{"cell_type":"code","metadata":{"id":"sW9DMblWkhj_"},"source":["# Load the dataset\n","data = pd.read_csv(\"titanic.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"54ktmr8lh8AS"},"source":["# Print first ten records\n","data.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TNVlsUHJbtai"},"source":["# Drop the unwanted columns, specifying axis=1\n","data = data.drop([\"Name\",\"Ticket\",\"Fare\",\"Cabin\",\"SibSp\",\"Parch\"], axis=1)\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-pMXWDyaspe3"},"source":["### Exercise 02: Data Cleaning \n","\n","* Find out the missing values for each column\n","\n","    * Hint: pd.isnull( )\n","* Remove the missing values for the \"Age\" and \"Embarked\" column from the above data set\n","\n","    * For Age, replace the missing values with mean\n","    * For Embarked, replace the missing values with mode"]},{"cell_type":"code","metadata":{"id":"mv3l8T2LsubX"},"source":["features = list(data.columns.values)\n","\n","for feat in features:\n","    print (feat,\": \",sum(pd.isnull(data[feat])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BcaeORO9e6N1"},"source":["# Calculate the mean of Age column\n","data[\"Age\"].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqsOUDSr72wi"},"source":["data[\"Age\"] = data[\"Age\"].fillna(data[\"Age\"].mean())\n","data[\"Age\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bBvO-EsXe4k9"},"source":["# Calculate the mode of Age column\n","data[\"Embarked\"].mode()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F-QeenvrfBts"},"source":["data[\"Embarked\"] = data[\"Embarked\"].fillna(\"s\")\n","data[\"Embarked\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ID4c_m2yfhtQ"},"source":["sum(pd.isnull(data[\"Embarked\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8R6FqRagSyLV"},"source":["### Exercise 03: Convert categorical values to numerical \n","\n","*  Sex feature contains categorical values such as male and female then replace them with 1, 2 \n","\n","*  Embarked feature contains categorical values such as `S` and` s`. Replace 's' with 'S'\n","\n","*  Embarked feature contains categorical values such as S, C and Q  then  replace with 1, 2, 3"]},{"cell_type":"code","metadata":{"id":"N5dU5ucVS2t1"},"source":["# Convert categorical values to numerical using replace\n","data = data.replace('male', 1)\n","data = data.replace('female', 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BGKRFAV3uN3T"},"source":["data[\"Embarked\"].unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lp4qSwMHWtBE"},"source":["data = data.replace('s','S')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"twyckatIijA_"},"source":["data = data.replace(['S','C','Q'],[1,2,3])\n","data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QRypkIrUuKyQ"},"source":["### Exercise 04:  Consider the labels as survived  and the remaining as the features \n","\n","* Find the shape of the features and labels\n"]},{"cell_type":"code","metadata":{"id":"3vfJEIMcxGHb"},"source":["X1 = data.drop('Survived',axis=1) # Features\n","y1 = data['Survived']  # Labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H8bKJWW5lBoh"},"source":["print(X1.head())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWhrrYmqlE7C"},"source":["print(X1.shape, y1.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PR3RfiHQQoOa"},"source":["### Exercise 05:  Split the data into train and test sets \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"AmVALdqKP9M8"},"source":["X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"73corzSCq6xH"},"source":["print(X_train.shape,X_test.shape, y_train.shape, y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iZyh0FCev03p"},"source":["### Exercise 06: Perform Ensemble Technique \n","\n","\n","* Create LogisticRegression, Decision Tree and SVC object\n","\n","* Apply Voting Classifier for LogisticRegression, Decision Tree and SVC\n","\n","* Fit the model with X_train and y_train\n","\n","* Predict the model for X_test \n","\n","* Find the accuracy using sklearn metrics for actual response values (y_test) and predicted response values (y_pred) \n","\n","Hint: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html"]},{"cell_type":"code","metadata":{"id":"kEnxXSMdv36J"},"source":["# Create an object for all the algorithms\n","model1 = LogisticRegression()\n","model2 = DecisionTreeClassifier()\n","model3 = SVC()\n","\n","# Apply VotingClassifier\n","model = VotingClassifier(estimators = [('LR', model1), ('DT', model2), ('SVC',model3)])\n","\n","# Fit the model\n","model.fit(X_train,y_train)\n","\n","# Predict the model\n","y_pred = model.predict(X_test)\n","\n","# Calculate the accuracy\n","print(\"Accuracy(in %):\", accuracy_score(y_test, y_pred)*100)"],"execution_count":null,"outputs":[]}]}