{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-CML-05-AN-2-2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VosP8kS9rvlU"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n","## Not for grading"]},{"cell_type":"markdown","metadata":{"id":"-WChjDMH6K-v"},"source":["## Dataset "]},{"cell_type":"markdown","metadata":{"id":"62AAQoRKrQIK"},"source":["#### Description\n","The Iris dataset consists of 150 data instances. There are 3 classes (Iris Versicolor, Iris Setosa and Iris Virginica) each have 50 instances. \n","\n","\n","For each flower we have the below data attributes \n","\n","- sepal length in cm\n","- sepal width in cm\n","- petal length in cm\n","- petal width in cm\n","\n","To make our experiment easy we rename the classes  with numbers : \n","\n","    \"0\": setosa\n","    \"1\": versicolor\n","    \"2\": virginica"]},{"cell_type":"code","source":["!wget https://cdn.talentsprint.com/aiml/Experiment_related_data/Iris.csv"],"metadata":{"id":"1DGyqGZaev02"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"--kkd7_VOi3B"},"source":["### Import required packages"]},{"cell_type":"code","metadata":{"id":"e1xwihoPLM1_"},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.utils import resample\n","from sklearn import metrics"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DczL6DB8LM2K"},"source":["### Load the data"]},{"cell_type":"code","metadata":{"id":"fOe4HSmiLM2O"},"source":["# Load the iris dataset\n","iris = pd.read_csv(\"Iris.csv\")\n","iris = iris.drop(\"Id\",axis=1)\n","iris.head()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uakhwE4KLM2W"},"source":["# Species from Iris dataset\n","iris.species.unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CToHtpBULM2e"},"source":["# Convert the labels to numericals\n","converter = {\"Iris-setosa\":0, \"Iris-versicolor\": 1,\"Iris-virginica\":2}\n","iris[\"species\"] = [converter [i] for i in iris[\"species\"]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LZYBH9CvLM2k"},"source":["# Split the data into train and test data\n","train_data, test_data = train_test_split(iris, test_size=0.2, random_state=42) \n","len(train_data), len(test_data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sotj49EfLM20"},"source":["### Sampling with replacement"]},{"cell_type":"code","metadata":{"id":"ch4tlKwMLM21"},"source":["# Function to create 5 subsets with replacement. nTimes = No. of Subsets; howmany = No. of samples in a subset\n","\n","def select_samples(nTimes, howmany, train_data):\n","  subsets = []\n","  for i in range(nTimes):\n","    subset_i = resample(train_data, n_samples=howmany, replace=True)\n","    subsets.append(subset_i)\n","\n","    # To find number of unique samples in a subset\n","    unique_samples = len(np.unique(subset_i, axis=0))\n","\n","    # To find no. of repeated samples in a subset\n","    repeated_samples = len(subset_i)-len(np.unique(subset_i, axis=0))\n","       \n","    print(\"D%d has %d samples in which %d are unique samples and %d are repeated samples\" %(i,len(subset_i), unique_samples, repeated_samples))\n","  return subsets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VJDIGehCLM27"},"source":["# Call the above function to create 5 subsets for train data, each of size 120\n","subsets = select_samples(5, 120, train_data) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EOtpsq4OLM3C"},"source":["# Initialize the Decision tree\n","decision_tree = DecisionTreeClassifier(max_depth=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yne39dZ_ctUr"},"source":["# Classify each subset using Decision tree\n","def DT_subset(train_data, test_data, model):\n","  \n","  # Extract features and labels of the train_data and test_data\n","  X_train = train_data.iloc[:,:-1]\n","  y_train = train_data.iloc[:, -1] \n","  X_test = test_data.iloc[:,:-1]\n","  y_test = test_data.iloc[:,-1]\n","  \n","  model.fit(X_train, y_train)\n","  y_pred = model.predict(X_test)\n","  score = metrics.accuracy_score(y_pred, y_test)\n","  \n","  return model, score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LNK1zRjWw3mM"},"source":["# Calculate accuracy for each subset\n","for i,each in enumerate(subsets):\n","    model, score = DT_subset(each, test_data, decision_tree)\n","    print(\"Accuracy for {} subset: {}\".format(i, score))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wsyn--Op3TdP"},"source":["print(\"Actuals and Predictions of 30 test samples\")\n","test_labels = test_data.iloc[:, -1].astype(int)\n","\n","# Create a dictionary for storing the labels\n","labels_30 = {\"actual_values\": test_labels}\n","\n","# Get the prediction labels of 30 samples for all subsets\n","for i in range(1,6):\n","  model,score = DT_subset(subsets[i-1], test_data, decision_tree)\n","  print(\"Subset_\",i, \"Accuracy is\", score)\n","  test_features = test_data.iloc[:,:-1]\n","  y_pred30 = model.predict(test_features)\n","  pred_30 = y_pred30.astype(int)\n","  labels_30[\"subset\"+ str(i)] = pred_30\n","  \n","# Create a dataframe of 30 test samples with actuals and predictions of all 5 subsets\n","df_test = pd.DataFrame(labels_30)\n","df_test"],"execution_count":null,"outputs":[]}]}