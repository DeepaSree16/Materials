{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-CML-10-AS-3-3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HjrYIpy2yYbI"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n","\n"]},{"cell_type":"markdown","metadata":{"id":"x77SzRGJcY3o"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"UKB4OmrMccgl"},"source":["At the end of the experiment,  you will be able to :\n","\n","* Understand how to derive Eigen faces using PCA\n","* Use the PCA features for classification purpose"]},{"cell_type":"code","metadata":{"id":"YGXM1QVJnGcI","cellView":"form","executionInfo":{"status":"ok","timestamp":1640243901415,"user_tz":-330,"elapsed":27,"user":{"displayName":"Sumanth Kalyan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16310973513670246647"}},"outputId":"bee47b66-3bc5-47e0-fc0b-54410f4603e5","colab":{"base_uri":"https://localhost:8080/","height":521}},"source":["#@title Experiment Walkthrough Video\n","\n","from IPython.display import HTML\n","HTML(\"\"\"<video width=\"854\" height=\"480\" controls>\n","<source src=\"https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/aiml_2018_b7_hyd/experiment_details_backup/pca_with_eigen_faces.mp4\" type=\"video/mp4\">\n","</video>\"\"\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<video width=\"854\" height=\"480\" controls>\n","<source src=\"https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/aiml_2018_b7_hyd/experiment_details_backup/pca_with_eigen_faces.mp4\" type=\"video/mp4\">\n","</video>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"nFEZUAvJdXcW"},"source":["\n","\n","## Dataset"]},{"cell_type":"markdown","metadata":{"id":"_reikMZBdZ0o"},"source":["### Description \n","\n","The dataset chosen for this experiment is a preprocessed excerpt of the “Labeled Faces in the Wild”, aka LFW. \n","\n","Labeled Faces in the Wild, a database of face photographs designed for studying the problem of unconstrained face recognition. The data set contains more than 13,000 images of faces collected from the web. Each face has been labeled with the name of the person pictured. 1680 of the people pictured have two or more distinct photos in the data set. The only constraint on these faces is that they were detected by the Viola-Jones face detector. "]},{"cell_type":"markdown","metadata":{"id":"RlGNyzR5fsxQ"},"source":["## AI / ML Technique"]},{"cell_type":"markdown","metadata":{"id":"Vy4vk5Fdfwg3"},"source":["### Eigen Faces\n","\n","Eigenfaces is the name given to a set of eigenvectors when they are used in the computer vision problem of human face recognition. The approach of using eigenfaces for recognition was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland in face classification. The eigenvectors are derived from the covariance matrix of the probability distribution over the high-dimensional vector space of face images. The eigenfaces themselves form a basis set of all images used to construct the covariance matrix. This produces dimension reduction by allowing the smaller set of basis images to represent the original training images. Classification can be achieved by comparing how faces are represented by the basis set."]},{"cell_type":"markdown","metadata":{"id":"_R_HrXRcyYbL"},"source":["### Importing Required Packages"]},{"cell_type":"code","metadata":{"id":"BBg8NqofzFy3"},"source":["from time import time\n","import matplotlib.pyplot as plt\n","\n","# Importing Sklearn Packages\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import fetch_lfw_people\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import accuracy_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gmjym9DFJwF_"},"source":["### Download the data\n","\n","Load the Labeled Faces in the Wild (LFW) people dataset, To know more about LFW people dataset refer [link](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html)"]},{"cell_type":"code","metadata":{"id":"t3BSxmnXJvgJ"},"source":["# Loading and Downloading data from sklearn \n","lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n","\n","# Storing images arrays shapes (for plotting)\n","n_samples, h, w = lfw_people.images.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CLB7CpEw2j0x"},"source":["`lfw_poeple` provides various attributes, where in `lfw_people.images` is the features of 3-dimensional shape and `lfw_people.data` holds the same information of images which is flattened array of images (1-dimensional array)"]},{"cell_type":"markdown","metadata":{"id":"I9-dYGItJ_ex"},"source":["### Assigning lfw_people data to the X variable, by using the 'data' attribute."]},{"cell_type":"code","metadata":{"id":"hrC0ewCmzMx4"},"source":["X = lfw_people.data\n","\n","# Data is stored in X, where the shape of X is (no.of samples, no.of features)\n","n_features = X.shape[1] \n","X.shape[0], X.shape[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aq5O4SJjzXpi"},"source":["# The label is the id of the person\n","y = lfw_people.target\n","\n","# Loading the target names (Label names)\n","target_names = lfw_people.target_names\n","\n","# Checkinq no.of classes\n","n_classes = target_names.shape[0]\n","\n","print(\"Target names:\", target_names)\n","print(\"\\nTotal dataset size:\")\n","print(\"n_samples: %d\" % n_samples)\n","print(\"n_features: %d\" % n_features)\n","print(\"n_classes: %d\" % n_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fxkbeTCsKRm0"},"source":["### Split into a training and testing set using train_test_split sklearn function\n"]},{"cell_type":"code","metadata":{"id":"lEGSgiOynFFt"},"source":["X.shape, y.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TU7bRT6WKQ8m"},"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n","X_train.shape, X_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1-fb1HraKiHU"},"source":["## Performing PCA on the face images, otherwise known as Eigenfaces"]},{"cell_type":"markdown","metadata":{"id":"bauwkVrNK4yU"},"source":["### Compute the PCA\n","\n","In PCA, a parameter Whiten = True, will remove some information from the transformed signal (the relative variance scales of the components) but can sometime improve the predictive accuracy of the downstream estimators by making their data respect some hard-wired assumptions.\n","\n","Whitening just makes our resulting data have a unit variance, which has been shown to produce better results"]},{"cell_type":"code","metadata":{"id":"ZIbummkGzYH6"},"source":["# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n","# dataset): unsupervised feature extraction / dimensionality reduction\n","\n","n_components = 150\n","\n","print(\"Extracting the top %d eigenfaces from %d faces\"\n","      % (n_components, X_train.shape[0]))\n","\n","# Starting the timer\n","t0 = time()\n","\n","# Trying to extract PCA features using PCA function from sklearn\n","pca = PCA(n_components=n_components, whiten=True).fit(X_train)\n","\n","# Printing the time taken to extract the features\n","print(\"done in %0.3fs\" % (time() - t0))\n","\n","# Storing the eigen faces and reshaping to 3 dimensions\n","# pca.components_ is the set of all eigenvectors of the covariance matrix (one eigenvector for each principal component)\n","eigenfaces = pca.components_.reshape((n_components, h, w))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Vw4oQ-B3bCZ"},"source":["pca.components_.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BR0YiszmSL5Y"},"source":["eigenfaces.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qi0IQ1-nIIOk"},"source":["### Projecting the input data on the eigenfaces orthonormal basis\n"]},{"cell_type":"code","metadata":{"id":"hRHdK40Fzcg6"},"source":["t0 = time()\n","# Transforming the data\n","X_train_pca = pca.transform(X_train)\n","X_test_pca = pca.transform(X_test)\n","print(\"done in %0.3fs\" % (time() - t0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4OKjxIaLzfZP"},"source":["# Checking for the shape of the original and pca data\n","X_train.shape, X_train_pca.shape, X_test.shape, X_test_pca.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kzp9u2jdISz7"},"source":["## Train a Linear Classifier"]},{"cell_type":"markdown","metadata":{"id":"kBD2USvfIapC"},"source":["### Fitting the classifier to the training set"]},{"cell_type":"code","metadata":{"id":"IJCSYo1QYgAA"},"source":["t0 = time()\n","\n","from sklearn.linear_model import SGDClassifier\n","clf = SGDClassifier()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wCvUHd9_zjCo"},"source":["# Fit the data\n","clf = clf.fit(X_train_pca, y_train)\n","print(\"done in %0.3fs\" % (time() - t0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i486kOGEImdO"},"source":["###  Quantitative evaluation of the model quality on the test set"]},{"cell_type":"code","metadata":{"id":"bUfrCIQazr5_"},"source":["print(\"Predicting people's names on the test set\")\n","t0 = time()\n","y_pred = clf.predict(X_test_pca)\n","\n","print(\"done in %0.3fs\" % (time() - t0))\n","print(\"accuracy is\", accuracy_score(y_test,y_pred))\n","\n","print(\"\\nclassification report\")\n","print(classification_report(y_test, y_pred, target_names=target_names))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wSBKVU6eIyZX"},"source":["### Qualitative evaluation of the predictions using matplotlib\n","\n","Below function `plot_gallery()` takes images, titles , height, width and plots each image in subplot \n"]},{"cell_type":"code","metadata":{"id":"ya44ZmAEzsX5"},"source":["def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n","    \"\"\"Helper function to plot a gallery of portraits\n","      out of all images passed it will plot only 12 images as rows and columns defined 3 and 4\"\"\"\n","    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n","    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n","    for i in range(n_row * n_col):\n","        plt.subplot(n_row, n_col, i + 1)\n","        plt.imshow(images[i].reshape((h, w)), cmap='gray')\n","        plt.title(titles[i], size=12)\n","        plt.xticks(())\n","        plt.yticks(())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8SMZsuqasWVR"},"source":["Below get_Title() function is to extract target names for predictions and actual values to plot along with images"]},{"cell_type":"code","metadata":{"id":"jjCCRI8trwFt"},"source":["# Getting the last name of each target name\n","def get_Title(y_pred, y_test, target_names, i):\n","    pred_name = target_names[y_pred[i]].split(' ')[-1]\n","    true_name = target_names[y_test[i]].split(' ')[-1]\n","    return 'predicted: %s\\ntrue: %s' % (pred_name, true_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HlMW7PGGrtbt"},"source":["# Get the prediction and actual titles and store in a list\n","prediction_titles = []\n","for i in range(y_pred.shape[0]):\n","  title =  get_Title(y_pred, y_test, target_names, i)\n","  prediction_titles.append(title)\n","\n","# Plot the result of the prediction on a portion of the test set\n","plot_gallery(X_test, prediction_titles, h, w, n_row=5, n_col= 2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kc5In04SL-8f"},"source":["### Plotting the eigen faces"]},{"cell_type":"code","metadata":{"id":"aT8HwfEhtoaz"},"source":["# Plot the gallery of the most significative eigenfaces\n","eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n","plot_gallery(eigenfaces, eigenface_titles, h, w)"],"execution_count":null,"outputs":[]}]}