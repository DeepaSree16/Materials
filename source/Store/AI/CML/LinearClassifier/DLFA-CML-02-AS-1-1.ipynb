{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M1_AST_06_Numerical_Optimization_C.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4Nwm4FK3wgU"
      },
      "source": [
        "# Advanced Programme in Deep Learning (Foundations and Applications)\n",
        "## A Program by IISc and TalentSprint\n",
        "### Assignment 6: Numerical Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHj34EaN5oa5"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krALfcVa8aHp"
      },
      "source": [
        "At the end of the experiment, you will be able to\n",
        "\n",
        "*   understand Linear Least Squares method\n",
        "\n",
        "*   understand about Constrained Optimization\n",
        "\n",
        "*   understand about Support Vector Machines \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNWmCQEA971F"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM0nX5x7971H"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \" \" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv0OwgOI971I"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujKg5abM971J",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook= \"M1_AST_06_Numerical_Optimization_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")  \n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "    \n",
        "    elif getAnswer1() and getAnswer2() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"answer1\" : Answer1, \"answer2\" : Answer2, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None   \n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://dlfa.iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional: \n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional  \n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "  \n",
        "  \n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "  \n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer1():\n",
        "  try:\n",
        "    if not Answer1:\n",
        "      raise NameError \n",
        "    else: \n",
        "      return Answer1\n",
        "  except NameError:\n",
        "    print (\"Please answer Question 1\")\n",
        "    return None\n",
        "\n",
        "def getAnswer2():\n",
        "  try:\n",
        "    if not Answer2:\n",
        "      raise NameError \n",
        "    else: \n",
        "      return Answer2\n",
        "  except NameError:\n",
        "    print (\"Please answer Question 2\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup() \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmhI3-ho-A1i"
      },
      "source": [
        "### Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOMG46mc-A1j"
      },
      "source": [
        "from scipy import optimize\n",
        "from scipy.optimize import linprog                                      # Minimize a linear objective function subject to linear equality and inequality constraints\n",
        "import numpy as np                                                      # Numpy library        \n",
        "from scipy.optimize import minimize, fsolve, LinearConstraint           # Minimization of scalar function of one or more variables and Find the roots of a function  \n",
        "from scipy.linalg import solve                                          # Solves the linear equation set a * x = b for the unknown x for square a matrix\n",
        "from autograd import grad                                               # Python package for automatic differentiation\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgbAwtf6G6l5"
      },
      "source": [
        "### Importing required packages for SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WCBUiz0oG6l6"
      },
      "source": [
        "import pandas as pd                                                       # to read files\n",
        "import seaborn as sns                                                     # library for statistical data visualization\n",
        "from matplotlib.colors import ListedColormap                              # for filling colors in mapping\n",
        "from sklearn.metrics import accuracy_score                                # importing confusion matrix, accuracy score\n",
        "from sklearn.svm import SVC                                               # importing Support vector classifier, Support Vector Regressor, LinearSVC  \n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder            # preprocessing\n",
        "from sklearn.model_selection import train_test_split                      # for splitting the dataset\n",
        "from mlxtend.plotting import plot_decision_regions                        # to plot the decision boundaries and hyperplane\n",
        "from sklearn.pipeline import make_pipeline                                # to import pipeline\n",
        "from sklearn import datasets\n",
        "from cvxopt import matrix as cvxopt_matrix\n",
        "from cvxopt import solvers as cvxopt_solvers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH2gCoHINz8P"
      },
      "source": [
        "## Linear Least Squares "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buNhj9c0N2wB"
      },
      "source": [
        "The least squares method is a statistical strategy for determining the **best fit** for a group of data points by reducing the total of the points' offsets or residuals from the plotted curve. Linear least square method is also a technique which is commonly used in **regression analysis** that falls in the category of **Supervised Learning**. Further, least squares regression is applied to predict the behaviour of dependent variables.\n",
        "\n",
        "Here, we try to find the best fit line which can represent the relationship between two variables where one is **dependent** and another is **independent** variable.\n",
        "\n",
        "**Line of best fit**: The line of best fit is a line that runs through a scatter plot of data points and best reflects the relationship between them. The below graph represents the data points and the line of best fit for them.\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gQO-j4pnaYx"
      },
      "source": [
        "Steps to compute line of best fit:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cxx8xTgW_97k"
      },
      "source": [
        "1. Calculate the slope 'm' of the line using the below formula:\n",
        "\n",
        "  $m = \\frac{n\\sum xy - (\\sum x)(\\sum y)}{n\\sum x^2 - (\\sum x)^2}$\n",
        "\n",
        "  m - slope of the line\n",
        "\n",
        "  n - total number of data points\n",
        "\n",
        "  x - independent variable\n",
        "\n",
        "  y - dependent variable\n",
        "\n",
        "2. Compute the y intercept using the below expression: \n",
        "\n",
        "    c = y - mx\n",
        "\n",
        "3. Substitute all the values in the final equation and plot the line.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecrcyzhvuRu2"
      },
      "source": [
        "Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nvScYEuFhhG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "427806f3-c920-44f9-a978-15161e9537ca"
      },
      "source": [
        "!wget https://cdn.iisc.talentsprint.com/DLFA//Experiment_related_data/Iris.csv\n",
        "data_1 = pd.read_csv('Iris.csv')\n",
        "print(data_1.shape)\n",
        "print(data_1.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-27 05:31:41--  https://cdn.iisc.talentsprint.com/DLFA//Experiment_related_data/Iris.csv\n",
            "Resolving cdn.iisc.talentsprint.com (cdn.iisc.talentsprint.com)... 172.105.52.210\n",
            "Connecting to cdn.iisc.talentsprint.com (cdn.iisc.talentsprint.com)|172.105.52.210|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5107 (5.0K) [application/octet-stream]\n",
            "Saving to: ‘Iris.csv’\n",
            "\n",
            "Iris.csv            100%[===================>]   4.99K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-07-27 05:31:43 (622 MB/s) - ‘Iris.csv’ saved [5107/5107]\n",
            "\n",
            "(150, 6)\n",
            "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
            "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
            "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
            "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
            "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
            "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qh0ewbsFseA"
      },
      "source": [
        "# Declaring X(independent variable) and Y(dependent variable) \n",
        "X = data_1['PetalLengthCm'].values\n",
        "Y = data_1['PetalWidthCm'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6YoQzb6aiHJ"
      },
      "source": [
        "Calculating the coefficients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q-z-GiPF7vJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb2654c-c19b-4ced-ea15-88ab06fd3f64"
      },
      "source": [
        "# Mean X and Y as per the formula \n",
        "mean_x = np.mean(X)\n",
        "mean_y = np.mean(Y)\n",
        "# Total number of values\n",
        "n = len(X)\n",
        "mean_x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.758666666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7luhHC11GWyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38f98251-8377-4eb7-c3b5-141a61abf296"
      },
      "source": [
        "# Calculate 'm' and 'c' using the formula\n",
        "numerator = 0\n",
        "denominator = 0\n",
        "for i in range(n):\n",
        "  numerator += (X[i]-mean_x)*(Y[i]-mean_y)\n",
        "  denominator += (X[i]-mean_x)**2\n",
        "m = numerator/denominator\n",
        "c = mean_y - (m*mean_x)\n",
        "print(\"Coefficients are:\",m,c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coefficients are: 0.4164191322854012 -0.3665140452167275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ducbtU30b1Ll"
      },
      "source": [
        "Plotting the values and regression line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjcr53fSHWab"
      },
      "source": [
        "max_x = np.max(X)\n",
        "min_x = np.min(X)\n",
        "# Calculating line values x and y\n",
        "x = np.linspace(min_x,max_x,100)\n",
        "y = c + m*x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw9DtYA8H63K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "c3598d36-04fd-49cc-9687-0e2ea635032b"
      },
      "source": [
        "# Plotting the best fit line\n",
        "plt.plot(x,y,color = '#58b970',label = 'Best Fit Line')\n",
        "# Plotting Scatter points\n",
        "plt.scatter(X,Y,color = '#ef5423', label = 'Scatter Plot')\n",
        "plt.xlabel('Petal Length in Cm')\n",
        "plt.ylabel('Petal Width in Cm')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fn0jSdNpSW-"
      },
      "source": [
        "**RMSE**: The standard deviation of the residuals is known as **Root Mean Square Error (RMSE)** (prediction errors). Further, the residuals are an estimate of how distant the data points are from the regression line. In other words, it indicates how closely the data is clustered around the line of best fit.\n",
        "\n",
        "**Note**: Lower RMSE value indicates goodness of a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNEzQnlqIkJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f02eac-5864-479b-ade5-1cd29a592cfa"
      },
      "source": [
        "# Caculating Root Mean Square Error\n",
        "rmse = 0\n",
        "for i in range(n):\n",
        "  y_pred = c + m * X[i]\n",
        "  rmse += (Y[i] - y_pred)**2\n",
        "rmse = np.sqrt(rmse/n)\n",
        "print(\"RMSE is :\",rmse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE is : 0.20564519522586527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgI_0qxdk7CJ"
      },
      "source": [
        "## Introduction to Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJY8ndIHk-yD"
      },
      "source": [
        "Optimization is an important tool in decision science and the analysis of physical systems. To make use of this tool, first identify some objective, a quantitative measure of the performance of the system under study. This objective could be profit, time, potential energy, or any quantity or combination of quantities that can be represented by a single number. The objective depends on certain characteristics of the system, called variables or unknowns. Here, the goal is to find the values of the variables that optimize the objective function.\n",
        "\n",
        "The process of identifying objective, variables, and constraints for a given problem is known as *modeling*. This step is mostly the first and the most important step in the optimization process. After an optimization algorithm has been applied to the model, we must be able to recognize whether it has succeeded in its task of finding a solution. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGu-_eUqmiEW"
      },
      "source": [
        "#### Constrained optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozqgicu2mlZF"
      },
      "source": [
        "The general **constrained optimization** task is to maximize or minimize a function $f(x)$ by varying $x$, given certain constraints on $x$. \n",
        "\n",
        "Eg. Find minimum of $f(x_1,x_2,x_3) = x_1^2 + x_2^2 + x_3^2,  where \\lVert x_2\\rVert \\geq1$\n",
        "\n",
        "Eg. Designing the fastest vehicle with a constraint on fuel efficiency\n",
        "\n",
        "An optimization problem comprises of three basic components:\n",
        "\n",
        "- $x$: is the vector of variables, also called unknowns or parameters;\n",
        "- $f$: is the objective function, a (scalar) function of x that we want to maximize or\n",
        "minimize;\n",
        "- $c_i$: are constraint functions, which are scalar functions of x that define certain equations\n",
        "and inequalities that the unknown vector x must satisfy.\n",
        "\n",
        "Using this notation, the optimization problem can be written as follows:\n",
        "\n",
        "$\\min\\limits_{x \\in R^{N}}$ $f(x)$  \n",
        "\n",
        "$\\textrm{subject to}$ $\\hspace{1cm} c_i(x) = 0, \\hspace{0.25cm} i \\in \\xi$\n",
        "\n",
        "$\\hspace{2.75cm}$ $c_i(x)\\geq0, \\hspace{0.25cm} i \\in I$\n",
        "\n",
        "Here $I$ and $\\xi$ are sets of indices for equality and inequality constraints.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elxef7nTL7pI"
      },
      "source": [
        "#### Equality and Inequality Constraints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wdMUK1LMHAO"
      },
      "source": [
        "Consider the following general constrained optimization problem:\n",
        "\n",
        "$\\max\\limits_{x_i \\in R}$ $f(x_1,. . . . , x_n)$ \n",
        "\n",
        "subject to: \n",
        "\n",
        "$g_1(x_1, . . . , x_n) \\leq b_1, . . . , g_k(x_1, . . . , x_n) \\leq b_k$,\n",
        "\n",
        "$h_1(x_1, . . . , x_n) = c_1, . . . , h_m(x_1, . . . , x_n) = c_m$\n",
        "\n",
        "The function $f(x)$ is called the objective function, $g(x)$ is called an *inequality constraint*, and $h(x)$ is called an *equality constraint*. In the above problem, there are $k$ *inequality constraints* and $m$ *equality constraints*. In the following, we will always assume that $f, g$, and h are $C^{1}$ functions, i.e. that they are differentiable and their derivatives are continuous.\n",
        "\n",
        "Notice that this problem differs from the regular unconstrained optimization problem instead of finding the maximum of $f(x)$ we are finding the maximum of $f(x)$ only over the points which satisfy the constraints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u4IUikm8tYx"
      },
      "source": [
        "\n",
        "### Example: Stockbroker Income"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnK3SV36gWjS"
      },
      "source": [
        "Let’s try a demonstration on how to use `minimize()`. Imagine you’re a stockbroker who’s interested in maximizing the total income from the sale of a fixed number of your stocks. You have identified a particular set of buyers, and for each buyer, you know the price they’ll pay and how much cash they have on hand.\n",
        "\n",
        "There is one constraint on the problem, which is that the sum of the total shares purchased by the buyers does not exceed the number of shares you have on hand. There are also bounds on each of the solution variables because each buyer has an upper bound of cash available, and a lower bound of zero. Negative solution x-values mean that you’d be paying the buyers!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvyoazO52IWj"
      },
      "source": [
        "Steps we will follow to solve the problem:\n",
        "\n",
        "1. Initialize the variables\n",
        "\n",
        "2. Create arrays for storing price, money available with the buyers, and shares per buyer.\n",
        "\n",
        "3. Setting the constraints\n",
        "\n",
        "4. Setting the bounds\n",
        "\n",
        "5. Declaring the 'objective function'.\n",
        "\n",
        "6. Applying constrained optimization using minimize() method from scipy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZui-wK_wfKS"
      },
      "source": [
        "Solving Optimization Problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seR9SIemgWjU"
      },
      "source": [
        "# set variables to determine the number of buyers in the market and the number of shares you want to sell\n",
        "n_buyers = 10\n",
        "\n",
        "n_shares = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH6bPIOZgWjU"
      },
      "source": [
        "Next, create arrays to store the price that each buyer pays for the shares, the maximum amount they can afford to spend, and the maximum number of shares each buyer can afford, given the first two arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSJyHMJegWjV"
      },
      "source": [
        "np.random.seed(10)\n",
        "\n",
        "# Generating the array of prices the buyers will pay\n",
        "# np.random.random() creates an array of random numbers\n",
        "# on the half-open interval [0,1)\n",
        "prices = 100*np.random.random(n_buyers)\n",
        "\n",
        "# generate an array of integers on the half-open interval from [1, 4), \n",
        "# again with the size of the number of buyers\n",
        "money_available = 100*np.random.randint(1, 4, n_buyers)\n",
        "\n",
        "print(\"Price of the shares 1-{} : {}\".format(n_shares, prices))\n",
        "print(\"Money available with each buyer (1-{}): {}\".format(n_buyers, money_available))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CNdqXEkgWjV"
      },
      "source": [
        "Now, you need to compute the maximum number of shares each buyer can afford:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0LcA8jegWjV"
      },
      "source": [
        "# take the ratio of the money_available with prices to determine the maximum number of shares each buyer can purchase\n",
        "n_shares_per_buyer = money_available / prices\n",
        "\n",
        "print(\"No of shares per buyer:\\n\",n_shares_per_buyer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMIn-cn4gWjW"
      },
      "source": [
        "Now, you need to create the constraints and bounds for the solver.\n",
        "\n",
        " Remember that LinearConstraint takes the dot product of the input array with the solution values and compares it to the lower and upper bound. You can use this to set up the constraint on n_shares:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvbvwourgWjW"
      },
      "source": [
        "# create an array of ones with the length `n_buyers` as `LinearConstraint` takes the first argument as matrix\n",
        "# lb and ub are equal as it represents equality constraints \n",
        "# For example, a machine component may be required to move precisely by Δ to perform the desired operation, \n",
        "# so we must treat this as an equality constraint. \n",
        "constraint = LinearConstraint(np.ones(n_buyers), lb = n_shares, ub = n_shares)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCVXLHOJgWjW"
      },
      "source": [
        "Since `LinearConstraint` takes the dot product of the solution vector with this argument, it’ll result in the sum of the purchased shares.\n",
        "\n",
        "This result is then constrained to lie between the other two arguments:\n",
        "\n",
        "1. The lower bound lb\n",
        "2. The upper bound ub\n",
        "\n",
        "Next, create the bounds for the solution variable. The bounds limit the number of shares purchased to be 0 on the lower side and `n_shares_per_buyer` on the upper side. The format that `minimize()` expects for the bounds is a sequence of tuples of lower and upper bounds:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jVR7RERgWjW"
      },
      "source": [
        "bounds = [(0, n) for n in n_shares_per_buyer]\n",
        "bounds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXb3wCpBgWjX"
      },
      "source": [
        "# Here the objective function returns negative of dot product of 'x' declared as 'x0' below \n",
        "# and 'prices' which indicates that we are minimizing the value\n",
        "def objective_function(x, prices):\n",
        "    return -x.dot(prices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhUo-6KKgWjX"
      },
      "source": [
        "In this code, you define `objective_function()` to take two arguments. Then you take the dot product of x with prices and return the negative of that value. Remember that you have to return the negative because you’re trying to make that number as small as possible, or as close to negative infinity as possible. Finally, you can call `minimize()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAbLKfbqgWjY"
      },
      "source": [
        "res = minimize(\n",
        "    objective_function,\n",
        "    x0 = 10 * np.random.random(n_buyers),\n",
        "    args = (prices),\n",
        "    constraints=constraint,\n",
        "    bounds=bounds,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNIoWoXFgWjY"
      },
      "source": [
        "In this code, res is an instance of OptimizeResult, just like with `minimize_scalar()`. As you’ll see, there are many of the same fields, even though the problem is quite different. In the call to `minimize()`, you pass five arguments:\n",
        "\n",
        "1. objective_function\n",
        "2. $x_0$\n",
        "3. args\n",
        "4. constraints\n",
        "5. bounds\n",
        "\n",
        "Once the solver runs, you should inspect `res` by printing it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeOvD_6pgWjY"
      },
      "source": [
        "res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGmdjppmgWjZ"
      },
      "source": [
        "You should also check and make sure that the constraints and bounds that you set are satisfied. You can do this with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrNRqCdJgWjZ"
      },
      "source": [
        "print(\"The total number of shares is:\", sum(res.x))\n",
        "print(\"Leftover money for each buyer:\", money_available - res.x * prices)\n",
        "print(\"Money Exhausted:\\n\",res.x * prices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoBCr7X7S0Jd"
      },
      "source": [
        "## Support Vector Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVx8dO706ps4"
      },
      "source": [
        "**Support vector machines** are a set of supervised learning methods used for classification, regression, and outliers detection. \n",
        "\n",
        "A simple linear SVM classifier works by making a straight line between two classes. That means all of the data points on one side of the line will represent a category and the data points on the other side of the line will be put into a different category. This means there can be an infinite number of lines to choose from.\n",
        "\n",
        "**Hyperplanes** are decision boundaries that help classify the data points. Data points falling on either side of the hyperplane can be attributed to different classes.\n",
        " * The hyperplane with maximum margin is called the optimal hyperplane.\n",
        "\n",
        "**Support vectors** are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. \n",
        "\n",
        "**Margin** is the width that the boundary could be increased by before hitting a data point.\n",
        "\n",
        "![wget](https://cdn.talentsprint.com/aiml/aiml_2020_b14_hyd/experiment_details_backup/linear_data.png)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0DXXBDCQTng"
      },
      "source": [
        "#### Implementing the SVM algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Okaxfq9-P8q"
      },
      "source": [
        "Linearly separable, binary classification:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjIPiwnC-gW6"
      },
      "source": [
        "Using the notation and steps provided by [Tristan Fletcher](https://static1.squarespace.com/static/58851af9ebbd1a30e98fb283/t/58902fbae4fcb5398aeb7505/1485844411772/SVM+Explained.pdf) the general steps to solve the SVM problem are the following:\n",
        "\n",
        "1. Create P where $H_{i,j}= y^{(i)}y^{(j)}<x^{(i)}x^{(j)}>$\n",
        "\n",
        "2. Calculate $w=\\sum_{i}^{m}y^{(i)} \\alpha_{i}x^{(i)}$\n",
        "\n",
        "3. Determine the set of support vectors S by finding the indices such that $\\alpha_{i}>0$\n",
        "\n",
        "4. Calculate the intercept term using $b=y^{(s)}−\\sum_{m ∈ S} \\alpha_{m}y^{(m)}<x^{(m)}x^{(s)}>$\n",
        "\n",
        "5. For each new point $x'$ classify according to $y′=sign(w^{T}x′+b)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT_tX8aL_eLJ"
      },
      "source": [
        "#### Re-writing the problem in an appropriate format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJsy2ebb_gpv"
      },
      "source": [
        "Since we will solve this optimization problem using the [CVXOPT](https://cvxopt.org/userguide/coneprog.html#quadratic-programming) library in python we will need to match the solver's API which, according to the documentation is of the form:\n",
        "\n",
        "$min \\frac{1}{2}x^{T}Px+q^{T}x$\n",
        "\n",
        "$s.t.  G_{x}\\leq h$\n",
        " \n",
        "$Ax=b$\n",
        "\n",
        "With API\n",
        "\n",
        "    cvxopt.solvers.qp(P, q[, G, h[, A, b[, solver[, initvals]]]])\n",
        "\n",
        "Recall that the dual problem is expressed as:\n",
        "\n",
        "$max \\sum_{i}^{m} \\alpha_{i}−\\frac{1}{2}\\sum_{i,j}^{m} y^{(i)}y^{(j)} \\alpha_{i} \\alpha_{j}<x^{(i)}x^{(j)}>$\n",
        "\n",
        "Let H be a matrix such that $H_{i,j}= y^{(i)}y^{(j)}<x^{(i)}x^{(j)}>$, then the optimization becomes:\n",
        "\n",
        "$max \\sum_{i}^{m} \\alpha_{i}−\\frac{1}{2} \\alpha^{T} H \\alpha$\n",
        "\n",
        "$s.t. \\alpha_{i}\\geq0$ \n",
        "\n",
        "$\\sum_{i}^{m}\\alpha_{i} y^{(i)}=0$\n",
        "\n",
        "We convert the sums into vector form and multiply both the objective and the constraint by −1 which turns this into a minimization problem and reverses the inequality\n",
        "\n",
        "$min \\frac{1}{2}\\alpha^{T}H\\alpha - 1^{T}\\alpha$\n",
        "\n",
        "$s.t. - \\alpha_{i}\\leq0$\n",
        "\n",
        "$s.t. y^{T}\\alpha = 0$\n",
        "\n",
        "We are now ready to convert our numpy arrays into the cvxopt format, using the same notation as in the documentation this gives\n",
        "\n",
        "P:  $H$ a matrix of size $m×m$\n",
        "\n",
        "q: $\\vec{-1}$  a vector of size $m×1$\n",
        "\n",
        "G: $−diag[1]$ a diagonal matrix of -1s of size $m×m$\n",
        "\n",
        "h: $\\vec{0}$  a vector of zeros of size $m×1$\n",
        "\n",
        "A: $y$ the label vector of size $m×1$\n",
        "\n",
        "b: $0$ a scalar\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHWMp4tG_2MY"
      },
      "source": [
        "Note that in the simple example of $m=2$ the matrix $G$ and vector h which define the constraint are\n",
        "\n",
        "$$G = \\begin{bmatrix}\n",
        "-1 & 0 \\\\\n",
        "0 & 1 \\\\\n",
        "\\end{bmatrix} and $$ $$h = \\begin{bmatrix}\n",
        "-1 & 0 \\\\\n",
        "0 & 1 \\\\\n",
        "\\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0Wk_0WYITIK"
      },
      "source": [
        "#### Computing the matrix H in vectorized form"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KugagYs9IDLy"
      },
      "source": [
        "\n",
        "Consider the simple example with 2 input samples $(\\left\\{x^{(1)}, x^{(2)}\\right\\} \\in \\mathbb{R}^{2})$ which are two dimensional vectors. i.e. $\n",
        "x^{(1)}=\\left(x_{1}^{(1)}, x_{2}^{(1)}\\right)^{T}$\n",
        "\n",
        "$$X = \\begin{bmatrix}\n",
        "x^{(1)}_{1} & x^{(1)}_{2} \\\\\n",
        "x^{(2)}_{1} & x^{(2)}_{2} \\\\\n",
        "\\end{bmatrix}, y = \\begin{bmatrix}\n",
        "y^{(1)}\\\\\n",
        "y^{(2)}\\\\\n",
        "\\end{bmatrix}$$ \n",
        "\n",
        "We now proceed to creating a new matrix $X$ where each input sample $x$ is multiplied by the coresponding output label $y$.\n",
        "This can be done easily in Numpy using vectorization and padding.\n",
        "\n",
        "$$X' = \\begin{bmatrix}\n",
        "x^{(1)}_{1}y^{(1)} & x^{(1)}_{2}y^{(1)} \\\\\n",
        "x^{(2)}_{1}y^{(2)} & x^{(2)}_{2}y^{(2)} \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "Finally we take the **matrix multiplication** of $X′$ and its transpose giving $H=X'X'T$\n",
        "\n",
        "\n",
        "$$H = X'@X'^{T} = \\begin{bmatrix}\n",
        "x^{(1)}_{1}y^{(1)} & x^{(1)}_{2}y^{(1)} \\\\\n",
        "x^{(2)}_{1}y^{(2)} & x^{(2)}_{2}y^{(2)} \\\\\n",
        "\\end{bmatrix} \n",
        "\\begin{bmatrix}\n",
        "x^{(1)}_{1}y^{(1)} & x^{(2)}_{1}y^{(2)} \\\\\n",
        "x^{(1)}_{2}y^{(1)} & x^{(2)}_{2}y^{(2)} \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "\n",
        "$$\n",
        "H = \\begin{bmatrix}\n",
        "x_{1}^{(1)} x_{1}^{(1)} y^{(1)} y^{(1)}+x_{2}^{(1)} x_{2}^{(1)} y^{(1)} y^{(1)} & x_{1}^{(1)} x_{1}^{(2)} y^{(1)} y^{(2)}+x_{2}^{(1)} x_{2}^{(2)} y^{(1)} y^{(2)} \\\\ \n",
        "x_{1}^{(2)} x_{1}^{(1)} y^{(2)} y^{(1)}+x_{2}^{(2)} x_{2}^{(1)} y^{(2)} y^{(1)} & x_{1}^{(2)} x_{1}^{(2)} y^{(2)} y^{(2)}+x_{2}^{(2)} x_{2}^{(2)} y^{(2)} y^{(2)}\n",
        "\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oap46TSbUbRy"
      },
      "source": [
        "Dataset and inspection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAPZ85tV1Dmq"
      },
      "source": [
        "#Data set\n",
        "x_neg = np.array([[3,4],[1,4],[2,3]])\n",
        "y_neg = np.array([-1,-1,-1])\n",
        "x_pos = np.array([[6,-1],[7,-1],[5,-3]])\n",
        "y_pos = np.array([1,1,1])\n",
        "x1 = np.linspace(-10,10)\n",
        "x = np.vstack((np.linspace(-10,10),np.linspace(-10,10)))\n",
        "\n",
        "#Data for the next section\n",
        "X = np.vstack((x_pos, x_neg))\n",
        "y = np.concatenate((y_pos,y_neg))\n",
        "\n",
        "#Parameters guessed by inspection\n",
        "w = np.array([1,-1]).reshape(-1,1)\n",
        "b = -3\n",
        "\n",
        "#Plot\n",
        "fig = plt.figure(figsize = (10,10))\n",
        "plt.scatter(x_neg[:,0], x_neg[:,1], marker = 'x', color = 'r', label = 'Negative -1')\n",
        "plt.scatter(x_pos[:,0], x_pos[:,1], marker = 'o', color = 'b',label = 'Positive +1')\n",
        "plt.plot(x1, x1  - 3, color = 'darkblue')\n",
        "plt.plot(x1, x1  - 7, linestyle = '--', alpha = .3, color = 'b')\n",
        "plt.plot(x1, x1  + 1, linestyle = '--', alpha = .3, color = 'r')\n",
        "plt.xlim(0,10)\n",
        "plt.ylim(-5,5)\n",
        "plt.xticks(np.arange(0, 10, step=1))\n",
        "plt.yticks(np.arange(-5, 5, step=1))\n",
        "\n",
        "#Lines\n",
        "plt.axvline(0, color = 'black', alpha = .5)\n",
        "plt.axhline(0,color = 'black', alpha = .5)\n",
        "plt.plot([2,6],[3,-1], linestyle = '-', color = 'darkblue', alpha = .5 )\n",
        "plt.plot([4,6],[1,1],[6,6],[1,-1], linestyle = ':', color = 'darkblue', alpha = .5 )\n",
        "plt.plot([0,1.5],[0,-1.5],[6,6],[1,-1], linestyle = ':', color = 'darkblue', alpha = .5 )\n",
        "\n",
        "#Annotations\n",
        "plt.annotate(s = '$A \\ (6,-1)$', xy = (5,-1), xytext = (6,-1.5))\n",
        "plt.annotate(s = '$B \\ (2,3)$', xy = (2,3), xytext = (2,3.5))#, arrowprops = {'width':.2, 'headwidth':8})\n",
        "plt.annotate(s = '$2$', xy = (5,1.2), xytext = (5,1.2) )\n",
        "plt.annotate(s = '$2$', xy = (6.2,.5), xytext = (6.2,.5))\n",
        "plt.annotate(s = '$2\\sqrt{2}$', xy = (4.5,-.5), xytext = (4.5,-.5))\n",
        "plt.annotate(s = '$2\\sqrt{2}$', xy = (2.5,1.5), xytext = (2.5,1.5))\n",
        "plt.annotate(s = '$w^Tx + b = 0$', xy = (8,4.5), xytext = (8,4.5))\n",
        "plt.annotate(s = '$(\\\\frac{1}{4},-\\\\frac{1}{4}) \\\\binom{x_1}{x_2}- \\\\frac{3}{4} = 0$', xy = (7.5,4), xytext = (7.5,4))\n",
        "plt.annotate(s = '$\\\\frac{3}{\\sqrt{2}}$', xy = (.5,-1), xytext = (.5,-1))\n",
        "\n",
        "#Labels and show\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uef2XWrJ1O9i"
      },
      "source": [
        "#Initializing values and computing H. Note the 1. to force to float type\n",
        "m,n = X.shape\n",
        "y = y.reshape(-1,1) * 1.\n",
        "X_dash = y * X\n",
        "H = np.dot(X_dash , X_dash.T) * 1.\n",
        "\n",
        "#Converting into cvxopt format\n",
        "P = cvxopt_matrix(H)\n",
        "q = cvxopt_matrix(-np.ones((m, 1)))\n",
        "G = cvxopt_matrix(-np.eye(m))\n",
        "h = cvxopt_matrix(np.zeros(m))\n",
        "A = cvxopt_matrix(y.reshape(1, -1))\n",
        "b = cvxopt_matrix(np.zeros(1))\n",
        "\n",
        "#Setting solver parameters (change default to decrease tolerance) \n",
        "cvxopt_solvers.options['show_progress'] = False\n",
        "cvxopt_solvers.options['abstol'] = 1e-10\n",
        "cvxopt_solvers.options['reltol'] = 1e-10\n",
        "cvxopt_solvers.options['feastol'] = 1e-10\n",
        "\n",
        "#Run solver\n",
        "sol = cvxopt_solvers.qp(P, q, G, h, A, b)\n",
        "alphas = np.array(sol['x'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6FiLhfZ6EgY"
      },
      "source": [
        "#Run solver\n",
        "%%time\n",
        "sol = cvxopt_solvers.qp(P, q, G, h, A, b)\n",
        "#alphas = np.array(sol['x'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I8epqbNUqcb"
      },
      "source": [
        "Compute w and b parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPDFY-J42Bkd"
      },
      "source": [
        "#w parameter in vectorized form\n",
        "w = ((y * alphas).T @ X).reshape(-1,1)\n",
        "\n",
        "#Selecting the set of indices S corresponding to non zero parameters\n",
        "S = (alphas > 1e-4).flatten()\n",
        "\n",
        "#Computing b\n",
        "b = y[S] - np.dot(X[S], w)\n",
        "\n",
        "#Display results\n",
        "print('Alphas = ',alphas[alphas > 1e-4])\n",
        "print('w = ', w.flatten())\n",
        "print('b = ', b[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8bfOpu3414T"
      },
      "source": [
        "support_vector_boolean = (alphas > 1e-4).reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3omFTluN5Ctq"
      },
      "source": [
        "print(\"Following are the support vectors:\\n{}\".format(X[support_vector_boolean]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBo4lpqd3Rj1"
      },
      "source": [
        "plt.scatter(x_neg[:, 0], x_neg[:,1])\n",
        "plt.scatter(x_pos[:, 0], x_pos[:,1])\n",
        "X1 = np.linspace(0, 10, 11)\n",
        "X2 = (-b[0]-w[0]*X1)/w[1]\n",
        "plt.plot(X1, X2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FropYUI45jhH"
      },
      "source": [
        "Comparing to Sklearn results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNVFfB2Q6XNb"
      },
      "source": [
        "clf = SVC(C = 10, kernel = 'linear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5HkfBP-6Yap"
      },
      "source": [
        "%%time\n",
        "clf.fit(X, y.ravel())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI2ywEkn5g1I"
      },
      "source": [
        "print('w = ',clf.coef_)\n",
        "print('b = ',clf.intercept_)\n",
        "print('Indices of support vectors = ', clf.support_)\n",
        "print('Support vectors = ', clf.support_vectors_)\n",
        "print('Number of support vectors for each class = ', clf.n_support_)\n",
        "print('Coefficients of the support vector in the decision function = ', np.abs(clf.dual_coef_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEvt2wzSUzNk"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrfZ66DaUzOQ"
      },
      "source": [
        "#@title Q.1. Use least-squares regression method to fit a straight line for x = [1, 3, 5, 7, 10, 12, 13, 16, 18, 20] and y = [4, 5, 6, 5, 8, 7, 6, 9, 12, 11].  { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer1 = \"\" #@param [\"\",\"y = 0.3725x - 3.3888\", \"y = 0.3725x + 3.3888\", \"y = -0.3725x + 3.3888\", \"y = -0.3725x - 3.3888\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX24XAeIJ6Nf"
      },
      "source": [
        "#@title Q.2. Use Lagrange multipliers to find the maxima and minima values of f( x, y ) = 3x−4y subject to the constraint x^2+3y^2 = 129, if such values exist. { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer2 = \"\" #@param [\"\",\"Maxima = 11, Minima = -11\", \"Maxima = 48, Minima = -48\", \"Maxima = 43, Minima = -43\", \"Maxima = 24, Minima = -24\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAZHt1zw-Y-",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}