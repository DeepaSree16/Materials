{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-CML-02-AS-1-1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YFu_oj3E0jYc"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n","## Not for grading"]},{"cell_type":"markdown","metadata":{"id":"0BFwTfYgrI-1"},"source":["## Learning Objective"]},{"cell_type":"markdown","metadata":{"id":"dC4JnILabiF3"},"source":["The objective of this experiment is to understand Linear classifier"]},{"cell_type":"markdown","metadata":{"id":"BV7n8Ymzu40T"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"L3k3JXdqUt2W"},"source":["The dataset chosen for this  experiment is a handmade fruits dataset. The dataset contains 69 records. Each record represents the following details of fruits : \n","\n","*  Weight -   It is the mass of an object. With respect to this dataset, we have calculated the weights in grams \n","\n","* Sphericity -   is a measure of how closely the shape of an object approaches that of a mathematically perfect sphere.\n","\n","* Color -  Every fruit has a different color at different stages. You can encode the color to an integer value. For example\n","\n","     - Green as 20\n","     - Greenish Yellow as 40\n","     - Orange as 60\n","     - Red as 80\n","     - Reddish Yellow as 100\n","\n","*  Label -   We have considered two fruits for simplicity. They are Apple and Orange.\n","\n","\n"]},{"cell_type":"code","source":[" !wget https://cdn.talentsprint.com/aiml/Experiment_related_data/fruits_weight_sphercity.csv"],"metadata":{"id":"EmpDWWfLjqgu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y9pFXqtfbcxG"},"source":["### Importing Required Packages"]},{"cell_type":"code","metadata":{"id":"hOiKa2ma0iXG"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import SGDClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WW2MIcyYbp3R"},"source":["### Loading the data"]},{"cell_type":"code","metadata":{"id":"0pfg23cCuFPj"},"source":["fruits_data = pd.read_csv(\"fruits_weight_sphercity.csv\")\n","fruits_data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d__egCJXt9yz"},"source":["fruits_data['Color'] = fruits_data['Color'].replace(['Green', 'Greenish yellow','Orange', 'Red','Reddish yellow'],[20, 40, 60, 80, 100])  \n","fruits_data['labels'] = fruits_data['labels'].replace(['apple','orange'],[1, 0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WYSubHTYkgM-"},"source":["**To get better understanding of the data let us visualize first five rows of the data using head () and last five rows of the data using tail()**"]},{"cell_type":"code","metadata":{"id":"PbGRFYYCkivt"},"source":["fruits_data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EySGzgsWzQD5"},"source":["fruits_data.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ev4ui_v2MfOQ"},"source":["There are a few noisy samples in the data which is skew in the accuracies. So here is the code to drop them. However before un-commenting the code below, go through the experiment and visualize those noisy samples and then re-run the experiment after un-commenting the lines below."]},{"cell_type":"code","metadata":{"id":"ESLVjza6OppH"},"source":["#fruits_data = fruits_data.drop(fruits_data[(fruits_data['labels'] == 1) & (fruits_data['Weight'] > 325)].index)\n","#fruits_data = fruits_data.drop(fruits_data[(fruits_data['labels'] == 0) & (fruits_data['Weight'] < 290)].index)\n","#fruits_data.head()\n","# To understand the above code properly look at the plot and also try to drop the noisy data of class 0 & class 1."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dA042UqZfQKn"},"source":["### Storing data and labels in two seperate variables\n"]},{"cell_type":"code","metadata":{"id":"EOLdINUZkpCo"},"source":["data = fruits_data[[\"Weight\",\"Color\",\"Sphericity\"]] "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7dLVITEjhfhc"},"source":["labels = fruits_data[\"labels\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LK8VJHlv71Bd"},"source":["data.shape, type(data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1OY3gGxUUMm4"},"source":["### Visualizing the data\n","\n"," Let us plot 2 parameters (out of the three) for visualization. (If you're interested in plotting in 3-D, which might be of help here, you can explore Matplotlib's Axes3D [here](https://jakevdp.github.io/PythonDataScienceHandbook/04.12-three-dimensional-plotting.html))"]},{"cell_type":"code","metadata":{"id":"cr0XqvV4LrXU"},"source":["apples = fruits_data[fruits_data['labels']== 1] # apples are 1\n","oranges = fruits_data[fruits_data['labels']== 0] # oranges are 0 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AstfIbIcLL6Q"},"source":["plt.plot(apples.Weight, apples.Sphericity, \"ro\")\n","plt.plot(oranges.Weight, oranges.Sphericity, \"bo\")\n","\n","plt.xlabel(\"Weight -- in grams\")\n","plt.ylabel(\"Sphericity -- r-o-y-g-b-p\")\n","\n","plt.legend([\"Apples\", \"Oranges\"])\n","\n","#plt.plot([373], [1], \"ko\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I7U-Twt17lbo"},"source":["### Splitting the data into train and test sets"]},{"cell_type":"code","metadata":{"id":"jjP5s4zX7vyL"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-t0sCcrA8Mhq"},"source":["# Let us see the size of train and test sets\n","X_train.shape, X_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EFpCi8-jbyOO"},"source":["### Training a  Linear Classifier "]},{"cell_type":"code","metadata":{"id":"5sNJ0RcK8neX"},"source":["linear_classifier = SGDClassifier(random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7FAEVCEL8qV2"},"source":["# Training or fitting the model with the train data\n","linear_classifier.fit(X_train, y_train)\n","\n","# Testing the trained model\n","y_pred = linear_classifier.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-wOGGUu287be"},"source":["# Calculating the score\n","linear_classifier.score(X_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P-LbWawq3ABl"},"source":["from sklearn.metrics import accuracy_score\n","accuracy_score(y_test, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ghgawtV6feya"},"source":["Not happy with the accuracies? How about trying to see which exact samples caused the accuracies to drop? (Especially given that this is a small dataset which can be doable. This sort of analysis is infeasible on large-datasets)"]}]}