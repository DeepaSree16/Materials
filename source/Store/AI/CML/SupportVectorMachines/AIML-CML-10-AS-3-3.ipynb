{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-CML-10-AS-3-3.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"i35LuPCsxJaQ"},"source":["\n","# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"x9wLqIUIyML-"},"source":["## Learning Objective"]},{"cell_type":"markdown","metadata":{"id":"lD86AWh0yHG4"},"source":["At the end of the experiment, you will be able to :\n","\n","* perform SVM classifier using different kernels"]},{"cell_type":"code","metadata":{"id":"mj2Y2HwZ9fzW","cellView":"form"},"source":["#@title Experiment Walthrough Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"854\" height=\"480\" controls>\n","  <source src=\"https://cdn.exec.talentsprint.com/content/svm_and_kernels.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R-H31RhK1lot"},"source":["### Dataset"]},{"cell_type":"markdown","metadata":{"id":"NH1Js1cUyWfo"},"source":["### History\n","\n","Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.\n"]},{"cell_type":"markdown","metadata":{"id":"P677A-Xb0ONT"},"source":["### Description\n","\n","Whenever you go to the bank to deposit some cash, money, the cashier places banknotes in a machine which tells whether a banknote is real or not. Therefore, to identify whether a banknote is real or not, you need a dataset of real as well as fake bank notes along with their different features.\n","\n","\n","The Banknote Authentication Data Set consists of 1372 instances. This is a binary classification problem which consists of 2 classes. Here our task is to predict whether a bank currency note is authentic or not based upon four attributes of the note.\n","\n","\n","\n","We have the below data attributes for Banknote Authentication\n","\n","- variance of Wavelet Transformed image\n","- skewness of Wavelet Transformed image\n","- curtosis of Wavelet Transformed image\n","- entropy of image \n","\n"]},{"cell_type":"markdown","metadata":{"id":"J0kyhxHZPhbk"},"source":["### AI / ML Technique"]},{"cell_type":"markdown","metadata":{"id":"3pWfnzLjPkDh"},"source":["### SVM\n","\n","In this experiment, we are using SVM.\n","\n","**Below is a quick overview of SVM.**\n","\n","* SVM assumes that the data is linearly separable.\n","\n","* It chooses the line which is more distant from both the classes.\n","\n","In the SVM algorithm, we find the points closest to the line from both the classes. These points are called support vectors. We compute the distance between the line and the support vectors which is called the margin. Our goal is to maximize the margin. The hyperplane for which the margin is maximum is called an optimal hyperplane.\n","\n","![alttxt](https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Images/SVM.png)\n","\n","\n"]},{"cell_type":"code","source":["!  wget -qq https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/bill_authentication.csv\")"],"metadata":{"id":"5VtigCH98T97"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ljGsDKkF3rHT"},"source":["### Importing required packages"]},{"cell_type":"code","metadata":{"id":"0mO_21Mp3lO7"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","from mlxtend.plotting import plot_decision_regions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vAhVr64D4Rf8"},"source":["### Loading the data"]},{"cell_type":"code","metadata":{"id":"jHWkrHDX4Bml"},"source":["dataset = \"bill_authentication.csv\"\n","bankdata = pd.read_csv(dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ZV0zxtx4G1E"},"source":["# Check the dimensions of the data \n","bankdata.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YlG1VWMDzXqz"},"source":["# Print first 5 rows of the data\n","bankdata.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HrNFJlhTNoib"},"source":["**Perform feature correlation to find linearly and non-linear separable classes that can be classified using SVM**\n","\n","To see the relationship between different features in our dataset let us use the “pairplot()” function from the Seaborn library. The function takes dataset as a parameter and plots a graph that contains relationships between all the features in the dataset as shown below:"]},{"cell_type":"code","metadata":{"id":"VHXi6Ja1t13P"},"source":["sns.pairplot(bankdata, hue=\"Class\", palette=\"bright\", height=2, aspect=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pSgn5qNGTWs2"},"source":["Considering 'Variance' and 'Skewness' features from the Banknote dataset, we see that the classes are not linearly separable."]},{"cell_type":"markdown","metadata":{"id":"6AWhQAVsOFSY"},"source":["### Storing the data into features and labels\n"]},{"cell_type":"code","metadata":{"id":"rLMT7Obk4wJB"},"source":["# Storing the data and labels into \"X\" and \"y\" variables\n","X = bankdata.drop('Class', axis=1)\n","y = bankdata['Class']\n","X = X.iloc[:,:2]\n","X.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o5wdbxLXPc7N"},"source":["### Visualizing the data"]},{"cell_type":"code","metadata":{"id":"_SFiaupZxLYe"},"source":["from matplotlib import pyplot as plt\n","plt.scatter(X.iloc[:,0], X.iloc[:,1], c=y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W2FH_Jg-5eqB"},"source":["### Splitting the data into train and test sets \n","\n","Note: [Train-Test split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"]},{"cell_type":"code","metadata":{"id":"_NTXCKN-5TgV"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J4LCegBV5ol5"},"source":["## Training a SVM Classifier with different Kernels"]},{"cell_type":"markdown","metadata":{"id":"Yi-Ve1tTP90D"},"source":["### Apply 'Linear' Kernel\n","\n","Linear Kernel in SVM is used to see the data is linearly separable data or not, which means if a dataset can be classified into two classes by using a single straight line.\n","\n","**Note:** Refer to  [SVM](https://scikit-learn.org/0.16/modules/generated/sklearn.svm.SVC.html)"]},{"cell_type":"code","metadata":{"id":"bSN2xLn46PN0"},"source":["# Create an object for 'SVC' with 'linear' kernel\n","svc_linear = SVC(kernel='linear') "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4-yzCki-UHh"},"source":["# Fit the data\n","svc_linear.fit(X_train, y_train)\n","\n","# Get the predictions on the test data\n","y_pred = svc_linear.predict(X_test)\n","\n","# Calculate the accuracy\n","accuracy_score(y_pred, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hIDQx7ivMlTV"},"source":["Visualization using linear Kernel"]},{"cell_type":"code","metadata":{"id":"BvkSlqROBkJx"},"source":["plot_decision_regions(X.values, y.values, svc_linear, legend=1)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HzddyvV0VqAF"},"source":["### Apply 'poly' Kernel\n","\n","The polynomial kernel is a kernel function that represents the similarity of vectors (training samples) in a feature space over polynomials of the original variables, allowing learning of non-linear models. Below is the formula to compute Polynomial function\n","\n","* $K(X, X_i) = (X*X_i + r)^d$\n","    * $X$ and $X_i$ are vectors in the input space, i.e. vectors of features computed from training or test samples\n","    * r determines the coefficients of the polynomial.\n","    * d determines the degree of the polynomial.\n","\n","**Note:** Refer to [SVM](https://scikit-learn.org/0.16/modules/generated/sklearn.svm.SVC.html)"]},{"cell_type":"code","metadata":{"id":"0bTI-yZ9YsN4"},"source":["# Create an object for 'SVC' with 'poly' kernel\n","svc_poly = SVC(kernel='poly')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a7Y_4L4S9smN"},"source":["# Fit the data\n","svc_poly.fit(X_train, y_train)\n","\n","# Get the predictions on the test data\n","poly_pred = svc_poly.predict(X_test)\n","\n","# Calculate the accuracy\n","accuracy_score(poly_pred, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"77wEWNbxMf7e"},"source":["Visualization using polynomial kernel"]},{"cell_type":"code","metadata":{"id":"e4y_EvX2BdMR"},"source":["plot_decision_regions(X.values, y.values, svc_poly, legend=1)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZaqabmlLZYrS"},"source":["### Apply 'rbf' Kernel\n","\n","The RBF kernel is also called the Gaussian Radial Basis kernel. RBF (Radial Basis Function) can map an input space in infinite dimensional space. This type of basis function transformation is known as a kernel transformation. The RBF kernel function for two points a and b computes the similarity between each pair of points or how close they are to each other. Below is the formula to compute RBF function.\n","\n","* $K(X, X_i) = exp^{(-\\gamma * \\sum(X-X_i)^2)}$\n","    * $X$ and $X_i$ are two feature vectors of two samples.\n","    * The difference between the vectors is then squared, i.e.  it gives squared euclidean distance.\n","    * $γ$ (Gamma) scales the squared euclidean distance and thus scales the influence the two vectors/points have on each other."]},{"cell_type":"code","metadata":{"id":"p0VP5tmIgDL1"},"source":["# Create an object for 'SVC' with 'rbf' kernel\n","svc_rbf = SVC(kernel='rbf')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KeIGmlyzLzeW"},"source":["# Fit the data\n","svc_rbf.fit(X_train, y_train)\n","\n","# Get the predictions on the test data\n","rbf_pred = svc_rbf.predict(X_test)\n","\n","# Calculate the accuracy\n","accuracy_score(rbf_pred, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sihk-0OR3DPC"},"source":["Visualization using RBF Kernel"]},{"cell_type":"code","metadata":{"id":"hwXNl9NCsSCs"},"source":["plot_decision_regions(X.values, y.values, svc_rbf, legend=1)\n","plt.show()"],"execution_count":null,"outputs":[]}]}