{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-CML-04-AS-1-1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"SnognA2MnOUp"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n","\n"]},{"cell_type":"markdown","metadata":{"id":"bGgCVs0KGzDN"},"source":["### Not for Grading"]},{"cell_type":"markdown","metadata":{"id":"L_aG2ggu-qxL"},"source":["## Learning Objective"]},{"cell_type":"markdown","metadata":{"id":"yxLDtcMD-0zm"},"source":["The objective of this experiment is to understand the KFold cross-validaton and Leave One Out\n"]},{"cell_type":"markdown","metadata":{"id":"1fFBQGayWHR8"},"source":["### Dataset Decription:\n","The dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n","\n","The datasets consists of several medical predictor variables and one target variable, Outcome.\n","\n","    Preg: Number of times pregnant\n","    Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n","    BloodPressure: Diastolic blood pressure (mm Hg)\n","    SkinThickness: Triceps skin fold thickness (mm)\n","    Insulin: 2-Hour serum insulin (mu U/ml)\n","    BMI: Body mass index (weight in kg/(height in m)^2)\n","    DiabetesPedigreeFunction: Diabetes pedigree function\n","    Age: Age (years)\n","    Outcome: Class variable (0 or 1)\n"]},{"cell_type":"markdown","metadata":{"id":"HDX5qQyNAxRR"},"source":["### K-Fold Cross Validation\n","\n","\n","The problem with machine learning models is that you won’t get to know how well a model performs until you test it's performance on an independent data set (the data set which was not used for training the machine learning model).\n","\n","Cross Validation comes in to picture here and helps us to estimate the performance of our model. One type of cross validation is the K-Fold Cross Validation\n","\n","In our experiment, we are using K-Fold Cross Validation  technique to reduce (limit) the problem of overfitting. K-Fold Cross Validation is a way to evaluate and improve the performance of our machine learning model. It helps to prevent from overfitting to a single train or test split. \n","\n","\n","When we are given a machine learning problem, we will be given two types of data sets — known data (training data set) and unknown data (test data set). By using cross validation, you would be “testing” your machine learning model in the “training” phase to check for overfitting and to get an idea about how your machine learning model will generalize to independent data, which is the test data set given in the problem.\n","\n","\n","In first round of cross validation, we have to divide our original training data set into two parts:\n","\n","1. Cross validation training set\n","2. Cross validation testing set or Validation set\n","\n","<img src=\"https://cdn.talentsprint.com/aiml/Experiment_related_data/IMAGES/K-Fold.png\" alt=\"drawing\" width=\"500\"/>\n","\n","\n","The above image represents how the K-Fold Cross Validation works. We divide the dataset in to \"K'' parts and will use the K-1 parts for training and remaining 1 for testing. We will rotate the test set and repeat the process for \"K\" times. \n","\n","we will train our machine learning model on the cross validation training set and test the model’s predictions against the validation set. we will get to know how accurate our machine learning model’s predictions are when we compare the model’s predictions on the validation set and the actual labels of the data points in the validation set.\n","\n","To reduce the variability, multiple rounds of cross validation are performed by using different cross validation training sets and cross validation testing sets. The results from all the rounds are averaged to estimate the accuracy of the machine learning model.\n","\n","**K-fold cross validation is performed as per the following steps:**\n","\n","1. Randomly split the entire training dataset into k subsets.\n","2. Reserve one block as our test data\n","3. Train on each of the remaining K-1 blocks\n","4. Measure the performance against the test set\n","5. The average of our K recorded errors is called the cross-validation error and it will be used as a performance metric for the model\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dcvKo4B1XNTX"},"source":["### Leave One Out\n","\n","Leave One Out is a special form of Cross-Validation. In this method each sample is used once as a test set while the remaining samples for the training set. A generalization error estimate is obtained by repeating this procedure for each of the training points available, averaging the results."]},{"cell_type":"code","source":["!wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/diabetes.csv\n","    "],"metadata":{"id":"48nZDGs_QWHf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sL7fUIUgEQki"},"source":["### Importing Required Packages"]},{"cell_type":"code","metadata":{"id":"X8bMSCmX8dLt"},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"poIPmkrlhkOZ"},"source":["### Prepare the model"]},{"cell_type":"code","metadata":{"id":"n_M73bNAhz9w"},"source":["diabetes_data = pd.read_csv(\"/content/diabetes.csv\")\n","diabetes_data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S3dyABY0w4lc"},"source":["Extracting features and labels from the diabetes data"]},{"cell_type":"code","metadata":{"id":"hayszB8hiHru"},"source":["x_data = diabetes_data.iloc[:,:-1].values\n","y_data = diabetes_data.iloc[:,-1].values\n","x_data.shape, y_data.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YsvmnJKGnrw4"},"source":["### Apply KFold"]},{"cell_type":"code","metadata":{"id":"hP7NHTZ_KLfu"},"source":["def crossvalidation(data):\n","    scores_Test = []\n","    for train_index, test_index in data.split(x_data):\n","        # Split the data into train and test\n","        x_train, x_test = x_data[train_index], x_data[test_index]\n","        y_train, y_test  = y_data[train_index], y_data[test_index]\n","\n","        # Create DecisionTree classifier object with hyper parameters \n","        decision_tree2 = DecisionTreeClassifier(max_depth=2)\n","        \n","        # Fit the data into the model\n","        decision_tree2.fit(x_train, y_train)\n","        scores_Test.append(decision_tree2.score(x_test, y_test))\n","    print(\"Average score of the Testing set %.2f\"%np.mean(scores_Test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dzcT5VNWV_P8"},"source":["# Set the KFold module for 5 splits:\n","kf = KFold(n_splits=5)\n","\n","# crossvalidation function returns the average score of the test data\n","crossvalidation(kf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-i5mmFYcXHkB"},"source":["### Ungraded Exercise 1"]},{"cell_type":"code","metadata":{"id":"9wwQoSVPWHwY"},"source":["from sklearn.model_selection import LeaveOneOut\n","# YOUR CODE HERE : Create the LeaveOneOut object and call crossvalidation function to get average score of the test data"],"execution_count":null,"outputs":[]}]}