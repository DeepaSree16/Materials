{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AIML-CML-04-AN-1-1.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"H7W6IuZjFVoD"},"source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RQL9oiyvFYck"},"source":["### Not for Grading"]},{"cell_type":"markdown","metadata":{"id":"JkxYpEOgC2-q"},"source":["## Learning Objectives\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iAZ1SeBoPskl"},"source":["At the end of the experiment, you will be able to:\n","\n","\n","* split dataset into k consecutive folds"]},{"cell_type":"markdown","metadata":{"id":"Ce27hwGdRLhS"},"source":["## AI /ML Technique"]},{"cell_type":"markdown","metadata":{"id":"S_gprAMYRGnb"},"source":["### K-Fold Cross Validation\n","\n","In k-fold cross-validation, the original sample is randomly partitioned into k equal sized subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k âˆ’ 1 subsamples are used as training data. The cross-validation process is then repeated k times, with each of the k subsamples used exactly once as the validation data. The k results can then be average to produce a single estimation."]},{"cell_type":"code","source":["!wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Purchase_Dataset.csv\n","    "],"metadata":{"id":"w08na0UmQNQM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4AO135J3Xrqi"},"source":["### **Section I: Understand the k-fold data split**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OfleGJ0189Ta"},"source":["#### Importing required packages"]},{"cell_type":"code","metadata":{"id":"w8NWXWUDXrVy"},"source":["# Import required packages\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import KFold\n","from sklearn.neighbors import KNeighborsClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X9iRT4rmoZQ-"},"source":["x = np.array([\"yellow\", \"blue\", \"pink\", \"white\", \"red\", \"violet\", \"orange\", \"green\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MGY9R4aRp0_4"},"source":["# Set the KFold module for 4 splits:\n","kf = KFold( n_splits=4 )\n","i = 0\n","\n","# Divide the data into trainindex and testindex\n","# K splits are iterated \n","for trainindex, testindex in kf.split(x):\n","    print( \"Round :\", i, \":\" ) \n","    i += 1\n","\n","    print( \"Training index\", trainindex, \"Training set is:\", x[trainindex])\n","    print( \"Testing index\", testindex, \"Testing set is:\", x[testindex])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eKUsxwH9Aysd"},"source":["### **Section II: K-fold using Purchase_Dataset**"]},{"cell_type":"code","metadata":{"id":"Epy-NOUWQ_Me"},"source":["# Read the data in to a pandas dataframe\n","data = pd.read_csv(\"/content/Purchase_Dataset.csv\")\n","\n","print( \"Shape of data\", data.shape)\n","# The first few lines of data to verify the data\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SNXY1Si_2hL0"},"source":["# Get unique values of Gender\n","#data[\"Gender\"].unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X3fDv-DJ2xVg"},"source":["# Convert categorial values to numerical values \n","#data[\"Gender\"] = data[\"Gender\"].replace([ \"Male\", \"Female\"],[ 0, 1])\n","#data[\"Gender\"].head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CqOQ4mlB6gDT"},"source":["LabelEncoder() is a utility class to help normalize labels such that they contain only values between 0 and n_classes-1. It can also be used to transform non-numerical labels to numerical labels"]},{"cell_type":"code","metadata":{"id":"WHioUOA5ryzl"},"source":["# Convert categorial values to numerical values using label encoder\n","from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()  \n","data[\"Gender\"] = le.fit_transform(data[\"Gender\"])  # fit_transform, Fit label encoder and return encoded labels.\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lC9ab5owRE6R"},"source":["# X will be our independent/feature variables and y is our dependent/target variable\n","X = data[[\"Age\", \"EstimatedSalary\", \"Gender\"]]\n","y = data[\"Purchased\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nZQ51u4a5OD2"},"source":["#### Splitting the data using Kfold"]},{"cell_type":"code","metadata":{"id":"XZT-K8vndPk4"},"source":["# Set the our KFold module for 4 splits:\n","kf = KFold(n_splits=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SQZb65_v-u3O"},"source":["x_data = X.values\n","i = 1\n","# Divide the data into trainindex and testindex\n","# K splits are iterated \n","for train_index, test_index in kf.split(x_data):\n","   \n","    x_train, x_test, y_train, y_test = x_data[train_index], x_data[test_index], y[train_index], y[test_index]\n","    print( \"Split :\", i, \":\" ) \n","    i += 1\n","    print( \"Distribution of Training labels:\", y_train.values)\n","    print( \"Distribution of Testing labels:\", y_test.values)\n","    print(\"--------------------------------------\")"],"execution_count":null,"outputs":[]}]}