{"cells":[{"cell_type":"markdown","metadata":{"id":"powered-thong"},"source":["# Applied Data Science and Machine Intelligence\n","## A program by IIT Madras and TalentSprint\n","### Mini Project 5 : Software Use Case - Issue Detection"]},{"cell_type":"markdown","metadata":{"id":"1nK0fzdQzk0g"},"source":["## Learning Objectives\n","\n","At the end of the mini project, you will be able to -\n","\n","* Get an understanding of the dataset.\n","* Perform Extensive EDA and Visualizations\n","* Handraft the raw data suitable for a ML problem\n","* Predict(Classify) the Bugs\n"]},{"cell_type":"markdown","metadata":{"id":"5xoyNc-yTy7U"},"source":["## Information"]},{"cell_type":"markdown","metadata":{"id":"FvhRny6xpviu"},"source":["### Issue Classification\n","\n","A company that uses online issue tracking system, often gets a hurdle with the performance of the human resources and digital resource allocation. This is due the fact that the persons raising tickets sometimes put it in under a different tag or a category. Redirections to solve the issue throught the right person takes more time. So it is essential to solve it on time by linking the appropriate issue tags. This role will be taken care by the area of Machine Learning called as Natural Language Processing (NLP). In this Mini-Project we will be utilizing the fundamental building blocks of the NLP to classify the issues under appropriate categories based on the text body of the issue/ticket being raised."]},{"cell_type":"markdown","metadata":{"id":"mFyE8NDOUPyq"},"source":["### About the Dataset\n","\n","This Mini-Project uses the Dataset from the [GitHub](https://github.com/roundcube/roundcubemail/issues). It contains the issues of Roundcube mail application, along with the software defect labelled across each issue."]},{"cell_type":"markdown","metadata":{"id":"hungry-accident"},"source":["**Python Packages used:**  \n","\n","* [`Google.colab`](https://colab.research.google.com/notebooks/io.ipynb) for linking the notebook to your Google-drive\n","* [`Pandas`](https://pandas.pydata.org/docs/reference/index.html) for data frames and easy to read csv files  \n","* [`Numpy`](https://numpy.org/doc/stable/reference/index.html#reference) for array and matrix mathematics functions  \n","* [`sklearn`](https://scikit-learn.org/stable/user_guide.html) for the pre-processing data, building ML models, and performance metrics\n","* [`seaborn`](https://seaborn.pydata.org/) and [`matplotlib`](https://matplotlib.org/) for plotting\n","* [`regex`](https://docs.python.org/3/library/re.html) and [`nltk`](https://www.nltk.org/) for text preocessing\n"]},{"cell_type":"markdown","metadata":{"id":"u-g3SLm-DLEW"},"source":["## Importing the packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_V0z4eaDILg"},"outputs":[],"source":["### The required libraries and packages ###\n","import pandas as pd\n","import numpy as np\n","from google.colab import drive\n","import seaborn as sns\n","import regex as re\n","\n","import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import Normalizer, StandardScaler\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.preprocessing import \n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"uw7Z9BHgU0PL"},"source":["## Importing the Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EtBadif5VixE"},"outputs":[],"source":["drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pdduayuwN171"},"outputs":[],"source":["path = 'drive/MyDrive/<YOUR FOLDER NAME AS IT APPEARS ON GOOGLE DRIVE>'\n","\n","df_raw = pd.read_csv(path+'issues_data.csv')\n","print(df_raw.shape)\n","df_raw.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gbGi8TFG8MWy"},"outputs":[],"source":["df = df_raw.copy()\n","df.head(2)"]},{"cell_type":"markdown","metadata":{"id":"mvHJsdQB4tYi"},"source":["## Graded Exercises (10 points)"]},{"cell_type":"markdown","metadata":{"id":"M-wokqH94zBd"},"source":["### Exercise 1 (1 point): Basic EDA\n","\n","- Check the shape of the data\n","- Check the nulls present in each field\n","- Check the unique number of entries per field\n","- Drop the features that are either redundant or that do not help in modelling\n","\n","\n","**Hint** : Use the `pandas` module"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dI8LpqKkSbNw"},"outputs":[],"source":["# Check the shape of the data\n","# YOUR CODE HERE"]},{"cell_type":"code","source":["# Check the nulls present in each field\n","# YOUR CODE HERE"],"metadata":{"id":"jZgdhhHn4VpU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the unique number of entries per field\n","# YOUR CODE HERE"],"metadata":{"id":"o3pW2qjT4Zhw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the statistics of the data for each column\n","# YOUR CODE HERE"],"metadata":{"id":"d2tzzX_T4eZu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove the unwanted columns\n","# YOUR CODE HERE"],"metadata":{"id":"dl5YI07NT3RY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-F_8MS1xOIdg"},"source":["### Exercise 2 (3 Marks): Text Pre-Processing for Feature Columns\n","\n","For each row of the data, write **functions** perform the following steps seperately for the feature Data columns - `Issue Title` and `Issue Body`\n","\n"]},{"cell_type":"code","source":["stopwords = nltk.corpus.stopwords.words('english')\n","print(stopwords)"],"metadata":{"id":"gfrGKh9QOEXY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Function - 1: (To be performed for `Issue Title` ONLY)**\n","\n","Hint: The following steps will be present in both the functions\n","\n","* Make all the texts to Lower case\n","* Remove punctuations, numbers, symbols and other emojis and replace with empty spaces. \n","\n","  This is done to ensure only the text is retained.\n","* Strip the excess spaces\n","* Remove the stop words using english stop words of nltk library\n","* Strip the excess spaces\n","* Remove words smaller than 3 letters (example: a, i , n, it, js, ab etc. )"],"metadata":{"id":"7Noj9heBpDFk"}},{"cell_type":"code","source":["def tp_title(text_data):\n","\n","  # Step - Convert to lower case\n","  # YOUR CODE HERE\n","\n","  # Step - Keep only alphabetical characters\n"," # YOUR CODE HERE\n","\n","  # Step - Strip the excess spaces\n","  # YOUR CODE HERE\n","\n","  # Step - Remove words smaller than 3 letters\n","  # YOUR CODE HERE\n","\n","  # Step - Join Back the words\n","  # YOUR CODE HERE\n","\n","  # Step - Remove the English Stop words\n","  # YOUR CODE HERE\n","\n","  # stop_words_eng = set(stopwords.words('english'))\n","  # YOUR CODE HERE  \n","\n","  # Step - Join Back the words\n","  # YOUR CODE HERE\n","\n","  return text_data"],"metadata":{"id":"XGV3m50pNvvm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Function - 2 (To be performed for `Issue Body` ONLY)**\n","\n","Hint: Either copy paste the steps of Function-1 or call the function and add the below steps\n","\n","* Split lines \n","* Remove first and last lines such as \n","\n","  -`_Reported by L1Ntu on 17 Apr 2014 19:41 UTC as Trac ticket #1489818_`\n","\n","  -`_Migrated-From: http://trac.roundcube.net/ticket/1489818_`\n","\n","  by replacing with empty/no space - `\" \"` or `\"\"`\n","* Remove lines containing urls\n","\n","  (**Hint**: it contains `http`,`www.`, `.com`, `.net` etc) by replacing with empty/no space\n","* Join back the lines with a space `\" \"`\n","* Strip the excess spaces\n","\n","**Hint:** For the below tasks, Copy paste the lines of code from above `Function-1`\n","* Make all the texts to Lower case\n","* Remove punctuations, numbers, symbols and other emojis and replace with empty spaces. \n","\n","  This is done to ensure only the text is retained.\n","* Strip the excess spaces\n","* Remove the stop words using english stop words of nltk library\n","* Strip the excess spaces\n","* Remove words smaller than 3 letters (example: a, i , n, it, js, ab etc. )\n","* Strip the excess spaces\n","* If the entry contains only a space `\" \"`, replace it with no character `\"\"`"],"metadata":{"id":"0chK-YFGpDcv"}},{"cell_type":"markdown","source":["#### Using the functions: \n","\n","For each Use the above 2 functions on respective columns, to achieve the desired tasks."],"metadata":{"id":"3UzV1DtrpTsB"}},{"cell_type":"code","source":["def tp_body(text_data):\n","\n","  # Step - Splitlines\n","  # YOUR CODE HERE\n","\n","  # Step - Remove Last Lines\n","  # YOUR CODE HERE\n","\n","  # Step - Remove the lines that contain any URLs\n","  url_terms = [\"www\", \"http\", \".net\", \".com\"]\n","  # YOUR CODE HERE\n","\n","  # Step - Join Back the lines\n","  # YOUR CODE HERE\n","\n","  # Step - Strip the excess spaces\n","  # YOUR CODE HERE\n","\n","  # Step - Convert to lower case\n","  # YOUR CODE HERE\n","\n","  # Step - Keep only alphabetical characters\n","  # YOUR CODE HERE\n","\n","  # Step - Strip the excess spaces\n","  # YOUR CODE HERE\n","\n","  # Step - Remove words smaller than 3 letters\n","  # YOUR CODE HERE\n","\n","  # Step - Join Back the words\n","  # YOUR CODE HERE\n","\n","  # Step - Remove recurring Characters\n","  # YOUR CODE HERE\n","\n","  # Step - Remove the English Stop words\n","  stop_words_eng = nltk.corpus.stopwords.words('english')\n","  # stop_words_eng = set(stopwords.words('english'))\n","  # YOUR CODE HERE  \n","\n","  # Step - Join Back the words\n","  # YOUR CODE HERE\n","\n","  return text_data  "],"metadata":{"id":"ruOuDCPNzxfv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply the above functions here\n","df['Issue Body'] = df['Issue Body'].apply(lambda x: tp_body(x))\n","df['Issue Title'] = df['Issue Title'].apply(lambda x: tp_title(x))\n","df.head()"],"metadata":{"id":"iMZyyH72Niw4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Drop all the rows that have no content in them\n","# YOUR CODE HERE"],"metadata":{"id":"CCKHCbw8NVih"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Exercise 3a (1 point): Feature Engineering Approach-1\n","\n","* Combine the title and body strings by a space\n","*  the words\n","* Use `CountVectorizer` to Tokenize and transform the the text to features\n","* Reduce the features using PCA"],"metadata":{"id":"HaATx5TCrXLr"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JKGS3VaV4iNf"},"outputs":[],"source":["corpus_body = list(df[\"Issue Title\"]+\" \"+df[\"Issue Body\"])\n","# YOUR CODE HERE"]},{"cell_type":"markdown","source":["### Exercise 4a (1 point) : Data Preparation\n","\n","* Check for the data value counts to see the data imbalance\n","  - Merge the smaller classes to a bigger class so that the number of classes is between 3 and 4\n","\n","* Perform Label Encoding for the Target variable classes\n","\n","* Create a New DataFrame\n","  - Merge the dataframe with PCA filtered variables and \n","\n","    the Target variable-1 `\"Defect Type Family using IEEE\"` and  \n","\n","    the Target variable -2 `\"Defect Type Family using ODC\"`\n","\n","* Split the above data into Training and Testing Datasets\n","\n","\n"],"metadata":{"id":"y3XHQPZrngAV"}},{"cell_type":"code","source":["# Check the class Distribution of the Target Variables\n","# YOUR CODE HERE"],"metadata":{"id":"du7ph27bE74h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Replace the minority classes into a class with larger count\n","# YOUR CODE HERE"],"metadata":{"id":"bgU3vDBah9A4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the class Distribution of the Target Variables AGAIN\n","# YOUR CODE HERE"],"metadata":{"id":"F3c2EQXxhQCQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Label Encode the Target Variable-1\n","# YOUR CODE HERE"],"metadata":{"id":"6vUq_CsQo1Jz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Label Encode the Target Variable-2\n","# YOUR CODE HERE"],"metadata":{"id":"w2pY1B9Ao1Fp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MERGE the features and target in a single DataFrame\n","# YOUR CODE HERE"],"metadata":{"id":"u7XFIyb7o092"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check for nulls if any, and fill the values with a new class (integer)\n","# YOUR CODE HERE"],"metadata":{"id":"quQ0jdQK0_UD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the Data into training and testing, for Target Variable-1 \n","# YOUR CODE HERE"],"metadata":{"id":"MGdnqVPMtY8r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the Data into training and testing, for Target Variable-2\n","# YOUR CODE HERE"],"metadata":{"id":"he1v7anXnVOS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Exercise 5a (1 point) : Classification\n","\n","* Classification-Target 1 (`\"Defect Type Family using IEEE\"`)\n","\t\n","    - Perform classification using any ONE of your favorite Sklearn's classifier\n","\n","    - Explain with metrics\n","\n","* Classification-Target 2 (`\"Defect Type Family using ODC\"`)\n","\t\n","    - Perform classification using any ONE of your favorite Sklearn's classifier\n","\n","    - Explain with metrics\n","\n","**Tip**: Train the model and predict on seperate cells. It will save time debugging."],"metadata":{"id":"FcWqda-YrkJW"}},{"cell_type":"code","source":["# Import the classifier Functions\n","# YOUR CODE HERE"],"metadata":{"id":"bCX6zID6ff3u"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5N47ZVuly-O9"},"outputs":[],"source":["# MODEL 1\n","\n","# Call and fit the model on Training Data\n","# Predict on the test data\n","# YOUR CODE HERE"]},{"cell_type":"code","source":["# Print confusion_matrix,  andclassification_report\n","# YOUR CODE HERE"],"metadata":{"id":"pQVvTB7DXo7F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MODEL 2\n","\n","# Call and fit the model on Training Data\n","# Predict on the test data\n","# YOUR CODE HERE"],"metadata":{"id":"6TNAljuFppHy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print confusion_matrix,  andclassification_report\n","# YOUR CODE HERE"],"metadata":{"id":"LcGJxAuMbVvS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### YOUR FINDINGS/ Reasoning for which model is better and why (Qualitatively and Quantatively)\n","\n","Explain why one model behaves better than the other(s) in terms of Accuracy, Precision, Recall and F1-Score"],"metadata":{"id":"wJhjqBh3hClZ"}},{"cell_type":"markdown","source":["### Exercise 3b (1 point): Feature Engineering Approach-2\n","\n","* Combine the title and body strings by a space\n","*  the words\n","* Use `TfidfVectorizer` to Tokenize and transform the the text to features\n","* Reduce the features using PCA"],"metadata":{"id":"fj3766rrgYBz"}},{"cell_type":"code","source":["\n","corpus_body = list(df[\"Issue Title\"]+\" \"+df[\"Issue Body\"])\n","vectorizer_body = TfidfVectorizer()\n","Xbody           = vectorizer_body.fit_transform(corpus_body)\n","X_body          = Xbody.toarray()\n","\n","features_body   = vectorizer_body.get_feature_names_out()\n","print(X_body.shape)\n","\n","\n","n_pc = 30\n","pca = PCA(n_components=n_pc, svd_solver='full')\n","X_body_new = pca.fit_transform(X_body)\n","\n","print(f\"explained_variance_ratio_ = \\n{pca.explained_variance_ratio_}\")\n","print(f\"\\nsingular_values_ = \\n{pca.singular_values_}\")\n","\n","from sklearn.preprocessing import Normalizer\n","X_body_new = Normalizer().fit_transform(X_body_new)\n","\n","\n","cols_pc = []\n","for nth_pc in range(n_pc):\n","  cols_pc.append(f\"pc_{nth_pc+1}\")\n","\n","\n","df_body_counts  = pd.DataFrame(data=X_body_new, columns=cols_pc)\n","df_body_counts = df_body_counts.replace(np.nan, 0)\n","df_body_counts = df_body_counts.replace(np.NaN, 0)\n","df_body_counts"],"metadata":{"id":"Lh4U2L04iXof"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Exercise 4b (1 point) : Data Preparation\n","\n","* Check for the data value counts to see the data imbalance\n","  - Merge the smaller classes to a bigger class so that the number of classes is between 3 and 4\n","\n","* Perform Label Encoding for the Target variable classes\n","\n","* Create a New DataFrame\n","  - Merge the dataframe with PCA filtered variables and \n","\n","    the Target variable-1 `\"Defect Type Family using IEEE\"` and  \n","\n","    the Target variable -2 `\"Defect Type Family using ODC\"`\n","\n","* Split the above data into Training and Testing Datasets\n","\n","\n"],"metadata":{"id":"NyCSlLTHjDek"}},{"cell_type":"code","source":["# Check the class Distribution of the Target Variables\n","# YOUR CODE HERE"],"metadata":{"id":"A4q5zuXsogrL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Replace the minority classes into a class with larger count\n","# YOUR CODE HERE"],"metadata":{"id":"jXkTYVafogrZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the class Distribution of the Target Variables AGAIN\n","# YOUR CODE HERE"],"metadata":{"id":"UUFyaxXnogrZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Label Encode the Target Variable-1\n","# YOUR CODE HERE"],"metadata":{"id":"Jw9Dt1aeogra"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Label Encode the Target Variable-2\n","# YOUR CODE HERE"],"metadata":{"id":"uZ2FJgJGogrb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MERGE the features and target in a single DataFrame\n","# YOUR CODE HERE"],"metadata":{"id":"mS538Muaogrb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check for nulls if any, and fill the values with a new class (integer)\n","# YOUR CODE HERE"],"metadata":{"id":"9eA3Nlhbogrb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the Data into training and testing, for Target Variable-1 \n","# YOUR CODE HERE"],"metadata":{"id":"T8n_O7atogrb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the Data into training and testing, for Target Variable-2\n","# YOUR CODE HERE"],"metadata":{"id":"hTs8ezVtogrc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Exercise 5b (1 point) : Classification\n","\n","* Classification-Target 1 (`\"Defect Type Family using IEEE\"`)\n","\t\n","    - Perform classification using any ONE of your favorite Sklearn's classifier\n","\n","    - Explain with metrics\n","\n","* Classification-Target 2 (`\"Defect Type Family using ODC\"`)\n","\t\n","    - Perform classification using any ONE of your favorite Sklearn's classifier\n","\n","    - Explain with metrics\n","\n","**Tip**: Train the model and predict on seperate cells. It will save time debugging."],"metadata":{"id":"_SbQiOSIjfM2"}},{"cell_type":"code","source":["# Import the classifier Functions\n","# YOUR CODE HERE"],"metadata":{"id":"g1zrnYjPoSGR"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bNYvO-R8oSGU"},"outputs":[],"source":["# MODEL 1\n","\n","# Call and fit the model on Training Data\n","# Predict on the test data\n","# YOUR CODE HERE"]},{"cell_type":"code","source":["# Print confusion_matrix,  andclassification_report\n","# YOUR CODE HERE"],"metadata":{"id":"z8tg9KEsoSGV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MODEL 2\n","\n","# Call and fit the model on Training Data\n","# Predict on the test data\n","# YOUR CODE HERE"],"metadata":{"id":"T6FZdQI9oSGV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print confusion_matrix,  andclassification_report\n","# YOUR CODE HERE"],"metadata":{"id":"DmJvcu4KoSGV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hopfRuo7WHVR"},"source":["## Additional Ungraded Exercise for Practice:\n","\n","From the Data Perspective:\n","\n","- Try taking ONLY the Issue Title as the feature set\n","- Try taking ONLY the Issue Body as the feature set\n","- Try various data scaling techniques\n","\n","From the ML Model Perspective:\n","- Try out for other ML Models\n","- Try GridSearch\n","- Try Cross-Validation techniques"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"M3_MP6_NB_Software_Bugs.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}