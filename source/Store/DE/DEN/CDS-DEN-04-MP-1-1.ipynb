{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"colab":{"name":"M3_NB_MiniProject_4_End_to_End_Analytics_Pyspark.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"intensive-feature"},"source":["# Advanced Certification Program in Computational Data Science\n","## A program by IISc and TalentSprint\n","### Mini-Project: End-to-end analytics application using Pyspark"],"id":"intensive-feature"},{"cell_type":"markdown","metadata":{"id":"buried-qualification"},"source":["## Problem Statement"],"id":"buried-qualification"},{"cell_type":"markdown","metadata":{"id":"smaller-diana"},"source":["Perform sentiment classification by analyzing the tweets data with Pyspark"],"id":"smaller-diana"},{"cell_type":"markdown","metadata":{"id":"opposite-defense"},"source":["## Learning Objectives"],"id":"opposite-defense"},{"cell_type":"markdown","metadata":{"id":"incoming-professor"},"source":["At the end of the mini-project, you will be able to :\n","\n","* analyze the text data using pyspark\n","* derive the insights and visualize the data\n","* implement feature extraction and classify the data\n","* train the classification model and deploy"],"id":"incoming-professor"},{"cell_type":"markdown","metadata":{"id":"varied-emission"},"source":["### Dataset"],"id":"varied-emission"},{"cell_type":"markdown","metadata":{"id":"usual-suffering"},"source":["The dataset chosen for this mini-project is **[Twitter US Airline Sentiment](https://data.world/socialmediadata/twitter-us-airline-sentiment)**. It is a record of tweets about airlines in the US. It was created by scraping Twitter data from February 2015. Contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\").  Along with other information, it contains ID of a Tweet, the sentiment of a tweet ( neutral, negative and positive), reason for a negative tweet, name of airline and text of a tweet."],"id":"usual-suffering"},{"cell_type":"markdown","metadata":{"id":"original-tsunami"},"source":["## Information"],"id":"original-tsunami"},{"cell_type":"markdown","metadata":{"id":"premier-northeast"},"source":["The airline industry is a very competitive market that has grown rapidly in the past 2 decades. Airline companies resort to traditional customer feedback forms which in turn are very tedious and time consuming. This is where Twitter data serves as a good source to gather customer feedback tweets and perform sentiment analysis. This dataset comprises of tweets for 6 major US Airlines and a multi-class classification can be performed to categorize the sentiment (neutral, negative, positive). For this mini-project we will start with pre-processing techniques to clean the tweets and then represent these tweets as vectors. A classification algorithm will be used to predict the sentiment for unseen tweets data. The end-to-end analytics will be performed using Pyspark."],"id":"premier-northeast"},{"cell_type":"markdown","metadata":{"id":"BewwTjZaJojg"},"source":["## Grading = 10 Points"],"id":"BewwTjZaJojg"},{"cell_type":"markdown","metadata":{"id":"younger-macro"},"source":["#### Install Pyspark"],"id":"younger-macro"},{"cell_type":"code","metadata":{"id":"aerial-amplifier","cellView":"form"},"source":["#@title Install packages and download the dataset\n","!pip -qq install pyspark\n","!pip -qq install handyspark\n","!wget -qq https://cdn.iisc.talentsprint.com/CDS/MiniProjects/US_Airline_Tweets.csv\n","print(\"Packages installed successfully and dataset downloaded!!\")"],"id":"aerial-amplifier","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rough-battlefield"},"source":["#### Import required packages"],"id":"rough-battlefield"},{"cell_type":"code","metadata":{"id":"cheap-workplace"},"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","from handyspark import *\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","import re\n","import string\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.feature import CountVectorizer\n","from pyspark.ml.classification import NaiveBayes\n","from pyspark.sql.types import ArrayType, StringType"],"id":"cheap-workplace","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"useful-meter"},"source":["# NLTK imports\n","import nltk\n","nltk.download('punkt')\n","# Download stopwords\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer"],"id":"useful-meter","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pregnant-april"},"source":["### Data Loading"],"id":"pregnant-april"},{"cell_type":"markdown","metadata":{"id":"toxic-baseball"},"source":["#### Start a Spark Session\n","\n","Spark session is a combined entry point of a Spark application, which came into implementation from Spark 2.0. It provides a way to interact with various Spark functionalities, with a lesser number of constructs."],"id":"toxic-baseball"},{"cell_type":"code","metadata":{"id":"christian-rental"},"source":["# YOUR CODE HERE\n"],"id":"christian-rental","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"casual-narrative"},"source":["#### Load the data and infer the schema\n","\n","To load the dataset use the `read.csv` with `inferSchema` and `header` as parameters."],"id":"casual-narrative"},{"cell_type":"code","metadata":{"id":"natural-lexington"},"source":["path = \"/content/US_Airline_Tweets.csv\"\n","# YOUR CODE HERE"],"id":"natural-lexington","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lFZu1AVBHs0X"},"source":["### EDA & Visualization ( 2 points)"],"id":"lFZu1AVBHs0X"},{"cell_type":"markdown","metadata":{"id":"angry-canyon"},"source":["#### Visualize the horizontal barplot of airline_sentiment (positive, negative, neutral)\n","\n","Convert the data to handyspark and remove the other records from the column except 3 values mentioned above and plot the graph"],"id":"angry-canyon"},{"cell_type":"code","metadata":{"id":"accomplished-crest"},"source":["# YOUR CODE HERE"],"id":"accomplished-crest","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"serial-cedar"},"source":["#### Plot the number of tweets received for each airline"],"id":"serial-cedar"},{"cell_type":"code","metadata":{"id":"peripheral-bookmark"},"source":["# YOUR CODE HERE"],"id":"peripheral-bookmark","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"surface-major"},"source":["#### Visualize a stacked barchart of 6 US airlines and 3 sentiments on each bar\n","\n","* Display the count corresponding to each sentiment in each bar. [hint](https://priteshbgohil.medium.com/stacked-bar-chart-in-python-ddc0781f7d5f)"],"id":"surface-major"},{"cell_type":"code","metadata":{"id":"FkhT25vtNuz8"},"source":["# YOUR CODE HERE"],"id":"FkhT25vtNuz8","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ahead-control"},"source":["#### Visualize the horizontal barplot of negative reasons"],"id":"ahead-control"},{"cell_type":"code","metadata":{"id":"coordinate-rough"},"source":["# YOUR CODE HERE"],"id":"coordinate-rough","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3qwi5krQH1Q3"},"source":["### Pre-processing (3 points)"],"id":"3qwi5krQH1Q3"},{"cell_type":"markdown","metadata":{"id":"pharmaceutical-agency"},"source":["#### Check the null values and drop the records where the text value is null"],"id":"pharmaceutical-agency"},{"cell_type":"code","metadata":{"id":"x4hU06aBNzHj"},"source":["# YOUR CODE HERE"],"id":"x4hU06aBNzHj","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"convinced-batch"},"source":["#### Fill the null values with 0 in all the columns except the target\n","\n","The target should not be empty. Ensure that all features are integer type, convert if needed."],"id":"convinced-batch"},{"cell_type":"code","metadata":{"id":"thorough-jones"},"source":["# YOUR CODE HERE"],"id":"thorough-jones","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"first-david"},"source":["#### Preprocessing and cleaning the tweets\n","\n","* Convert the text to lower case\n","* Remove usernames, hashtags and links from the text (tweets)"],"id":"first-david"},{"cell_type":"code","metadata":{"id":"studied-blowing"},"source":["# YOUR CODE HERE"],"id":"studied-blowing","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"subtle-spain"},"source":["#### Tokenize each sentence into words using nltk word tokenizer"],"id":"subtle-spain"},{"cell_type":"code","metadata":{"id":"yellow-wholesale"},"source":["# YOUR CODE HERE"],"id":"yellow-wholesale","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"recognized-wrist"},"source":["#### Remove the stopwords from tokenized words"],"id":"recognized-wrist"},{"cell_type":"code","metadata":{"id":"scientific-guinea"},"source":["stop_words = set(stopwords.words('english'))\n","print(stop_words)"],"id":"scientific-guinea","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pleased-skiing"},"source":["# YOUR CODE HERE"],"id":"pleased-skiing","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"persistent-projection"},"source":["#### Apply Lemmatization to the words"],"id":"persistent-projection"},{"cell_type":"code","metadata":{"id":"asian-parade"},"source":["# YOUR CODE HERE"],"id":"asian-parade","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UR5FnuSn-c-S"},"source":["### Feature Extraction (3 points)\n","\n","Create the useful features from the text column to train the model\n","\n","For example:\n","* Length of the tweet \n","* No. of hashtags in the tweet starting with '#'\n","* No. of mentions in the tweet starting with '@'\n","\n","Hint: create a new column for each of the above features"],"id":"UR5FnuSn-c-S"},{"cell_type":"code","metadata":{"id":"lyric-processor"},"source":["# YOUR CODE HERE"],"id":"lyric-processor","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"under-point"},"source":["#### Get the features by applying CountVectorizer\n","CountVectorizer converts the list of tokens to vectors of token counts. See the [documentation](https://spark.apache.org/docs/latest/ml-features.html#countvectorizer) for details."],"id":"under-point"},{"cell_type":"code","metadata":{"id":"christian-voltage"},"source":["# YOUR CODE HERE"],"id":"christian-voltage","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"killing-aside"},"source":["#### Encode the labels\n","\n","Using the `udf` function encode the string values of *airline_sentiment* to integers."],"id":"killing-aside"},{"cell_type":"code","metadata":{"id":"assigned-trout"},"source":["def LabelEncoder(x):\n","    if x == 'positive':\n","        return 0\n","    elif x == 'negative':\n","        return 1\n","    return 2\n","\n","# YOUR CODE HERE"],"id":"assigned-trout","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NqnjXJR9IC5d"},"source":["### Train the classifier the evaluate (1 point)"],"id":"NqnjXJR9IC5d"},{"cell_type":"markdown","metadata":{"id":"attempted-lender"},"source":["#### Create vector assembler with the selected features to train the model"],"id":"attempted-lender"},{"cell_type":"code","metadata":{"id":"stuffed-seating"},"source":["# YOUR CODE HERE"],"id":"stuffed-seating","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bored-metropolitan"},"source":["#### Arrange features and label and split them into train and test."],"id":"bored-metropolitan"},{"cell_type":"code","metadata":{"id":"structured-actress"},"source":["# YOUR CODE HERE"],"id":"structured-actress","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fiscal-utilization"},"source":["#### Train the model with train data and make predictions on the test data\n","\n","For classification of text data, implement NaiveBayes classifier. It is a probabilistic machine learning model.\n","\n","For more information about **NaiveBayes Classifier**, click [here](https://spark.apache.org/docs/latest/ml-classification-regression.html#naive-bayes)"],"id":"fiscal-utilization"},{"cell_type":"code","metadata":{"id":"destroyed-religion"},"source":["nb = NaiveBayes(featuresCol='features', labelCol='labels')\n","# Fit the model with train data\n","model = nb.fit(train_data)"],"id":"destroyed-religion","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"seeing-money"},"source":["# get the predictions\n","# YOUR CODE HERE"],"id":"seeing-money","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"foreign-consent"},"source":["#### Evaluate the model and find the accuracy\n","\n","Compare the labels and predictions and find how many are correct.\n","\n","To find the accuracy, get the count of correct predictions from test data and divide by the total amount of test dataset.\n","\n","**Hint:** convert the predictions dataframe to pandas and compare with labels"],"id":"foreign-consent"},{"cell_type":"code","metadata":{"id":"greenhouse-crack"},"source":["# YOUR CODE HERE"],"id":"greenhouse-crack","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"neugaxggvfrY"},"source":["### Deployment (1 point)\n","\n","Let's integrate all the above code snippets in app.py and run it with **Streamlit**.\n","\n","From the start (data loading step), place every code in app.py including data preprocessing, feature extraction and model training.\n","\n","* implement the `predict_users_Input()` function which takes one tweet input from user and returns the prediction using the trained model.\n","\n","* use the same preprocessing techniques and features extraction used for train data on user input.\n","\n","* user input can be captured from the textbox from **Streamlit** app. Action is triggered when predict button is clicked and user input is classified using `predict_users_Input()` function.\n","\n","\n","For More information about Streamlit, click [here](https://docs.streamlit.io/en/stable/)"],"id":"neugaxggvfrY"},{"cell_type":"code","metadata":{"id":"wnlD5cS9zcsL"},"source":["# Install streamlit and colab-everything\n","!pip install -qq streamlit\n","# Python library to run streamlit, flask, fastapi, etc on Google Colab\n","!pip install -qq colab-everything"],"id":"wnlD5cS9zcsL","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5CJI536Q2-u-"},"source":["Create the `app.py` file and run with Streamlit\n","\n","**Note:** We have provided the required code to execute Streamlit."],"id":"5CJI536Q2-u-"},{"cell_type":"code","metadata":{"id":"jmpuLMdD7ih9"},"source":["%%writefile app.py\n","import streamlit as st\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","import re\n","import string\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.feature import CountVectorizer\n","from pyspark.ml.classification import NaiveBayes\n","from pyspark.sql.types import ArrayType, StringType\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","\n","st.write(\"Creating a spark session\")\n","spark = SparkSession.builder.appName('TwitterSentiment').getOrCreate()\n","dataset = spark.read.csv(\"/content/US_Airline_Tweets.csv\",inferSchema=True,header=True)\n","\n","st.write(\"Preprocessing the train data\")\n","# 1. Data preprocessing (PASTE YOUR ENTIRE DATA PREPROCESSING CODE FROM ABOVE)\n","\n","st.write(\"Ongoing feature extraction!!\")\n","# 2. Feature Extraction (PASTE YOUR ENTIRE FEATURE EXTRACTION CODE FROM ABOVE)\n","\n","st.write(\"Training the model\")\n","# 3. Training the model (PASTE YOUR MODEL TRAINING CODE FROM ABOVE)\n","\n","def predict_users_Input(user_input):\n","  df1 = spark.createDataFrame([ (1, user_input)],['Id', 'UserTweet'])\n","\n","  # YOUR CODE HERE for data preprocessing and feature extraction for user input data\n","\n","  # YOUR CODE HERE for predicting the user input vector using trained model\n","\n","  return predicted_result # return dataframe object\n","\n","def decode(label):\n","  if label == 0:\n","    return \"Positive Tweet!\"\n","  elif label == 1:\n","    return \"Negative Tweet!\"\n","  return \"Neutral Tweet\"\n","\n","user_input = st.text_input(\"Take Input\",\"@mention #Hashtag good something!\")\n","if st.button('predict'):\n","    result = predict_users_Input(user_input)\n","    st.write(decode(result.prediction.values[0]))"],"id":"jmpuLMdD7ih9","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PvxEWsdN4Hao"},"source":["After you execute the code below you will get a web app link where you could perform the sentiment prediction task.\n","* Note: The cell below keeps executing until the server is stopped by interrupting the execution. An error message may appear upon interruption, you could ignore it."],"id":"PvxEWsdN4Hao"},{"cell_type":"code","metadata":{"id":"Nz1JE6qv3JB8"},"source":["from colab_everything import ColabStreamlit\n","ColabStreamlit('/content/app.py')"],"id":"Nz1JE6qv3JB8","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GFU1tT8UER3d"},"source":["Refer the screenshot below.\n","![img](https://cdn.iisc.talentsprint.com/CDS/MiniProjects/sentiment_analysis_streamlit_button.JPG)"],"id":"GFU1tT8UER3d"}]}