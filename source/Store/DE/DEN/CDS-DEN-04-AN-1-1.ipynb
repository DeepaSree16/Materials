{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Analytics with Spark_Quality Checks",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps9llghv8jX1"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "## A program by IISc and TalentSprint\n",
        "### Module 3 - Delta_Lake_Demo_notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeP1PAXf8jYD"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkwaW3k58jYG"
      },
      "source": [
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "* have an overview of storage solutions and their limitations (Databases and Data Lakes).\n",
        "* get an overview of futuristic storage  solution - lakehouses\n",
        "* work on Delta Lake tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3oZtbys8jYL"
      },
      "source": [
        "## Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nR2ZLd-8jYM"
      },
      "source": [
        "**Databases:**\n",
        "\n",
        "Databases  are  designed  to  store  structured  data  as  tables,  which  can  be  read  using SQL queries. They provide very fast computations on the  stored  data  along  with  strong  transactional  ACID  guarantees  on  all  read/write operations.\n",
        "\n",
        "**However, there are few limitations of Databases like:**\n",
        "*  inability to handle growth in data size.\n",
        "*  inability to handle growth in the diversity of analytics.\n",
        "*  they are extremely expensive to scale out.\n",
        "*  they do not support non–SQL based analytics very well.\n",
        "\n",
        "Database and data warehouses can only store data that has been structured. A data lake, on the other hand, stores all types of data: structured, semi-structured, or unstructured.\n",
        "\n",
        "The image in below URL shows how data is handled in Data warehouse, Data Lake and Lakehouse:\n",
        "\n",
        "![img](https://databricks.com/wp-content/uploads/2020/01/data-lakehouse.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4edpSjUfVgS"
      },
      "source": [
        "\n",
        "\n",
        "**Data Lakes:**\n",
        "\n",
        "The data lake architecture, unlike that of databases, decouples the distributed storage system from the distributed compute system. This allows each system to scale out as needed  by  the  workload.  \n",
        "The  data  is  saved  as  files  with  open  formats, such  that  any  processing  engine  can  read  and  write  them  using  standard  APIs. \n",
        "\n",
        "\n",
        "**Limitations of Data Lakes:**\n",
        "\n",
        "* **No atomicity:** means failed production jobs leave data in corrupt state requiring tedious recovery.\n",
        "\n",
        "* **No quality enforcement:** creates insconsistent and unusable data.\n",
        "\n",
        "* **No consistency / isolation:** makes it almost impossible to mix appends and reads, batch and streaming.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geX285sNfV0m"
      },
      "source": [
        "**Lakehouses:** The Next Step in the Evolution of Storage Solutions.\n",
        "\n",
        "The  lakehouse  is  a  new  paradigm  that  combines  the  best  elements  of  data  lakes  and data  warehouses  for  OLAP  workloads.  \n",
        "Lakehouses  are  enabled  by  a  new  system design  that  provides  data  management  features  similar  to  databases  directly  on  the low-cost, scalable storage used for data lakes. \n",
        "\n",
        "\n",
        "**Lakehouse features:**\n",
        "\n",
        "* Transaction support\n",
        "* Schema enforcement and governance\n",
        "* Support for diverse data types in open formats\n",
        "* Support for diverse workloads\n",
        "* Support for upserts and deletes\n",
        "* Data governance\n",
        "\n",
        "Currently, there are a few open source systems, such as Apache Hudi, Apache Iceberg, and Delta Lake, that can be used to build lakehouses with these properties. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnRmxtdVfWAA"
      },
      "source": [
        "**Delta Lake** - Data reliability for Data Lakes.\n",
        "\n",
        "Delta  Lake  is  an  open  source  project  hosted  by  the  Linux  Foundation,  built  by  the original creators of Apache Spark. It is an open data storage format that provides transactional guarantees and enables schema enforcement and evolution. \n",
        "\n",
        "Delta Lake has the tightest integration with Apache  Spark (when compared to Apache Hudi and Apache Iceberg) data  sources  (both  for  batch  and  streaming  workloads)  and  SQL operations  (e.g.,  MERGE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGVZBKRRz3e3"
      },
      "source": [
        "**Delta Lake** - Delta Lake allows you to incrementally improve the quality of your data until it is ready for consumption.\n",
        "\n",
        "Delta Lake Features:\n",
        "\n",
        "1.  **ACID Transactions:** ACID is an acronym for atomicity, consistency, isolation, and durability\n",
        "\n",
        "       **Atomicity:** means that a transaction must exhibit an “all or nothing” behavior. Either all of the instructions within the transaction happen successfully, or none of them happen. Atomicity preserves the “completeness” of the business process.\n",
        "\n",
        "       **Consistency:** refers to the state of the data both before and after the transaction is executed. A transaction maintains the consistency of the state of the data. In other words, after running a transaction, all data in the database is “correct.”\n",
        "\n",
        "      **Isolation:** means that transactions can run at the same time. Any transactions running in parallel have the illusion that there is no concurrency. Multiple transactions occur in isolation.\n",
        "\n",
        "      **Durability:** refers to the impact of an outage or a failure on a running transaction. A durable transaction will not impact the state of data if the transaction ends abnormally. In other words, the data survives any failures. \n",
        "\n",
        "2. **Enables Time travel:** Query previous versions of the table by time or version number.\n",
        "3. **Deletes and upserts:** Supports deleting and upserting into tables with programmatic APIs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICiZzUl75j1C"
      },
      "source": [
        "#### Databricks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbqxhSGu5QFV"
      },
      "source": [
        "We will be using Databricks to work on Delta Lake:\n",
        "\n",
        "Databricks Connect is a client library for Databricks Runtime. It allows you to write jobs using Spark APIs and run them remotely on a Databricks cluster instead of in the local Spark session."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9-i9aINVdBK"
      },
      "source": [
        "###Databricks Community Edition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9dIPfp5UVNT"
      },
      "source": [
        "It is the free version of cloud-based big data platform where users can access a micro-cluster as well as a cluster manager and notebook environment. All users can share their notebooks and host them free of charge with Databricks.\n",
        "\n",
        "It is hosted on Amazon Web Services. However, you are not charged when you use the Databricks Community Edition. \n",
        "\n",
        "The Databricks Community Edition notebooks are compatible with IPython notebooks. You can easily import your existing IPython notebooks into the Databricks Community Edition notebook environment.\n",
        "\n",
        "Click on below link to Sign Up:\n",
        "\n",
        "https://community.cloud.databricks.com/login.html\n",
        "\n",
        "* Click on Sign Up (which you will see next to \"New to Databricks\" below \"Sign In\" button).\n",
        "* Once you click on \"Sign Up\", you will be directed to a page where you are required to enter your details.\n",
        "* Once the details are entered, click on \"Get Started for Free\".\n",
        "* You will be navigated to a page which will ask you to \"Select a Platform\".\n",
        "* Click on \"Get Started\" under - \"Community Edition\" (For students and educational institutions), \n",
        "\n",
        "* Setup your password.\n",
        "\n",
        "**Once the Databricks Community Edition is set up, please follow the below instructions to \"Import the Notebook\" using URL.**\n",
        "\n",
        "**Note : This notebook is adapted from the reference [here](https://docs.databricks.com/_static/notebooks/delta/quickstart-python.html)**\n",
        "\n",
        "* Click the \"Workspace button\" or the \"Home button\" in the sidebar.\n",
        "* Next to any folder, click the \"Menu Dropdown\" on the right side of the text and select Import.\n",
        "* In the Workspace or a user folder, click \"Down Caret\" and select Import.\n",
        "* Specify the URL given below and Click Import (Download the file to your Desktop from this link or directly copy the link):\n",
        "\n",
        "https://cdn.iisc.talentsprint.com/CDS/DeltaLakeTutorial.ipynb \n",
        "\n",
        "This will load Delta Lake Tutorial (Python) to Databricks Community edition where you can go through the example (on Delta Lake) provided and execute the commands."
      ]
    }
  ]
}
