%\tolerance=10000
%\documentclass[prl,twocoloumn,preprintnumbers,amssymb,pla]{revtex4}
\documentclass[prl,twocolumn,showpacs,preprintnumbers,superscriptaddress]{revtex4}
\documentclass{article}
\usepackage{graphicx}
\usepackage{color}
\usepackage{dcolumn}
%\linespread{1.7}
\usepackage{bm}
%\usepackage{eps2pdf}
\usepackage{graphics}
\usepackage{pdfpages}
\usepackage{caption}
%\usepackage{subcaption}
\usepackage[demo]{graphicx} % omit 'demo' for real document
%\usepackage{times}
\usepackage{multirow}
\usepackage{hhline}
\usepackage{subfig}
\usepackage{amsbsy}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{float}
\documentclass{article}
\usepackage{amsmath,systeme}
\usepackage{tikz}

\sysalign{r,r}

% \textheight = 8.5 in
% \topmargin = 0.3 in

%\textwidth = 6.5 in
% \textheight = 8.5 in
%\oddsidemargin = 0.0 in
%\evensidemargin = 0.0 in

%\headheight = 0.0 in
%\headsep = 0.0 in
%\parskip = 0.2in
%\parindent = 0.0in

% \newcommand{\ket}[1]{\left|#1\right\rangle}
% \newcommand{\bra}[1]{\left\langle#1\right|}
\newcommand{\ket}[1]{| #1 \rangle}
\newcommand{\bra}[1]{\langle #1 |}
\newcommand{\braket}[2]{\langle #1 | #2 \rangle}
\newcommand{\ketbra}[2]{| #1 \rangle \langle #2 |}
\newcommand{\proj}[1]{| #1 \rangle \langle #1 |}
\newcommand{\al}{\alpha}
\newcommand{\be}{\beta}
\newcommand{\op}[1]{ \hat{\sigma}_{#1} }
\def\tred{\textcolor{red}}
\def\tgre{\textcolor{green}}


\theoremstyle{plain}
\newtheorem{theorem}{Theorem}

\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}


\begin{document}
\begin{widetext}
\\
\\
\\

\begin{wrapfigure}
\centering
%\includegraphics[\textwidth]{TS_IISc.png}
\end{wrapfigure}
\begin{figure}[h!]
 \begin{right}
  \hfill\includegraphics[\textwidth, right]{TS_IISc.png}
 \end{right}
\end{figure}
\noindent \textbf{1. Match the following TensorflowLite Model Optimization techniques with ther functions.}
\\
\\
\\
%\begin{figure}[H]
%\begin{center}
%    \includegraphics[width=1.25\textwidth,centering]{cloud_model.pdf}
%\end{center}
%    %\caption{}
%\end{figure}
\textbf{TensorflowLite Model Optimization techniques:}
\\
\\
1. Pruning
\\
\\
2. Clustering
\\
\\
3. Quantization
\\
\\

\noindent \textbf{Functions:}
\\
\\
1. Reduces the precision of the numbers used to represent a model's parameters.
\\
\\
2. Removes parameters within a model that have only a minor impact on its predictions.
\\
\\
3. Groups the weights of each layer in a model into a predefined number of clusters.
\\
\\
\\
\noindent A. 1 $\rightarrow$ 1, 2 $\rightarrow$ 3, 3 $\rightarrow$ 2
\\
\\
B. 1 $\rightarrow$ 3, 2 $\rightarrow$ 2, 3 $\rightarrow$ 1
\\
\\
C. 1 $\rightarrow$ 3, 2 $\rightarrow$ 1, 3 $\rightarrow$ 2
\\
\\
D. 1 $\rightarrow$ 2, 2 $\rightarrow$ 3, 3 $\rightarrow$ 1
\\
\\
\\
\textbf{Answer: D}
\\
\\
\\
\\
\textbf{Study the given below statements and answer the second question.}
\\
\\
\\
$i$. TensorFlow Lite is a lighter version of TensorFlow, which is specifically designed for the mobile platform and embedded devices.
\\
\\
$ii$. TensorFlow Lite supports Quantization while TensorFlow does not.
\\
\\
$iii$. Number of operations supported on TensorFlow Lite are more as compared to TensorFlow.
\\
\\
$iv$. TensorFlow Lite supports architectures of TPUs and GPUs.
\\
\\
$v.$ TensorFlow Lite does not support Quantization while TensorFlow does support Quantization.
\\
\\
\\
\textbf{2. Which of the statements given above is/are true?}
\\
\\
\\
A. $iii$, $iv$ and $v$ only
\\
\\
B. $i$, $ii$, and $iii$ only
\\
\\
C. $i$ and $ii$ only
\\
\\
%E. $i$ and $iv$
%\\
%\\
D. $iv$ and $v$ only
\\
\\
\\
\textbf{Answer: C}
\\
\\
\\
\\
\textbf{3. Tiny Machine Learning (TinyML) is where the embedded internet of things (IoT) and machine learning (ML) intersect.}
\\
\\
\\
A. True
\\
\\
B. False
\\
\\
\\
\textbf{Answer: A}
\\
\\
\\
\\
\textbf{4. Study the given below statements and answer the fourth question.}
\\
\\
\\
$i$. Limited OS Support
\\
\\
$ii$. Lower compute power
\\
\\
$iii$. Less memory
\\
\\
$iv$. More compute power
\\
\\
$v$. Only focused on inference
\\
\\
$vi$. More memory
\\
\\
\\
\textbf{4. From the statements given above, what are some of the attributes of Tiny Machine Learning ?}
\\
\\
\\
A. $iv$, $v$ and $vi$ only
\\
\\
B. $i$, $ii$, $iii$ and $v$ only
\\
\\
C. $ii$, $iv$ and $v$ 
\\
\\
D. $i$, $ii$ and $iii$ only
\\
\\
\\
\textbf{Answer: B}
\\
\\
\\
\\
\textbf{5. In the Tiny Machine Learning framework, does the software provide support for virtual memory?}
\\
\\
\\
A. Yes
\\
\\
B. No
\\
\\
\\
\textbf{Answer: B}
\\
\\
\\
\\
\\
\\
\\
\\
\\
\end{widetext}
\end{document} 