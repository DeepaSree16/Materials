{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"13_ResNet50_Pretrained_model.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"jFUjPQMAn_n3"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"0Xq1LLdMoDwa"},"source":["At the end of the experiment you will be able to :\n","\n","- finetune the resnet model to determine a dog's breed from a given image\n"]},{"cell_type":"code","metadata":{"id":"d8oaZCpUoFtU","cellView":"form"},"source":["#@title Experiment Explanation Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"850\" height=\"480\" controls>\n","  <source src=\"https://cdn.talentsprint.com/talentsprint1/archives/sc/misc/resnet50_dog_breed_classification.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5xJZ6po7p17R"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"DnBNowAkXGVL"},"source":["### Description\n","\n","\n","This dataset has been extracted from [stanford](http://vision.stanford.edu/aditya86/ImageNetDogs/main.html) which contains images of breeds of dogs from around the world where each image is a subset from ImageNet\n","\n","There are around 1,000 images, out of which 850 are used for training and 150 for testing\n","\n","The dataset comprises 12 breeds of dogs:\n","\n","    african_hunting_dog\n","    beagle\n","    bloodhound\n","    chow\n","    doberman\n","    eskimo_dog\n","    german_shepherd\n","    golden_retriever\n","    leonberg\n","    lhasa\n","    pug\n","    redbone"]},{"cell_type":"markdown","metadata":{"id":"e6aDGyYbOeOy"},"source":["### Transfer Learning\n","\n","Transfer learning is a machine learning technique in which a network that has been trained to perform a specific task is being reused (repurposed) as a starting point for another similar task."]},{"cell_type":"code","source":["! wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/dog_breed_images.zip\")\n","! unzip dog_breed_images.zip\")"],"metadata":{"id":"IKBEKnE0s8PA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GFPkgHv_RULY"},"source":["### 1. Importing required packages"]},{"cell_type":"code","metadata":{"id":"VXLT2GFloWAP"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torchvision\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","from torchsummary import summary\n","from torchvision import datasets, transforms, models"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J6XWrer9It5R"},"source":["### 2.  Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"WNAmOOnWRDMh"},"source":["# Specify root data directory\n","data_dir = 'dog_breed_images'\n","\n","batch_size = 10\n","\n","# ResNet50 input is 224x224 by default\n","IMG_HEIGHT = 224\n","IMG_WIDTH = 224"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2GTj8d1LDMtZ"},"source":["transform = transforms.Compose([transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),transforms.ToTensor()])\n","\n","# Loading the data\n","trainset = datasets.ImageFolder(data_dir + '/Train', transform=transform)\n","\n","testset = datasets.ImageFolder(data_dir + '/Test', transform=transform)\n","\n","# Load the data. utils.dataloader is a package for loading the dataset \n","train_loader = torch.utils.data.DataLoader(trainset, shuffle=True, batch_size=batch_size)\n","test_loader = torch.utils.data.DataLoader(testset, shuffle=True, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E4z4ipdTg8Pi"},"source":["# Check number of training and test images\n","dataset_sizes = {'Train': len(trainset), 'Test': len(testset)}\n","dataset_sizes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tUY6Kr4ap97A"},"source":["# Generate a batch of 10 images and labels\n","train_images, train_labels = next(iter(train_loader))\n","train_images.shape, train_labels.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LlszUhNNyrl_"},"source":["### 3. Visualizing the train images"]},{"cell_type":"code","metadata":{"id":"IFH3o_AWHJMY"},"source":["# labels Translator \n","label_names = {v: k for k, v in trainset.class_to_idx.items()}\n","label_names"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"olZZy0KbGQrz"},"source":["# Create a grid of images along with their corresponding labels\n","L = 3\n","W = 3\n","\n","fig, axes = plt.subplots(L, W, figsize = (12, 12))\n","axes = axes.reshape(-1)\n","\n","for i in np.arange(0, L*W):\n","    axes[i].imshow(train_images[i].permute(1, 2, 0))\n","    axes[i].set_title(label_names[train_labels[i].item()])\n","    axes[i].axis('off')\n","\n","plt.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wVSlpSPWQ574"},"source":["### 4. Initializing CUDA"]},{"cell_type":"code","metadata":{"id":"6oOkwtOsR62g"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2RnRtZ4tbSoH"},"source":["### 5. Loading Resnet50 model with pretrained weights"]},{"cell_type":"code","metadata":{"id":"hzS9j0i3R6_m"},"source":["basemodel = models.resnet50(pretrained=True)\n","print(basemodel)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K9dpnAY13lb1"},"source":["print(basemodel.fc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_tEYes3Ia9-6"},"source":["### 6. Fine-tuning ResNet-50 \n","\n","* The first layers of Resnet50 are used to extract high level general features\n","* The last couple of layers are used to perform classification (on a specific task)\n","* Copy the first trained layers (base model) and then add a new custom layers in the output to perform classification on a specific task\n"]},{"cell_type":"code","metadata":{"id":"2FSGeeM2R6zw"},"source":["# Freeze all layers\n","for param in basemodel.parameters():\n","    param.requires_grad = False\n","\n","# Parameters of the below newly constructed modules have \"requires_grad=True\" \n","basemodel.fc = nn.Sequential(nn.Linear(2048, 512),\n","                         nn.ReLU(),\n","                         nn.Dropout(0.2),\n","                         nn.Linear(512, len(label_names)))\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# Optimize only the fully connected layer portion\n","optimizer = optim.SGD(basemodel.fc.parameters(), lr=0.003, momentum=0.5)\n","model = basemodel.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fAj6k54WcT7i"},"source":["# Print the summary of the model\n","from torchsummary import summary\n","summary(model, input_size=(3, IMG_HEIGHT, IMG_WIDTH))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cgi7zylgdpzC"},"source":["### 7. Train the deep learning model"]},{"cell_type":"code","metadata":{"id":"yuI7YjGJ35Z5"},"source":["def train(net, trainloader, trainset, epochs):\n","    # keeping the network in train mode\n","    net.train()\n","\n","    train_loss,  train_accuracy = [], []\n","    # Loop for no of epochs\n","    for epoch in range(epochs+1):\n","          running_loss = 0.0\n","          running_accuracy = 0.0\n","\n","          # Iterate through all the batches in each epoch\n","          for images, labels in (trainloader):\n","                  images, labels = images.to(device), labels.to(device)\n","\n","                  #-----------------Forward Pass----------------------\n","                  outputs = net(images)\n","                  loss = criterion(outputs, labels) # Calculating the loss\n","\n","                  #-----------------Backward Pass---------------------\n","                  optimizer.zero_grad() # Zero the parameter gradients\n","                  loss.backward()\n","                  optimizer.step() # update the weights accordingly\n","\n","                  running_loss+=loss.item()\n","                  \n","                  # Accuracy calculation\n","                  _, predicted = torch.max(outputs, 1)\n","                  running_accuracy += (predicted == labels).sum().item()\n","\n","          #-----------------Log-------------------------------\n","          loss = running_loss/len(trainset)\n","          train_loss.append(loss)\n","\n","          accuracy = 100 * (running_accuracy/len(trainset))\n","          train_accuracy.append(accuracy)\n","          print(\"======> epoch: {}/{}, Train Loss:{:.4f} Train Accuracy:{:.2f}\".format(epoch,epochs,loss,accuracy))\n","    return net, train_loss, train_accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_7fSU5jP38Rt"},"source":["model, train_loss, train_accuracy = train(model, train_loader, trainset, 5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ssHGDRMEd1cT"},"source":["### 8. Evaluate the trained deep learning model"]},{"cell_type":"code","metadata":{"id":"005dOBwl85_B"},"source":["def test(net, testloader, testset):\n","    # keeping the network in evluation mode\n","    net.eval()\n","    \n","    predicted_label, original_label, test_images = [], [], []\n","    running_accuracy = 0.0\n","\n","    # Iterate through all the batches\n","    for images, labels in (testloader):\n","            images, labels = images.to(device), labels.to(device)\n","\n","            #-----------------Forward Pass----------------------\n","            outputs = net(images)\n","            \n","            # Accuracy calculation\n","            _, predicted = torch.max(outputs, 1)\n","            running_accuracy += (predicted == labels).sum().item()\n","            \n","            test_images.extend(images.cpu())\n","            predicted_label.extend(predicted.cpu())\n","            original_label.extend(labels.cpu())\n","\n","    #-----------------Log-------------------------------\n","    accuracy = 100 * (running_accuracy/len(testset))\n","    print(\"======> Test Accuracy:{:.2f}\".format(accuracy))\n","    return accuracy, predicted_label, original_label, test_images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0iiTZ-1c_9e9"},"source":["test_accuracy, predicted_label, original_label, test_images = test(model, test_loader, testset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eemlfQiThbbD"},"source":["### 9. Visualizing the test images along with the predictions"]},{"cell_type":"code","metadata":{"id":"FFyPh4yYJNDT"},"source":["# Create a grid of images along with their corresponding labels\n","L = 3\n","W = 3\n","\n","fig, axes = plt.subplots(L, W, figsize = (12, 12))\n","axes = axes.reshape(-1)\n","\n","for i in np.arange(0, L*W):\n","    axes[i].imshow(test_images[i].permute(1, 2, 0))\n","    axes[i].set_title('\\n{}\\nPredicted: {}'.format(str(label_names[original_label[i].item()]),str(label_names[predicted_label[i].item()])))\n","    axes[i].axis('off')\n","\n","plt.tight_layout()"],"execution_count":null,"outputs":[]}]}