{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"9_News_category_BoW VS W2V.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"koiIre6cUWv_"},"source":["## Learning Objective"]},{"cell_type":"markdown","metadata":{"id":"OzkHDYHGZnyC"},"source":["\n","At the end of the experiment, you will be able to:\n","\n","*  Pre-process the data\n","*  Representation of  text document using Bag of Words & Word2Vec"]},{"cell_type":"code","metadata":{"cellView":"form","id":"XnIT_27v5ORu"},"source":["#@title Experiment Walkthrough Video\n","#@markdown BoW vs W2V\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"854\" height=\"480\" controls>\n","  <source src=\"https://cdn.exec.talentsprint.com/non-processed/Bag_of_Words_Vs_Word2Vec.mp4\">\n","</video>\n","\"\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dataset"],"metadata":{"id":"2RPrPQi532cK"}},{"cell_type":"markdown","metadata":{"id":"snBfzAFAkIFA"},"source":["   This dataset contains around 200k news headlines from the year 2012 to 2018 obtained from [HuffPost](https://www.huffpost.com/). The model trained on this dataset could be used to identify tags for untracked news articles or to identify the type of language used in different news articles.\n","\n","Each news headline has a corresponding category. Categories and corresponding article counts as follows:\n","\n","\n","    POLITICS: 32739\n","    WELLNESS: 17827\n","    ENTERTAINMENT: 16058\n","    TRAVEL: 9887\n","    STYLE & BEAUTY: 9649\n","    PARENTING: 8677\n","    HEALTHY LIVING: 6694\n","    QUEER VOICES: 6314\n","    FOOD & DRINK: 6226\n","    BUSINESS: 5937\n","    COMEDY: 5175\n","    SPORTS: 4884\n","    BLACK VOICES: 4528\n","    HOME & LIVING: 4195\n","    PARENTS: 3955\n","    THE WORLDPOST: 3664\n","    WEDDINGS: 3651\n","    WOMEN: 3490\n","    IMPACT: 3459\n","    DIVORCE: 3426\n","    CRIME: 3405\n","    MEDIA: 2815\n","    WEIRD NEWS: 2670\n","    GREEN: 2622\n","    WORLDPOST: 2579\n","    RELIGION: 2556\n","    STYLE: 2254\n","    SCIENCE: 2178\n","    WORLD NEWS: 2177\n","    TASTE: 2096\n","    TECH: 2082\n","    MONEY: 1707\n","    ARTS: 1509\n","    FIFTY: 1401\n","    GOOD NEWS: 1398\n","    ARTS & CULTURE: 1339\n","    ENVIRONMENT: 1323\n","    COLLEGE: 1144\n","    LATINO VOICES: 1129\n","    CULTURE & ARTS: 1030\n","    EDUCATION: 1004\n","\n","\n","#### Description\n","This dataset has the following columns:\n","1. **Category:** Category article belongs to\n","2. **Headline:** Determines the Headline of the article\n","3. **Authors:** Person authored the article\n","4. **Link:** Link to the post\n","5. **Short_description:** Short description of the article\n","6. **Date:** Date the article was published\n","\n","Out of 41 category's from the News_Category_Dataset, we consider four category's (Travel, Tech, Science, College) for this experiment"]},{"cell_type":"code","source":["! wget https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/News_Category_Dataset_v2.csv\n","! wget https://cdn.talentsprint.com/talentsprint1/archives/sc/aiml/experiment_related_data/AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.rar\n","! unrar e /content/AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.rar\n","    "],"metadata":{"id":"p0bNu-vnt9xU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2a9XmVH8dXjK"},"source":["## Import packages\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53Heccvsee6Y"},"outputs":[],"source":["import re\n","import nltk\n","import pandas as pd\n","import numpy as np\n","import gensim\n","from nltk.corpus import stopwords \n","nltk.download('stopwords')\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","source":["## Load the data \n"],"metadata":{"id":"oxW_xSfK4tjH"}},{"cell_type":"code","source":["# Load the data\n","df = pd.read_csv('News_Category_Dataset_v2.csv')\n","df.head()"],"metadata":{"id":"JM4mgpFwpws3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Count the classes in category\n","df['category'].value_counts()"],"metadata":{"id":"Wu0ax7S5b6RS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Pre-processing"],"metadata":{"id":"KPTGmXsF82J2"}},{"cell_type":"markdown","source":["we are considering four category's (Travel, Tech, Science, College) for this experiment"],"metadata":{"id":"UiyOvedV5Rsl"}},{"cell_type":"code","source":["# Create a list of manually selected category \n","category = ['TRAVEL','TECH','SCIENCE','COLLEGE']\n","\n","# Load the dataset based on the category\n","df = df[df['category'].isin(category)]      # .isin whether each element in the DataFrame is contained in values.\n","df.shape"],"metadata":{"id":"lyg6RjTpbmJt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Add the two columns into text column\n","df['text'] = df['headline'] +','+ df['short_description'] \n","df['label'] = df['category']"],"metadata":{"id":"lx1oxkqKa-Tu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Drop the unwanted columns"],"metadata":{"id":"CudtuGFW6Pzp"}},{"cell_type":"code","source":["df = df.drop(['headline','short_description','date','authors','link','category','Unnamed: 0'], axis=1)\n","df.shape"],"metadata":{"id":"X6o41T2x6OH0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Consider text column as feature and label as target variable. Convert label into numerical.\n","\n","Hint: Label Encoder for obtaining a numeric representation, refer to the [link](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."],"metadata":{"id":"oF0X1nch6Zar"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()\n","df['label']=le.fit_transform(df['label'])\n","df['label'].head()"],"metadata":{"id":"2xEm4MdXjAeM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['text'].shape, df['label'].shape"],"metadata":{"id":"EeMg8HEZc1ID"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## BoW"],"metadata":{"id":"4hmWpDAtMnj_"}},{"cell_type":"markdown","metadata":{"id":"YQr_afHnUcTL"},"source":["### TF IDF\n"," tf-idf aims to represent the number of times a given word appears in a document (a movie review in our case) relative to the number of documents in the corpus that the word appears in â€” where, words that appear in many documents have a value closer to zero and words that appear in less documents have values closer to 1.\n","\n","\n"]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","tfidf_vectorizer = TfidfVectorizer()\n","alltext = df['text'].astype(str)\n","tfidf_feature = tfidf_vectorizer.fit_transform(alltext)  "],"metadata":{"id":"Y3WF846nxGTS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qBwRCxlVM1Ch"},"source":["### Split the data into train and test sets \n","\n","Hint: Refer to[Train-Test split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test,y_train,y_test = train_test_split(tfidf_feature,df['label'],test_size = 0.2,random_state=42)"],"metadata":{"id":"-yTNLOj9hIR8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sg3MwoH2M477"},"source":["### Apply the Classification \n"]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.svm import SVC\n","\n","# Create an object for all the algorithms\n","model1 = DecisionTreeClassifier()\n","model2 = KNeighborsClassifier(n_neighbors=8)\n","model3 = SGDClassifier()\n","model4 = SVC(kernel='linear')\n","\n","models = [model1, model2, model3, model4]\n","\n","for model in models:\n","    model.fit(X_train, y_train)         # fit the model\n","    y_pred= model.predict(X_test)       # then predict on the test set\n","    accuracy= accuracy_score(y_test, y_pred)\n","    print(\"Accuracy (in %):\", model, \"is\", accuracy)\n"],"metadata":{"id":"fArIDcoGgv3E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Word2Vec"],"metadata":{"id":"Gq4fYQQ8Yids"}},{"cell_type":"markdown","metadata":{"id":"Lvhba-_oNx8l"},"source":["###Load pre-trained Word2Vec\n","\n","Lets now proceed to load the complete pretrained vectors."]},{"cell_type":"code","source":["model = gensim.models.KeyedVectors.load_word2vec_format('AIML_DS_GOOGLENEWS-VECTORS-NEGATIVE-300_STD.bin', binary=True, limit=500000)"],"metadata":{"id":"tNxU0Jc10YqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wFdjtmZLDTqq"},"source":["### Word2Vec representation\n","\n","Convert each document into average of the word2vec vectors of all valid words in document"]},{"cell_type":"markdown","source":["Note: Below code cell take some time to compile"],"metadata":{"id":"3PQVzVad8eN3"}},{"cell_type":"code","source":["# Creating empty final dataframe\n","docs_vectors = pd.DataFrame() \n","\n","# Removing stop words\n","stopwords = nltk.corpus.stopwords.words('english') \n","text = df['text'].astype(str)\n","# Looping through each document and cleaning it\n","for doc in text.str.lower().str.replace('[^a-z ]', ''): \n","    temp = pd.DataFrame()  \n","    for word in doc.split(' '): \n","      # If word is not present in stopwords then (try)\n","        if word not in stopwords: \n","            try:\n","                # If word is present in embeddings then get the vector representation and append it to temporary dataframe\n","                word_vec = model[word] \n","                temp = temp.append(pd.Series(word_vec), ignore_index = True) \n","            except:\n","                pass\n","    # Take the average of vectors for each word\n","    doc_vector = temp.mean() \n","    # Append each document value to the final dataframe\n","    docs_vectors = docs_vectors.append(doc_vector, ignore_index = True) \n","docs_vectors.shape\n","\n"],"metadata":{"id":"B0iv1RAYzhtE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k2FR6SQv-TqC"},"source":["### Split the data into train and test sets \n","\n","Hint: Refer to[Train-Test split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test,y_train,y_test = train_test_split(docs_vectors,df['label'],test_size = 0.2,random_state=42)"],"metadata":{"id":"1EikyJ9qcj3P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oWTFS1oa8Xlf"},"source":["### Apply the Classification \n"]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.svm import SVC\n","\n","# Create an object for all the algorithms\n","model1 = DecisionTreeClassifier()\n","model2 = KNeighborsClassifier(n_neighbors=8)\n","model3 = SGDClassifier()\n","model4 = SVC(kernel='linear')\n","\n","models = [model1, model2, model3, model4]\n","\n","for model in models:\n","    model.fit(X_train, y_train)         # fit the model\n","    y_pred= model.predict(X_test)       # then predict on the test set\n","    accuracy= accuracy_score(y_test, y_pred)\n","    print(\"Accuracy(in %):\", model, \"is\", accuracy)"],"metadata":{"id":"Z994GRolBMrH"},"execution_count":null,"outputs":[]}]}